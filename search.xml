<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>推荐系统十大挑战</title>
      <link href="/2019/04/14/tui-jian-xi-tong-shi-da-tiao-zhan/"/>
      <url>/2019/04/14/tui-jian-xi-tong-shi-da-tiao-zhan/</url>
      
        <content type="html"><![CDATA[<h1 id="推荐系统十大挑战"><a href="#推荐系统十大挑战" class="headerlink" title="推荐系统十大挑战"></a>推荐系统十大挑战</h1><h2 id="挑战一：数据稀疏性问题"><a href="#挑战一：数据稀疏性问题" class="headerlink" title="挑战一：数据稀疏性问题"></a>挑战一：数据稀疏性问题</h2><blockquote><p>现在待处理的推荐系统规模越来越大，用户和商品（也包括其他物品，譬如音乐、网页、文献……）数目动辄百千万计，两个用户之间选择的重叠非常少。如果用用户和商品之间已有的选择关系占所有可能存在的选择关系的比例来衡量系统的稀疏性，那么我们平时研究最多的 MovieLens 数据集的稀疏度是 4.5%，Netflix 是 1.2%，这些其实都是非常密的数据了，Bibsonomy 是 0.35%，Delicious 是 0.046%。想想淘宝上号称有 8 亿商品，平均而言一个用户能浏览 800 件吗，我估计不能，所以稀疏度应该在百万分之一或以下的量级。数据非常稀疏，使得绝大部分基于关联分析的算法（譬如协同过滤）效果都不好。这个问题本质上是无法完全克服的，为了解决这个问题，也有很多办法，譬如可以通过扩散的算法，从原来的一阶关联（两个用户有多少相似打分或者共同购买的商品）到二阶甚至更高阶的关联（假设关联性或者说相似性本身是可以传播的）[8]，也可以添加一些缺省的打分[9]，从而提高相似性的分辨率。数据规模越大，一般而言越稀疏，现在能够处理稀疏数据的算法被认为是更有前途的（譬如扩散[8]、迭代寻优[10]，转移相似性[11]等等）。</p></blockquote><h2 id="挑战二：冷启动问题"><a href="#挑战二：冷启动问题" class="headerlink" title="挑战二：冷启动问题"></a>挑战二：冷启动问题</h2><blockquote><p>新用户因为罕有可以利用的行为信息，很难给出精确的推荐。反过来，新商品由于被选择次数很少，也难以找到合适的办法推荐给用户。一种办法是利用文本信息进行辅助推荐，或者通过注册以及询问得知一些用户的属性信息，譬如年龄、居住城市、受教育程度、性别、职业等等[12,13]。最近标签系统（tagging systems）的广泛应用提供了解决冷启动问题的可能方案[14]，因为标签既可以看作是商品内容的萃取，同时也反映了用户的个性化喜好——譬如对《桃姐》这部电影，有的人打上标签“伦理”，有的人打上标签“刘德华”，两个人看的电影一样，但是兴趣点可能不尽相同。当然，利用标签也只能是提高有少量行为的用户的推荐准确性，对于纯粹的冷启动用户，是没有帮助的，因为这些人还没有打过任何标签。有趣的是，最近的研究显示，新用户更容易选择特别流行的商品[15]——这无论如何是一个好消息，说明使用热销榜也能获得不错的结果。冷启动问题还可以通过多维数据的交叉推荐部分解决，其精确度和多样性又远胜于热销榜，这一点我们在后面会进一步介绍。</p></blockquote><h2 id="挑战三：大数据处理与增量计算问题"><a href="#挑战三：大数据处理与增量计算问题" class="headerlink" title="挑战三：大数据处理与增量计算问题"></a>挑战三：大数据处理与增量计算问题</h2><blockquote><p>尽管数据很稀疏，大部分数据都拥有百千万计的用户和商品，因此，如何快速高效处理这些数据成为迫在眉睫的问题，而算法时间和空间的复杂性，尤其是前者，获得了空前重视。一个高效的算法，要么复杂性很低，要么能够很好并行化，要么两者兼具。局部扩散算法在这两个方面都具有明显优势[16]！另外一条可能的解决之道，是设计增量算法，也就是说当产生新用户，新商品以及新的连接关系时，算法的结果不需要在整个数据集上重新进行计算，而只需要考虑所增加节点和连边局部的信息，对原有的结果进行微扰，快速得到新结果[17]。一般而言，这种算法随着加入的信息量的增多，其误差会积累变大，最终每过一段时间还是需要利用全局数据重新进行计算。一个特别困难的挑战，使如何设计一种算法，能够保证其误差不会累积，也就是说其结果与利用全部数据重新计算的结果之间的差异不会单调上升。我们把这种算法叫做自适应算法，它是增量算法的一个加强版本[18]，其设计要求和难度更高。增量算法已经在业界有了应用，譬如百分点科技推荐引擎中的若干算法都采用了增量技术，使得用户每次新浏览收藏或者购买商品后其推荐列表立刻得到更新。当然，该引擎也只是部分算法实现了增量技术，更没有达到所有算法都能够自适应学习的程度，还有很长的路要走。</p></blockquote><h2 id="挑战四：多样性与精确性的两难困境"><a href="#挑战四：多样性与精确性的两难困境" class="headerlink" title="挑战四：多样性与精确性的两难困境"></a>挑战四：多样性与精确性的两难困境</h2><blockquote><p>如果要给用户推荐他喜欢的商品，最“保险”的方式就是给他特别流行或者得分特别高的商品，因为这些商品有更大的可能性被喜欢（至少贝叶斯会这么想），往坏了说，也很难特别被讨厌。但是，这样的推荐产生的用户体验并不一定好，因为用户很可能已经知道这些热销流行的产品，所以得到的信息量很少，并且用户不会认同这是一种“个性化的”推荐。事实上，Mcnee 等人已经警告大家，盲目崇拜精确性指标可能会伤害推荐系统——因为这样可能会导致用户得到一些信息量为 0 的“精准推荐”并且视野变得越来越狭窄[19]。让用户视野变得狭窄也是协同过滤算法存在的一个比较主要的缺陷。与此同时，应用个性化推荐技术的商家，也希望推荐中有更多的品类出现，从而激发用户新的购物需求。遗憾的是，推荐多样的商品和新颖的商品与推荐的精确性之间存在矛盾，因为前者风险很大——一个没什么人看过或者打分较低的东西推荐出手，很可能被用户憎恶，从而效果更差。很多时候，这是一个两难的问题，只能通过牺牲多样性来提高精确性，或者牺牲精确性来提高多样性。一种可行之策是直接对推荐列表进行处理，从而提升其多样性[20-22]。目前百分点推荐引擎所使用的方法也是类似的。这种方法固然在应用上是有效的，但是没有任何理论的基础和优美性可言，只能算一种野蛮而实用的招数。我们发现，通过精巧混合精确性高和多样性好的两种算法，可以同时提高算法的多样性和精确性，不需要牺牲任何一方[23]。遗憾的是，我们还没有办法就这个结果提供清晰的解读和深刻的见解。多样性和精确性之间错综复杂的关系和隐匿其后的竞争，到目前为止还是一个很棘手的难题。</p></blockquote><h2 id="挑战五：推荐系统的脆弱性问题"><a href="#挑战五：推荐系统的脆弱性问题" class="headerlink" title="挑战五：推荐系统的脆弱性问题"></a>挑战五：推荐系统的脆弱性问题</h2><blockquote><p>受推荐系统在电子商务领域重大的经济利益的驱动，一些心怀不轨的用户通过提供一些虚假恶意的行为，故意增加或者压制某些商品被推荐的可能性[24]。因此，一个算法能否在一定程度上保持对恶意攻击的鲁棒性，成为需要认真考虑的一个特征。以最简单的关联规则挖掘算法为例，Apriori 算法的鲁棒性就远胜于 k 近邻算法[25]。有一些技术已经被设计出来提高推荐系统面对恶意攻击的鲁棒性，譬如通过分析对比真实用户和疑似恶意用户之间打分行为模式的差异，提前对恶意行为进行判断，从而阻止其进入系统或赋予疑似恶意用户比较低的影响力[26-28]。总体来说，这方面的研究相对较少，系统性的分析还很缺乏，反而是攻击策略层出不穷，有一种“道高一尺，魔高一丈”的感觉。仅 Burke 等人 2011 年的研究报告中就分析了 4 大种类 8 种不同的攻击策略[29]。</p></blockquote><h2 id="挑战六：用户行为模式的挖掘和利用"><a href="#挑战六：用户行为模式的挖掘和利用" class="headerlink" title="挑战六：用户行为模式的挖掘和利用"></a>挑战六：用户行为模式的挖掘和利用</h2><blockquote><p>深入挖掘用户的行为模式有望提高推荐的效果或在更复杂的场景下进行推荐。譬如说，新用户和老用户具有很不一样的选择模式：一般而言，新用户倾向于选择热门的商品，而老用户对于小众商品关注更多[15]，新用户所选择的商品相似度更高，老用户所选择的商品多样性较高[30]。有些混合算法可以通过一个单参数调节推荐结果的多样性和热门程度[23]，在这种情况下就可以考虑为给不同用户赋予不同参数（从算法结果的个性化到算法本身的个性化），甚至允许用户自己移动一个滑钮调节这个参数——当用户想看热门的时候，算法提供热门推荐；当用户想找点很酷的产品时，算法也可以提供冷门推荐。用户行为的时空统计特性也可以用于提高推荐或者设计针对特定场景的应用。用户的选择可能同时蕴含了长期的兴趣和短期的兴趣，通过将这两种效应分离出来，可以明显提高推荐的精确度[31-33]。事实上，简单假设用户兴趣随时间按照指数递减，也能够得到改进的推荐效果[34,35]。利用手机上网现在已经越来越普及，与此同时，嵌入 GPS 的手机越来越多，因此，基于位置的服务成为一个受到学术界和业界广泛关注的问题。基于位置信息的推荐可能会成为个性化推荐的一个研究热点和重要的应用场景，而这个问题的解决需要能够对用户的移动模式有深入理解[36,37]（包括预测用户的移动轨迹和判断用户在当前位置是否有可能进行餐饮购物活动等），同时还要有定量的办法去定义用户之间以及地点之间的相似性[38,39]。另外，不同用户打分的模式也很不一样[40,41]，用户针对不同商品的行为模式也不一样[42,43]（想象你在网上下载一首歌和团购房子时的区别），这些都可以用来提高推荐的效果。</p></blockquote><h2 id="挑战七：推荐系统效果评估"><a href="#挑战七：推荐系统效果评估" class="headerlink" title="挑战七：推荐系统效果评估"></a>挑战七：推荐系统效果评估</h2><blockquote><p>推荐系统的概念提出已经有几十年了，但是怎么评价推荐系统，仍然是一个很大的问题。常见的评估指标可以分为四大类，分别是准确度、多样性、新颖性和覆盖率，每一类下辖很多不同的指标，譬如准确度指标又可以分为四大类，分别是预测评分准确度、预测评分关联、分类准确度、排序准确度四类。以分类准确度为例，又包括准确率、召回率、准确率提高率、召回率提高率、F1 指标和 AUC 值。朱郁筱和吕琳媛总结了文献中曾经出现过的几乎所有的推荐系统指标[44]，这些指标都是基于数据本身的指标，可以认为是第一层次。实际上，在真实应用时，更为重要的是另外两个层次的评价，第二个层次是商业应用上的关键表现指标，譬如受推荐影响的转化率，购买率，客单价，购买品类数等等，第三个层次是用户真实的体验。绝大部分研究只针对第一个层次的评价指标，而业界真正感兴趣的是第二个层次的评价（譬如到底是哪个指标或者哪些指标组合的结果能够提高用户购买的客单价），而第三个层细最难，没人能知道，只能通过第二层面来估计。如何建立第一层面和第二层面指标之间的关系，就成为了关键，这一步打通了，理论和应用之间的屏障就通了一大半了。</p></blockquote><h2 id="挑战八：用户界面与用户体验"><a href="#挑战八：用户界面与用户体验" class="headerlink" title="挑战八：用户界面与用户体验"></a>挑战八：用户界面与用户体验</h2><blockquote><p>这个问题更多地不是一个学术性质的问题，而是真实应用的问题。十年前就有学者指出[45,46]，推荐结果的可解释性，对于用户体验有至关重要的影响——用户希望知道这个推荐是怎么来的。在这个意义上，协同过滤有明显的优势，譬如亚马逊基于商品的协同过滤在发送推荐的电子邮件时会告诉用户之所以向其推荐某书，是因为用户以前购买过某些书。相对地，矩阵分解或者集成学习算法就很难向用户解释推荐结果的起源。用户更喜欢来自自己朋友的推荐而不是系统的推荐，这一点在后面还会详细提到。另外，推荐列表往往含有很多项，这些推荐项最好能够区分成很多类别，不同类别往往来自于不同的推荐方法，譬如看过还看过（浏览过本商品的客户还浏览过的商品）、买过还买过（购买过本商品的客户还购买过的商品）、看过最终购买（浏览过本商品的客户最终购买的商品）、个性化热销榜（个性化流行品推荐）、猜你喜欢（个性化冷门商品推荐）等等。当然，如何更好呈现推荐，是一个很难建立理论模型和进行量化的问题，对于不同被推荐品而言，用户界面设计的准则也可能大不相同。建立一个可以进行 A/B 测试的系统，或可积累重要的实验数据。</p></blockquote><h2 id="挑战九：多维数据的交叉利用"><a href="#挑战九：多维数据的交叉利用" class="headerlink" title="挑战九：多维数据的交叉利用"></a>挑战九：多维数据的交叉利用</h2><blockquote><p>目前网络科学研究一个广受关注的概念是具有相互作用的网络的结构和动力学。网络与网络之间的相互作用大体可以分成三类：一类是依存关系[47]，譬如电力网络和 Internet，如果发生了大规模停电事故，当地的自主系统和路由器也会受到影响，导致网络局部中断；第二类是合作关系[48]，譬如人的一次出行，可以看作航空网络、铁路网络和公路网络的一次合作；第三类是交叠关系[49]，主要针对社会网络，这也是我们最关注的。我们几乎每一个人，都参与了不止一个大型的社会网络中，譬如你可能既有新浪微博的帐号，又是人人网的注册用户，还是用手机，那么你已经同时在三个巨大的社会网络中了。与此同时，你可能还经常在淘宝、京东、麦包包、1 号店、库巴网……这些地方进行网购，那么你也是一张巨大的用户-商品二部分图中的一员。想象如果能够把这些网络数据整合起来，特别是知道每个节点身份的对应关系（不需要知道你真实身份，只需要知道不同网络中存在的一些节点是同一个人），其中有特别巨大的社会经济价值。举个例子，你可能已经在新浪微博上关注了很多数据挖掘达人的微博，并且分享了很多算法学习的心得和问题，当你第一次上当当网购书的时候，如果主页向你推荐数据挖掘的最新专著并附有折扣，你会心动吗？交叠社会关系中的数据挖掘，或称多维数据挖掘，是真正有望解决系统内部冷启动问题的终极法宝——只要用户在系统外部的其他系统有过活动。单纯从个性化商品推荐来讲，可以利用用户在其他电商的浏览购买历史为提高在目标电商推荐的精确度——当然，每一个电商既是付出者，也是获利者，总体而言，大家能够通过提高用户体验和点击深度实现共赢。与此同时，可以利用微博和其他社会网络的活动提高商品推荐的精度，还可以反过来利用商品浏览历史提高微博关注对象推荐的精度。给一个经常购买专业羽毛球和浏览各种专业羽毛球设备的用户推荐关注羽毛球的专业选手和业余教练成功率应该很高，而且不会陷入“总在一个圈子里面来回推荐”的毛病中。 从机器学习的角度，杨强等人提出的“迁移学习”算法有望移植来解决这种跨邻域的推荐[50]。我们分析了百分点科技服务客户的真实数据，发现有相当比例的用户都具有交叉购物的习惯（在多个独立 B2C 电商有浏览和购买行为）[51,52]。即便只考虑两个点上，例如利用麦包包的浏览购买数据为名鞋库的用户进行个性化推荐（这些用户在名鞋库上是没有任何历史记录的新用户，但是在麦包包上有浏览购买行为），就可以明显提高推荐的准确度[51]（比完全冷启动的随机推荐高数十倍），而如果利用 3 家或以上的外部电商的数据，其推荐的精确度可以明显高于热销榜（注意，热销榜一点个性化都没有），特别在团购类网站上表现非常好[52]。虽然针对多维数据挖掘的研究刚刚起步，但是我完全相信这在学术和应用上都将是一个焦点和难点。</p></blockquote><h2 id="挑战十：-社会推荐"><a href="#挑战十：-社会推荐" class="headerlink" title="挑战十： 社会推荐"></a>挑战十： 社会推荐</h2><blockquote><p>很早以前，研究人员就发现，用户更喜欢来自朋友的推荐而不是被系统“算出来的推荐”[53]。社会影响力被认为比历史行为的相似性更加重要[54,55]，例如通过社会关系的分析，可以大幅度提高从科研文献[56]到网购商品[57]推荐的精确度。来自朋友的社会推荐有两方面的效果：一是增加销售（含下载、阅读……）[58]，二是在销售后提高用户的评价[59]。社会推荐的效果也不完全是正面的，譬如 Leskovec 等人[58]在同一篇论文中也报导了一个反例：朋友推荐对书的销售增长几乎没有帮助，有时候还会起到负面作用。国内业界做得最出色的是豆瓣网，其朋友推荐被接受被高度评价的比例非常高，我们的研究也主要是基于豆瓣网的数据[59]。最近有证据显示，朋友推荐也是淘宝商品销售一个非常重要的驱动力量[60]。在社会推荐方向存在的挑战主要可以分为三类：一是如何利用社会关系提高推荐的精确度[55]，二是如何建立更好的机制以促进社会推荐[61,62]，三是如何将社会信任关系引入到推荐系统中[63,64]。社会推荐的效果可能来自于类似口碑传播的社会影响力，也可能是因为朋友之间本来就具有相似的兴趣或者兴趣相投更易成为朋友，对这些不同的潜在因素进行量化区别，也属学术研究的热点之一[65]。</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Shadowsocks使用教程</title>
      <link href="/2019/04/13/shadowsocks-shi-yong-jiao-cheng/"/>
      <url>/2019/04/13/shadowsocks-shi-yong-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<h1 id="Shadowsocks-翻墙使用教程-适用于-Windows-和-Android-版"><a href="#Shadowsocks-翻墙使用教程-适用于-Windows-和-Android-版" class="headerlink" title="Shadowsocks 翻墙使用教程(适用于 Windows 和 Android 版)"></a>Shadowsocks 翻墙使用教程(适用于 Windows 和 Android 版)</h1><h2 id="1-Windows-教程"><a href="#1-Windows-教程" class="headerlink" title="1. Windows 教程"></a>1. Windows 教程</h2><h3 id="1-1-添加订阅地址（删除原有的）"><a href="#1-1-添加订阅地址（删除原有的）" class="headerlink" title="1.1 添加订阅地址（删除原有的）"></a>1.1 添加订阅地址（删除原有的）</h3><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1g21443zcpqj30h707lq2y.jpg" alt="1"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1g21443zczrj30n20d40sy.jpg" alt="2"></p><h3 id="1-2-更新订阅地址"><a href="#1-2-更新订阅地址" class="headerlink" title="1.2 更新订阅地址"></a>1.2 更新订阅地址</h3><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1g21443zuqzj30hy07h3yj.jpg" alt="3"></p><h3 id="1-3-常用软件设置"><a href="#1-3-常用软件设置" class="headerlink" title="1.3 常用软件设置"></a>1.3 常用软件设置</h3><ul><li>不需要翻墙的话可以选择直连模式，这样不会消耗服务器流量，PAC 模式据说会自动代理，但是不一定</li></ul><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1g21443y4ouj30fr04yt8n.jpg" alt="4"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1g21443zpjwj30kc0fwdg6.jpg" alt="5"></p><h3 id="1-4-选择服务器"><a href="#1-4-选择服务器" class="headerlink" title="1.4 选择服务器"></a>1.4 选择服务器</h3><ul><li>有个软件默认设置的服务器可以删除掉</li></ul><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1g214440ybhj30pq0qnq4m.jpg" alt="6"></p><h3 id="1-5-访问测试"><a href="#1-5-访问测试" class="headerlink" title="1.5 访问测试"></a>1.5 访问测试</h3><ul><li><a href="https://www.google.com.hk/" target="_blank" rel="noopener">https://www.google.com.hk/</a></li></ul><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1g214441mstj31h70m9mxk.jpg" alt="7"></p><h2 id="2-Android-教程"><a href="#2-Android-教程" class="headerlink" title="2. Android 教程"></a>2. Android 教程</h2><h3 id="2-1-添加订阅地址"><a href="#2-1-添加订阅地址" class="headerlink" title="2.1 添加订阅地址"></a>2.1 添加订阅地址</h3><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1g2144478jlj30u01rcjv6.jpg" alt="8"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1g214445c3aj30u01rcju9.jpg" alt="9"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1g214me9dzmj30u01rc0um.jpg" alt="10"></p><h3 id="2-2-关闭自动更新，然后点击确定并升级"><a href="#2-2-关闭自动更新，然后点击确定并升级" class="headerlink" title="2.2 关闭自动更新，然后点击确定并升级"></a>2.2 关闭自动更新，然后点击确定并升级</h3><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1g214444ykjj30gq0zaaax.jpg" alt="11"></p><h3 id="2-3-选择服务器后，退回主界面，点击闪电按钮启动即可"><a href="#2-3-选择服务器后，退回主界面，点击闪电按钮启动即可" class="headerlink" title="2.3 选择服务器后，退回主界面，点击闪电按钮启动即可"></a>2.3 选择服务器后，退回主界面，点击闪电按钮启动即可</h3><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1g21444b35pj30u01rc46f.jpg" alt="12"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 翻墙 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>个人健康技术</title>
      <link href="/2019/04/06/ge-ren-jian-kang-ji-zhu/"/>
      <url>/2019/04/06/ge-ren-jian-kang-ji-zhu/</url>
      
        <content type="html"><![CDATA[<h1 id="个人健康技术-PPT"><a href="#个人健康技术-PPT" class="headerlink" title="个人健康技术 PPT"></a>个人健康技术 PPT</h1><hr><p><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsqgd6gj30zk0k03yn.jpg" alt="1"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsqenoaj30zk0k0jrm.jpg" alt="2"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsqj9paj30zk0k0agg.jpg" alt="3"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsqgvu8j30zk0k0js7.jpg" alt="4"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsqg65mj30zk0k03z5.jpg" alt="5"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsqjm50j30zk0k0n2q.jpg" alt="6"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsqk0unj30zk0k0wf3.jpg" alt="7"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsqvxj4j30zk0k0agk.jpg" alt="8"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsqmxx9j30zk0k0taf.jpg" alt="9"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsqlofmj30zk0k0ta2.jpg" alt="10"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsqyalpj30zk0k0wfo.jpg" alt="11"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsr9ym3j30zk0k0q8g.jpg" alt="12"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsqxri3j30zk0k0myz.jpg" alt="13"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsrbh0ij30zk0k0jt5.jpg" alt="14"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsrctv9j30zk0k0406.jpg" alt="15"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsrb049j30zk0k0wfq.jpg" alt="16"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsrcjgej30zk0k075o.jpg" alt="17"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsrbzc1j30zk0k0dgy.jpg" alt="18"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1swsrdg80j30zk0k0a9w.jpg" alt="19"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 软件产品线 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>超新星发现</title>
      <link href="/2019/03/20/chao-xin-xing-fa-xian/"/>
      <url>/2019/03/20/chao-xin-xing-fa-xian/</url>
      
        <content type="html"><![CDATA[<h1 id="2019-未来杯高校-AI-挑战赛-gt-图像-发现超新星"><a href="#2019-未来杯高校-AI-挑战赛-gt-图像-发现超新星" class="headerlink" title="2019 未来杯高校 AI 挑战赛 &gt; 图像-发现超新星"></a>2019 未来杯高校 AI 挑战赛 &gt; 图像-发现超新星</h1><h2 id="1-任务目标"><a href="#1-任务目标" class="headerlink" title="1. 任务目标"></a>1. 任务目标</h2><pre><code>设计一个目标检测模型，从天文望远镜拍摄到的影像中发现疑似新星、超新星。</code></pre><h2 id="2-规则说明"><a href="#2-规则说明" class="headerlink" title="2. 规则说明"></a>2. 规则说明</h2><pre><code>参赛选手需要基于给定的数据集，设计并训练模型，用于检测PSP项目中天文望远镜拍摄到的影像中的疑似星体，排除噪点和鬼影。测试集中包含志愿者对坐标中心点的标注，以及高级用户对此标注的进一步分类标注。包含 疑似星体 和 非疑似星体，详见“数据集”页面。疑似星体包括高级用户标注为：已知的疑似超新星（known）、新发现的疑似超新星（newtarget）、变星或疑似变星（isnova）、恒星（isstar）、小行星（asteroid）。非疑似星体包括高级用户标注为：噪点（noise）、鬼影（ghost）、无可疑目标（pity）。每组包含三张照片，分别为新图、历史图，和这两张图片的差值图像。</code></pre><h2 id="3-测试集发放与结果提交"><a href="#3-测试集发放与结果提交" class="headerlink" title="3. 测试集发放与结果提交"></a>3. 测试集发放与结果提交</h2><pre><code>测试集会于约定时间开放给选手，选手需要在提交截止时间前提交正式数据集的验证结果、模型和代码，详见“结果提交”页面。每队选手有3次提交机会，取最好成绩作为客观成绩。</code></pre><ul><li>测试集 csv 格式如下：</li></ul><pre><code>idd52f52b895f03a214a3a077acd2530660b1685708bdf8bf82f1ffce8705b109b732c55c0629a016be567c5fe76d3cf9606bb4bc28935b60334153e7e8a5a06fd530099dd7961f5341f66d8cdcb89269b9e9b6fd78b5240058f5f6db837a16d48412375a90b92dd4c71d1245b5332c1341bfe2a17b1827a9eea1b5f2610aa7026f5796ac41ed58be966f253b59a83419f...</code></pre><ul><li>结果需要提交 csv 文件，格式要求如下：</li></ul><pre><code>id,x1,y1,x2,y2,x3,y3,havestard52f52b895f03a214a3a077acd253066,123,321,55,66,222,222,10b1685708bdf8bf82f1ffce8705b109b,234,432,77,88,111,111,0732c55c0629a016be567c5fe76d3cf96,123,321,55,66,222,222,106bb4bc28935b60334153e7e8a5a06fd,234,432,77,88,111,111,1530099dd7961f5341f66d8cdcb89269b,123,321,55,66,222,222,09e9b6fd78b5240058f5f6db837a16d48,123,321,55,66,222,222,0412375a90b92dd4c71d1245b5332c134,123,321,55,66,222,222,01bfe2a17b1827a9eea1b5f2610aa7026,123,321,55,66,222,222,1f5796ac41ed58be966f253b59a83419f,123,321,55,66,222,222,1...</code></pre><pre><code>其中，每组图片一行，(x1, y1)、(x2, y2)、(x3, y3) 为对应id所代表图片组的三对预测坐标（疑似星体的几何中心），按置信度由高到低排序，以图片左上角为(0,0)计算。havestar使用0/1表示，代表这组图片中是否存在星体的判断，1代表存在，0代表不存在。</code></pre><h2 id="4-计分方式"><a href="#4-计分方式" class="headerlink" title="4. 计分方式"></a>4. 计分方式</h2><pre><code>每组照片，选手提交的三个预测结果的坐标中，任一个与实际星体所在坐标欧几里得距离在15px之内的，即为预测成功。预测成功得1分，不成功得0分。每组照片，选手还需提交对图片中是否存在星体的判断（havestar），将作为次要的辅助计分因素。本次区域赛的目的是，可以为需要标注的图片提供参考，以提高人工看图的效率。所以，计分以预测坐标的命中率为主，命中率相同的，以疑似星体判断的F1值决定排名。计分公式如下：</code></pre><p><img src="https://ai.futurelab.tv/storage/app/media/formula/formula-cv-1.png" alt="1" title="1"></p><pre><code>S为最终得分，N表示存在疑似星体的图片组数，ti表示是否有预测正确的坐标，有为1，没有为0。其中：</code></pre><p><img src="https://ai.futurelab.tv/storage/app/media/formula/formula-cv-0.png" alt="2" title="2"></p><pre><code>F1为F1-score，即精确率和召回率的调和平均数（在0-1之间）。</code></pre><h2 id="5-测试集发放与结果提交"><a href="#5-测试集发放与结果提交" class="headerlink" title="5. 测试集发放与结果提交"></a>5. 测试集发放与结果提交</h2><pre><code>预测试集TestA会先行开放，提供给参赛选手调试程序和验证模型。TestA的结果可提交至竞赛平台，获取跑分，但不计入比赛成绩。正式测试集TestB会于约定时间开放给选手，选手需要在72小时内提交正式数据集的验证结果、模型和代码，详见“结果提交”页面。每队选手有3次提交机会，取最好成绩作为客观成绩。</code></pre><h2 id="6-比赛要求"><a href="#6-比赛要求" class="headerlink" title="6. 比赛要求"></a>6. 比赛要求</h2><ul><li>参赛选手需要同时提交说明文档、预测结果、训练和预测代码、模型（参数集），详见“结果提交”页面。</li><li>参赛选手所提交程序应可在 Linux 环境顺利运行。建议（不强制）使用 Python 2.7 或 Python3.6 作为首选编程环境，使用 Anaconda 3 搭建软件环境。不限制第三方软件包使用，但须获得合法授权和软件拷贝，以确保主办方可以复现程序运行过程。</li><li>参赛选手提交的程序须满足输入输出的要求，参见“结果提交”页面。</li><li>参数选手的提交物需要可完整复现训练和预测过程，主办方不会做任何代码修改，如无法复现的，视作无效提交。</li><li>参赛选手可以使用公开开源的预训练模型，需要提供相关下载地址。</li><li>不得使用提供的数据集之外的数据训练模型。</li><li>不得将自行手工标注的结果运用于训练和测试。</li></ul><h2 id="7-参赛网址"><a href="#7-参赛网址" class="headerlink" title="7. 参赛网址"></a>7. 参赛网址</h2><blockquote><p><a href="https://ai.futurelab.tv/contest_detail/1" target="_blank" rel="noopener">https://ai.futurelab.tv/contest_detail/1</a></p></blockquote><h2 id="8-背景知识介绍"><a href="#8-背景知识介绍" class="headerlink" title="8. 背景知识介绍"></a>8. 背景知识介绍</h2><blockquote><p><a href="http://psp.china-vo.org/article/sysaquiz1intro" target="_blank" rel="noopener">http://psp.china-vo.org/article/sysaquiz1intro</a></p></blockquote><h2 id="9-数据分析（未经允许不得转载）"><a href="#9-数据分析（未经允许不得转载）" class="headerlink" title="9. 数据分析（未经允许不得转载）"></a>9. 数据分析（未经允许不得转载）</h2><p><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq4bqraj30zk0k0mxz.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq49w3hj30zk0k0aaf.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq4hghzj30zk0k0afn.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq4cnwij30zk0k0mzp.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq4duusj30zk0k0juv.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq4fzv7j30zk0k0acl.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq4mrlaj30zk0k0adb.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq4h169j30zk0k00t6.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq565g9j30zk0k00w0.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq65lb3j30zk0k0tcx.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq6ai5pj30zk0k0dkv.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq7hssyj30zk0k0n17.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq5cp5jj30zk0k0764.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq5dfc5j30zk0k0aaf.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq624frj30zk0k0di7.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq6ey3rj30zk0k0dje.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq69nioj30zk0k0tas.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq6h573j30zk0k076o.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq6larnj30zk0k043q.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq6gyayj30zk0k0q3d.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq74cfcj30zk0k0adr.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq76p09j30zk0k0gov.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq7deesj30zk0k0413.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq6zla4j30zk0k0wfu.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beqboc69j30zk0k0acd.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq73pf4j30zk0k03yv.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq83yqcj30zk0k0dkg.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq878oaj30zk0k0gpp.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq7ioqej30zk0k0mxj.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq86z4vj30zk0k0q6r.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq84sykj30zk0k0n0m.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq87t5jj30zk0k0aaf.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq8o2z1j30zk0k0jtm.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq8o781j30zk0k076f.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq8bzp0j30zk0k0wew.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq8t4hgj30zk0k0tbx.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1beq9ham6j30zk0k0gp8.jpg" alt=""></p>]]></content>
      
      
      
        <tags>
            
            <tag> 比赛 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>推荐系统系列论文整理</title>
      <link href="/2019/03/14/tui-jian-xi-tong-lun-wen-zheng-li/"/>
      <url>/2019/03/14/tui-jian-xi-tong-lun-wen-zheng-li/</url>
      
        <content type="html"><![CDATA[<p><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jainwzdwj30zk0k0gm8.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jainwrqlj30zk0k074r.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jainxigtj30zk0k0abd.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jainwtqij30zk0k0gm5.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jainzfsyj30zk0k0n18.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jainzazqj30zk0k0wgm.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jainzfhlj30zk0k0jsn.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jainytavj30zk0k0aay.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jainzt2hj30zk0k0q56.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaio1d8ij30zk0k0q5o.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaio32ioj30zk0k0ta9.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaio2y2mj30zk0k0gnx.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaiomqd9j30zk0k03z4.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaioc93fj30zk0k0mzw.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaioxu9pj30zk0k0420.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaip7sclj30zk0k0goa.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaiov97xj30zk0k0djj.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaipw97wj30zk0k0dj1.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaioxgw2j30zk0k0q5y.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaipj64hj30zk0k041m.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaip1czdj30zk0k041f.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaipuh8tj30zk0k0god.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaipldgtj30zk0k0win.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaiqpz12j30zk0k0gqz.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaipcmcoj30zk0k0aah.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaiq6xe3j30zk0k0wh2.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jair1tflj30zk0k0q67.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jair5p5uj30zk0k0jtt.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaiq84njj30zk0k076l.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaiqy7amj30zk0k0411.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaiqb1k0j30zk0k075j.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaiqx4ykj30zk0k0juu.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaiqvfy3j30zk0k0go0.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jaiqvitqj30zk0k0q4y.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jairaiwuj30zk0k0ack.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jairb3y1j30zk0k00wq.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/006wCagogy1g2jair9c8ij30zk0k0aac.jpg" alt=""></p>]]></content>
      
      
      
        <tags>
            
            <tag> 推荐系统 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Graph Neural Networks for Social Recommendation</title>
      <link href="/2019/03/13/graph-neural-networks-for-social-recommendation/"/>
      <url>/2019/03/13/graph-neural-networks-for-social-recommendation/</url>
      
        <content type="html"><![CDATA[<h1 id="Graph-Neural-Networks-for-Social-Recommendation"><a href="#Graph-Neural-Networks-for-Social-Recommendation" class="headerlink" title="Graph Neural Networks for Social Recommendation"></a>Graph Neural Networks for Social Recommendation</h1><h2 id="1-摘要"><a href="#1-摘要" class="headerlink" title="1. 摘要"></a>1. 摘要</h2><ul><li><strong>构建基于图神经网络的推荐系统的三大挑战</strong><ul><li>the user-item graph encodes both interactions and their associated opinions</li><li>social relations have heterogeneous strengths</li><li>users involve in two graphs (e.g., the user-user social graph and the user-item graph)</li></ul></li></ul><h2 id="2-介绍"><a href="#2-介绍" class="headerlink" title="2. 介绍"></a>2. 介绍</h2><ul><li><p><strong>难点</strong></p><ul><li>Their main idea is how to iteratively aggregate feature information from local graph neighborhoods using neural networks. Meanwhile, node information can be propagated through a graph after transformation and aggregation.</li></ul></li><li><p><strong>GNN 的作用</strong></p><ul><li>Hence, GNNs naturally integrate the node information as well as the topological structure and have been demonstrated to be powerful in representation learning [ 5 , 7 , 15 ]. On the other hand, data in social recommendation can be represented as graph data with two graphs.</li></ul></li></ul><h2 id="3-本文模型"><a href="#3-本文模型" class="headerlink" title="3. 本文模型"></a>3. 本文模型</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1g10b2rj8ulj31dq0ttqdl.jpg" alt="model"></p><h3 id="3-1-用户模型"><a href="#3-1-用户模型" class="headerlink" title="3.1 用户模型"></a>3.1 用户模型</h3><h4 id="3-1-1-Item-Aggregation"><a href="#3-1-1-Item-Aggregation" class="headerlink" title="3.1.1 Item Aggregation"></a>3.1.1 Item Aggregation</h4><blockquote><p>The purpose of item aggregation is to learn item-space user latent factor $h_{i}^{I}$ by considering items a user $u_{i}$ has interacted with and users’ opinions on these items.</p></blockquote><script type="math/tex; mode=display">h^{I}_{i} = σ(W · Aggre_{items} ({x_{ia} ,∀a ∈ C(i)}) + b)</script><ul><li>$h^{I}_{i}$: item-space user latent factor</li><li>$C(i)$: item-space user latent factor</li><li>$x_{ia}$: a representation vector to denote opinion-aware interaction between $u_{i}$ and an item $v_{a}$</li></ul><blockquote><p>The output of MLP is the opinion-aware representation of the interaction between $u_{i}$ and $v_{a}$,$x_{ia}$, as follows:</p></blockquote><script type="math/tex; mode=display">x_{ia} = g_{v}([q_{a}⊕e_{r}])</script><h4 id="3-1-2-Social-Aggregation"><a href="#3-1-2-Social-Aggregation" class="headerlink" title="3.1.2 Social Aggregation"></a>3.1.2 Social Aggregation</h4><blockquote><p>与 Item Aggregation 做法类似</p></blockquote><h3 id="3-2-项目模型"><a href="#3-2-项目模型" class="headerlink" title="3.2 项目模型"></a>3.2 项目模型</h3><h4 id="3-2-1-User-Aggregation"><a href="#3-2-1-User-Aggregation" class="headerlink" title="3.2.1 User Aggregation"></a>3.2.1 User Aggregation</h4><blockquote><p>与 Item Aggregation 做法类似</p></blockquote><h3 id="3-3-预测评分"><a href="#3-3-预测评分" class="headerlink" title="3.3 预测评分"></a>3.3 预测评分</h3><blockquote><p>With the latent factors of users and items (i.e., $h_{i}$ and $z_{j}$ ), we can first concatenate them $[h_{i} ⊕ z_{j}]$ and then feed it into MLP for rating prediction as:</p></blockquote><script type="math/tex; mode=display">g_{1} = [h_{i}  ⊕ z_{j}]</script><script type="math/tex; mode=display">g_{2} = σ(W_{2} · g_{1} + b_{2})</script><script type="math/tex; mode=display">g_{l-1} = σ(W_{l} · g_{l-1} + b_{l})</script><script type="math/tex; mode=display">r^{′}_{ij} = w^{T} · g_{l−1}</script><ul><li>where l is the index of a hidden layer, and $r^{′}_{ij}$ is the predicted rating from $u_{i}$ to $v_{j}$.</li></ul><h3 id="3-4-模型训练"><a href="#3-4-模型训练" class="headerlink" title="3.4 模型训练"></a>3.4 模型训练</h3><blockquote><p><strong>Loss function as follows:</strong></p></blockquote><script type="math/tex; mode=display">Loss = \frac{1}{2|O|} \sum_{i,j∈O} (r^{′}_{ij} − r_{ij})^{2}</script><ul><li><p>where $|O|$ is the number of observed ratings , and $r_{ij}$ is the ground truth rating assigned by the user i on the item j.</p></li><li><p>Optimizer: RMSprop</p></li><li><p>Overfitting problem: Dropout</p></li></ul><h2 id="4-实验"><a href="#4-实验" class="headerlink" title="4. 实验"></a>4. 实验</h2><h3 id="4-1-数据集"><a href="#4-1-数据集" class="headerlink" title="4.1 数据集"></a>4.1 数据集</h3><ul><li>Ciao</li><li>Epinions</li></ul><h3 id="4-2-Baselines"><a href="#4-2-Baselines" class="headerlink" title="4.2 Baselines"></a>4.2 Baselines</h3><ul><li>PMF</li><li>SoRec</li><li>SoReg</li><li>SocialMF</li><li>TrustMF</li><li>NeuMF</li><li>DeepSoR</li><li>GCMC+SN</li></ul><h3 id="4-3-Result"><a href="#4-3-Result" class="headerlink" title="4.3 Result"></a>4.3 Result</h3><h4 id="4-3-1-Performance-Comparison-of-Recommender-Systems"><a href="#4-3-1-Performance-Comparison-of-Recommender-Systems" class="headerlink" title="4.3.1 Performance Comparison of Recommender Systems"></a>4.3.1 Performance Comparison of Recommender Systems</h4><p><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g11961foh9j31890e3n0y.jpg" alt="1"></p><h4 id="4-3-2-Model-Analysis"><a href="#4-3-2-Model-Analysis" class="headerlink" title="4.3.2 Model Analysis"></a>4.3.2 Model Analysis</h4><ul><li>Effect of Social Network and User Opinions</li><li>Effect of Attention Mechanisms</li><li>Effect of Embedding Size</li></ul><p><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g119615jtbj31d00e8wgt.jpg" alt="2"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g119615b4uj31cl0ehju7.jpg" alt="3"><br><img src="https://ws1.sinaimg.cn/large/0061Dw64gy1g1196167voj31c90ek772.jpg" alt="4"></p><h2 id="5-未来工作"><a href="#5-未来工作" class="headerlink" title="5. 未来工作"></a>5. 未来工作</h2><ul><li>探索用户和项目之间的更丰富、复杂的属性</li><li>考虑评分和社交关系的动态性</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 图神经网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2019消费者人群画像—信用智能评分竞赛</title>
      <link href="/2019/03/12/2019-xiao-fei-zhe-ren-qun-hua-xiang-xin-yong-zhi-neng-ping-fen-jing-sai/"/>
      <url>/2019/03/12/2019-xiao-fei-zhe-ren-qun-hua-xiang-xin-yong-zhi-neng-ping-fen-jing-sai/</url>
      
        <content type="html"><![CDATA[<h1 id="消费者人群画像—信用智能评分竞赛"><a href="#消费者人群画像—信用智能评分竞赛" class="headerlink" title="消费者人群画像—信用智能评分竞赛"></a>消费者人群画像—信用智能评分竞赛</h1><h2 id="1-比赛介绍"><a href="#1-比赛介绍" class="headerlink" title="1. 比赛介绍"></a>1. 比赛介绍</h2><ul><li><a href="https://www.datafountain.cn/competitions/337/details/data-evaluation" target="_blank" rel="noopener">https://www.datafountain.cn/competitions/337/details/data-evaluation</a></li></ul><h2 id="2-参考代码"><a href="#2-参考代码" class="headerlink" title="2. 参考代码"></a>2. 参考代码</h2><h3 id="Packages"><a href="#Packages" class="headerlink" title="Packages"></a>Packages</h3><pre class="line-numbers language-lang-python"><code class="language-lang-python"># -*- coding: utf-8 -*-import timeimport matplotlib.pyplot as pltimport seaborn as snsimport numpy as npimport pandas as pdimport lightgbm as lgbfrom sklearn.model_selection import StratifiedKFoldfrom sklearn.preprocessing import LabelEncoderimport xgboost as xgbfrom sklearn.model_selection import KFoldfrom sklearn.linear_model import BayesianRidgefrom sklearn.model_selection import RepeatedKFoldfrom sklearn.metrics import mean_absolute_errorplt.rcParams[u'font.sans-serif'] = ['simhei']  #用来正常显示中文标签plt.rcParams['axes.unicode_minus'] = False  #用来正常显示负号pd.set_option('display.max_columns', 100)  #显示最大列数import warningswarnings.filterwarnings("ignore")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Input-data"><a href="#Input-data" class="headerlink" title="Input data"></a>Input data</h3><pre class="line-numbers language-lang-python"><code class="language-lang-python">data_path = '../input/'train_data = pd.read_csv(data_path + 'train_dataset.csv')test_data = pd.read_csv(data_path + 'test_dataset.csv')sample_sub = pd.read_csv(data_path + 'submit_example.csv')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Pre-processing"><a href="#Pre-processing" class="headerlink" title="Pre-processing"></a>Pre-processing</h3><pre class="line-numbers language-lang-python"><code class="language-lang-python">x_cols = [col for col in train_data.columns if col not in ['信用分','用户编码']]labels = []values = []<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">x_cols<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>[&#39;用户实名制是否通过核实&#39;, &#39;用户年龄&#39;, &#39;是否大学生客户&#39;, &#39;是否黑名单客户&#39;, &#39;是否4G不健康客户&#39;, &#39;用户网龄（月）&#39;, &#39;用户最近一次缴费距今时长（月）&#39;, &#39;缴费用户最近一次缴费金额（元）&#39;, &#39;用户近6个月平均消费值（元）&#39;, &#39;用户账单当月总费用（元）&#39;, &#39;用户当月账户余额（元）&#39;, &#39;缴费用户当前是否欠费缴费&#39;, &#39;用户话费敏感度&#39;, &#39;当月通话交往圈人数&#39;, &#39;是否经常逛商场的人&#39;, &#39;近三个月月均商场出现次数&#39;, &#39;当月是否逛过福州仓山万达&#39;, &#39;当月是否到过福州山姆会员店&#39;, &#39;当月是否看电影&#39;, &#39;当月是否景点游览&#39;, &#39;当月是否体育场馆消费&#39;, &#39;当月网购类应用使用次数&#39;, &#39;当月物流快递类应用使用次数&#39;, &#39;当月金融理财类应用使用总次数&#39;, &#39;当月视频播放类应用使用次数&#39;, &#39;当月飞机类应用使用次数&#39;, &#39;当月火车类应用使用次数&#39;, &#39;当月旅游资讯类应用使用次数&#39;]</code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">#判断各列和信用分的相关性for col in x_cols:    labels.append(col)    values.append(        np.corrcoef(train_data[col].values, train_data['信用分'].values)[0, 1])corr_df = pd.DataFrame({'col_labels': labels, 'corr_values': values})corr_df = corr_df.sort_values(by='corr_values')ind = np.arange(len(labels))width = 0.5fig, ax = plt.subplots(figsize=(12, 60))rects = ax.barh(ind, np.array(corr_df.corr_values.values), color='y')ax.set_yticks(ind)ax.set_yticklabels(corr_df.col_labels.values, rotation='horizontal')ax.set_xlabel('Correlation coefficient')ax.set_title('Correlation coeficient of the variables')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Text(0.5,1,&#39;Correlation coeficient of the variables&#39;)</code></pre><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1g107dg69uvj30ng2k5myw.jpg" alt=""></p><pre class="line-numbers language-lang-python"><code class="language-lang-python">#密度曲线def plot_kde(data):    plt.figure(figsize=(8, 6))    data.plot(kind='kde')def plot_his(data):    plt.figure(figsize=(8, 6))    sns.distplot(data.values, bins=50, kde=False)plot_kde(train_data['信用分'])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1g107dg3uy3j30e409zdfw.jpg" alt=""></p><h3 id="Feature-Engineering"><a href="#Feature-Engineering" class="headerlink" title="Feature Engineering"></a>Feature Engineering</h3><pre class="line-numbers language-lang-python"><code class="language-lang-python"># top up amount, 充值金额是整数，和小数，应该对应不同的充值途径？def produce_offline_feature(train_data):    train_data['不同充值途径'] = 0    train_data['不同充值途径'][(train_data['缴费用户最近一次缴费金额（元）'] %                          10 == 0) & train_data['缴费用户最近一次缴费金额（元）'] != 0] = 1    return train_datatrain_data = produce_offline_feature(train_data)test_data = produce_offline_feature(test_data)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 看importance，当月话费 和最近半年平均话费都很高，算一下当月/半年 -->稳定性def produce_fee_rate(train_data):    train_data['当前费用稳定性'] = train_data['用户账单当月总费用（元）'] / \        (train_data['用户近6个月平均消费值（元）'] + 1)    # 当月话费/当月账户余额    train_data['用户余额比例'] = train_data['用户账单当月总费用（元）'] / \        (train_data['用户当月账户余额（元）'] + 1)    return train_datatrain_data = produce_offline_feature(train_data)test_data = produce_offline_feature(test_data)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 获取特征def get_features(data):    data.loc[data['用户年龄'] ==             0, '用户年龄'] = data['用户年龄'].mode()  # mode()选出一组数据中众数，这里改为平均值    data.loc[data['缴费用户最近一次缴费金额（元）'] ==             0, '缴费用户最近一次缴费金额（元）'] = data['缴费用户最近一次缴费金额（元）'].mode()    data['缴费金额是否能覆盖当月账单'] = data['缴费用户最近一次缴费金额（元）'] - data['用户账单当月总费用（元）']    data['最近一次缴费是否超过平均消费额'] = data['缴费用户最近一次缴费金额（元）'] - data['用户近6个月平均消费值（元）']    data['当月账单是否超过平均消费额'] = data['用户账单当月总费用（元）'] - data['用户近6个月平均消费值（元）']    # 映射年龄    def map_age(x):        if x <= 18:            return 1        elif x <= 30:            return 2        elif x <= 35:            return 3        elif x <= 45:            return 4        else:            return 5    data['是否大学生_黑名单'] = data['是否大学生客户'] + data['是否黑名单客户']    data['是否实名制_大学生'] = data['是否大学生客户'] + data['用户实名制是否通过核实']    data['是否实名制_大学生_黑名单'] = data['是否黑名单客户'] + data['用户实名制是否通过核实'] + data['是否大学生客户']    data['是否实名制_黑名单'] = data['是否黑名单客户'] + data['用户实名制是否通过核实']    data['是否去过高档商场'] = data['当月是否到过福州山姆会员店'] + data['当月是否逛过福州仓山万达']    data['是否去过高档商场'] = data['是否去过高档商场'].map(lambda x: 1 if x >= 1 else 0)    data['是否_商场_电影'] = data['是否去过高档商场'] * data['当月是否看电影']    data['是否_商场_体育馆'] = data['是否去过高档商场'] * data['当月是否体育场馆消费']    data['是否_商场_旅游'] = data['是否去过高档商场'] * data['当月是否景点游览']    data['是否_电影_体育馆'] = data['当月是否看电影'] * data['当月是否体育场馆消费']    data['是否_电影_旅游'] = data['当月是否看电影'] * data['当月是否景点游览']    data['是否_旅游_体育馆'] = data['当月是否景点游览'] * data['当月是否体育场馆消费']    data['是否_商场_旅游_体育馆'] = data['是否去过高档商场'] * data['当月是否景点游览'] * data[        '当月是否体育场馆消费']    data['是否_商场_电影_体育馆'] = data['是否去过高档商场'] * data['当月是否看电影'] * data[        '当月是否体育场馆消费']    data['是否_商场_电影_旅游'] = data['是否去过高档商场'] * data['当月是否看电影'] * data['当月是否景点游览']    data['是否_体育馆_电影_旅游'] = data['当月是否体育场馆消费'] * data['当月是否看电影'] * data[        '当月是否景点游览']    data['是否_商场_体育馆_电影_旅游'] = data['是否去过高档商场'] * \        data['当月是否体育场馆消费'] * data['当月是否看电影'] * data['当月是否景点游览']    discretize_features = [        '交通类应用使用次数', '当月物流快递类应用使用次数', '当月飞机类应用使用次数', '当月火车类应用使用次数',        '当月旅游资讯类应用使用次数'    ]    data['交通类应用使用次数'] = data['当月飞机类应用使用次数'] + data['当月火车类应用使用次数']    data['6个月平均占比总费用'] = data['用户近6个月平均消费值（元）'] / data['用户账单当月总费用（元）'] + 1    def map_discretize(x):        if x == 0:            return 0        elif x <= 5:            return 1        elif x <= 15:            return 2        elif x <= 50:            return 3        elif x <= 100:            return 4        else:            return 5    for col in discretize_features[:]:        data[col] = data[col].map(lambda x: map_discretize(x))    return datatrain_data = get_features(train_data)test_data = get_features(test_data)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">def base_process(data):    transform_value_feature = [        '用户年龄', '用户网龄（月）', '当月通话交往圈人数', '近三个月月均商场出现次数', '当月网购类应用使用次数',        '当月物流快递类应用使用次数', '当月金融理财类应用使用总次数', '当月视频播放类应用使用次数', '当月飞机类应用使用次数',        '当月火车类应用使用次数', '当月旅游资讯类应用使用次数'    ]    user_fea = [        '缴费用户最近一次缴费金额（元）', '用户近6个月平均消费值（元）', '用户账单当月总费用（元）', '用户当月账户余额（元）'    ]    log_features = [        '当月网购类应用使用次数', '当月金融理财类应用使用总次数', '当月物流快递类应用使用次数', '当月视频播放类应用使用次数'    ]    #处理离散点    for col in transform_value_feature + user_fea + log_features:        #取出最高99.9%值        ulimit = np.percentile(train_data[col].values, 99.9)        #取出最低0.1%值        llimit = np.percentile(train_data[col].values, 0.1)        train_data.loc[train_data[col] > ulimit, col] = ulimit        train_data.loc[train_data[col] < llimit, col] = llimit    for col in user_fea + log_features:        data[col] = data[col].map(lambda x: np.log1p(x))    return datatrain_data = base_process(train_data)test_data = base_process(test_data)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><pre class="line-numbers language-lang-python"><code class="language-lang-python">def display_importances(feature_importance_df_):    cols = feature_importance_df_[[        "feature", "importance"    ]].groupby("feature").mean().sort_values(        by="importance", ascending=False)[:40].index    best_features = feature_importance_df_.loc[        feature_importance_df_.feature.isin(cols)]    plt.figure(figsize=(8, 10))    sns.barplot(        x="importance",        y="feature",        data=best_features.sort_values(by="importance", ascending=False))    plt.title('LightGBM Features (avg over folds)')    plt.tight_layout()    plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">#paraparams1 = {    'learning_rate': 0.01,    'boosting_type': 'gbdt',    'objective': 'regression_l1',    'metric': 'mae',    'feature_fraction': 0.6,  #如果设置为 0.8, 将会在每棵树训练之前选择 80% 的特征    'bagging_fraction': 0.8,  # 它将在不进行重采样的情况下随机选择部分数据    'bagging_freq': 2,  #意味着每2次迭代执行bagging    'num_leaves': 31,    'verbose': -1,    'max_depth': 5,    'lambda_l2': 5,    'lambda_l1': 0,    'num_thread': 8}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">#paraparams2 = {    'learning_rate': 0.01,    'boosting_type': 'gbdt',    'objective': 'regression_l2',    'metric': 'mae',    'feature_fraction': 0.6,  #如果设置为 0.8, 将会在每棵树训练之前选择 80% 的特征    'bagging_fraction': 0.8,  # 它将在不进行重采样的情况下随机选择部分数据    'bagging_freq': 2,  #意味着每2次迭代执行bagging    'num_leaves': 31,    'verbose': -1,    'max_depth': 5,    'lambda_l2': 5,    'lambda_l1': 0,    'num_thread': 8}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">cv_pred_all1 = 0en_amount = 3oof_lgb1 = np.zeros(len(train_data))prediction_lgb1 = np.zeros(len(test_data))for seed in range(en_amount):    NFOLDS = 5    train_label = train_data['信用分']    kfold = KFold(n_splits=NFOLDS, shuffle=True, random_state=seed)    kf = kfold.split(train_data, train_label)    train_data_use = train_data.drop(['用户编码', '信用分'], axis=1)    test_data_use = test_data.drop(['用户编码'], axis=1)    cv_pred = np.zeros(test_data.shape[0])    valid_best_l2_all = 0    feature_importance_df = pd.DataFrame()    count = 0    for i, (train_fold, validate) in enumerate(kf):        print('fold: ', i, ' training')        X_train, X_validate, label_train, label_validate = \        train_data_use.iloc[train_fold, :], train_data_use.iloc[validate, :], \        train_label[train_fold], train_label[validate]        dtrain = lgb.Dataset(X_train, label_train)        dvalid = lgb.Dataset(X_validate, label_validate, reference=dtrain)        bst = lgb.train(            params1,            dtrain,            num_boost_round=10000,            valid_sets=dvalid,            verbose_eval=-1,            early_stopping_rounds=250)        cv_pred += bst.predict(test_data_use, num_iteration=bst.best_iteration)        valid_best_l2_all += bst.best_score['valid_0']['l1']        oof_lgb1[validate] = bst.predict(            X_validate, num_iteration=bst.best_iteration)        prediction_lgb1 += bst.predict(            test_data_use, num_iteration=bst.best_iteration) / kfold.n_splits        fold_importance_df = pd.DataFrame()        fold_importance_df["feature"] = list(X_train.columns)        fold_importance_df["importance"] = bst.feature_importance(            importance_type='split', iteration=bst.best_iteration)        fold_importance_df["fold"] = count + 1        feature_importance_df = pd.concat(            [feature_importance_df, fold_importance_df], axis=0)        count += 1    cv_pred /= NFOLDS    valid_best_l2_all /= NFOLDS    cv_pred_all1 += cv_predcv_pred_all1 /= en_amountprediction_lgb1 /= en_amountprint('cv score1 for valid is: ', 1 / (1 + valid_best_l2_all))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>fold:  0  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[3874]    valid_0&#39;s l1: 14.7271fold:  1  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[3908]    valid_0&#39;s l1: 14.7613fold:  2  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[3308]    valid_0&#39;s l1: 14.5285fold:  3  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[5434]    valid_0&#39;s l1: 14.5385fold:  4  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[3310]    valid_0&#39;s l1: 14.73fold:  0  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[3939]    valid_0&#39;s l1: 14.6399fold:  1  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[2806]    valid_0&#39;s l1: 14.6524fold:  2  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[4375]    valid_0&#39;s l1: 14.5624fold:  3  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[4439]    valid_0&#39;s l1: 14.7281fold:  4  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[4375]    valid_0&#39;s l1: 14.7686fold:  0  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[4424]    valid_0&#39;s l1: 14.7947fold:  1  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[5509]    valid_0&#39;s l1: 14.8132fold:  2  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[2970]    valid_0&#39;s l1: 14.4896fold:  3  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[4146]    valid_0&#39;s l1: 14.6055fold:  4  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[3937]    valid_0&#39;s l1: 14.5792cv score1 for valid is:  0.06387148777659804</code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">cv_pred_all2 = 0en_amount = 3oof_lgb1 = np.zeros(len(train_data))prediction_lgb2 = np.zeros(len(test_data))for seed in range(en_amount):    NFOLDS = 5    train_label = train_data['信用分']    kfold = KFold(n_splits=NFOLDS, shuffle=True, random_state=seed)    kf = kfold.split(train_data, train_label)    train_data_use = train_data.drop(['用户编码', '信用分'], axis=1)    test_data_use = test_data.drop(['用户编码'], axis=1)    cv_pred = np.zeros(test_data.shape[0])    valid_best_l2_all = 0    feature_importance_df = pd.DataFrame()    count = 0    for i, (train_fold, validate) in enumerate(kf):        print('fold: ', i, ' training')        X_train, X_validate, label_train, label_validate = \        train_data_use.iloc[train_fold, :], train_data_use.iloc[validate, :], \        train_label[train_fold], train_label[validate]        dtrain = lgb.Dataset(X_train, label_train)        dvalid = lgb.Dataset(X_validate, label_validate, reference=dtrain)        bst = lgb.train(            params2,            dtrain,            num_boost_round=10000,            valid_sets=dvalid,            verbose_eval=-1,            early_stopping_rounds=250)        cv_pred += bst.predict(test_data_use, num_iteration=bst.best_iteration)        valid_best_l2_all += bst.best_score['valid_0']['l1']        oof_lgb1[validate] = bst.predict(            X_validate, num_iteration=bst.best_iteration)        prediction_lgb2 += bst.predict(            test_data_use, num_iteration=bst.best_iteration) / kfold.n_splits        fold_importance_df = pd.DataFrame()        fold_importance_df["feature"] = list(X_train.columns)        fold_importance_df["importance"] = bst.feature_importance(            importance_type='split', iteration=bst.best_iteration)        fold_importance_df["fold"] = count + 1        feature_importance_df = pd.concat(            [feature_importance_df, fold_importance_df], axis=0)        count += 1    cv_pred /= NFOLDS    valid_best_l2_all /= NFOLDS    cv_pred_all2 += cv_predcv_pred_all2 /= en_amountprediction_lgb2 /= en_amountprint('cv2 score for valid is: ', 1 / (1 + valid_best_l2_all))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>fold:  0  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[4423]    valid_0&#39;s l1: 14.7215fold:  1  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[3077]    valid_0&#39;s l1: 14.7534fold:  2  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[3277]    valid_0&#39;s l1: 14.5732fold:  3  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[4180]    valid_0&#39;s l1: 14.5316fold:  4  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[3139]    valid_0&#39;s l1: 14.7765fold:  0  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[2928]    valid_0&#39;s l1: 14.5982fold:  1  trainingTraining until validation scores don&#39;t improve for 250 rounds.Early stopping, best iteration is:[2344]    valid_0&#39;s l1: 14.7204fold:  2  trainingTraining until validation scores don&#39;t improve for 250 rounds.</code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">display_importances(feature_importance_df)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="XGB-训练及预测"><a href="#XGB-训练及预测" class="headerlink" title="XGB 训练及预测"></a>XGB 训练及预测</h3><pre class="line-numbers language-lang-python"><code class="language-lang-python">xgb_params = {'eta': 0.005, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8,              'objective': 'reg:linear', 'eval_metric': 'mae', 'silent': True, 'nthread': 20}cv_pred_allxgb = 0en_amount = 3oof_xgb1 = np.zeros(len(train_data))prediction_xgb1 = np.zeros(len(test_data))for seed in range(en_amount):    NFOLDS = 5    train_label = train_data['信用分']    kfold = KFold(n_splits=NFOLDS, shuffle=True, random_state=seed+2019)    kf = kfold.split(train_data, train_label)    train_data_use = train_data.drop(['用户编码', '信用分'], axis=1)    test_data_use = test_data.drop(['用户编码'], axis=1)    cv_pred = np.zeros(test_data.shape[0])    valid_best_l2_all = 0    feature_importance_df = pd.DataFrame()    count = 0    for i, (train_fold, validate) in enumerate(kf):        print('fold: ', i, ' training')        X_train, X_validate, label_train, label_validate = train_data_use.iloc[train_fold,                                                                               :], train_data_use.iloc[validate, :], train_label[train_fold], train_label[validate]        dtrain = xgb.DMatrix(X_train, label_train)        dvalid = xgb.DMatrix(X_validate, label_validate)        watchlist = [(dtrain, 'train'), (dvalid, 'valid_data')]        bst = xgb.train(dtrain=dtrain, num_boost_round=10000, evals=watchlist,                        early_stopping_rounds=100, verbose_eval=300, params=xgb_params)        cv_pred += bst.predict(xgb.DMatrix(test_data_use),                               ntree_limit=bst.best_ntree_limit)        oof_xgb1[validate] = bst.predict(xgb.DMatrix(            X_validate), ntree_limit=bst.best_ntree_limit)        prediction_xgb1 += bst.predict(xgb.DMatrix(test_data_use),                                       ntree_limit=bst.best_ntree_limit)/kfold.n_splits        count += 1    cv_pred /= NFOLDS    cv_pred_allxgb += cv_predcv_pred_allxgb /= en_amount<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">prediction_xgb1 /= en_amountprediction_lgb_all = (prediction_lgb1 + prediction_lgb2) / 2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 将lgb和xgb的结果进行stackingtrain_stack = np.vstack([oof_lgb1, oof_xgb1]).transpose()test_stack = np.vstack([prediction_lgb_all, prediction_xgb1]).transpose()folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=2019)oof_stack = np.zeros(train_stack.shape[0])predictions = np.zeros(test_stack.shape[0])target = train_data['信用分']for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack, target)):    print("fold {}".format(fold_))    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values    clf_3 = BayesianRidge()    clf_3.fit(trn_data, trn_y)    oof_stack[val_idx] = clf_3.predict(val_data)    predictions += clf_3.predict(test_stack) / 10mean_absolute_error(target.values, oof_stack)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Submit"><a href="#Submit" class="headerlink" title="Submit"></a>Submit</h3><pre class="line-numbers language-lang-python"><code class="language-lang-python">test_data_sub1 = test_data[['用户编码']]test_data_sub1['score'] =  predictionstest_data_sub1.columns = ['id','score']# test_data_sub1['score1'] = (cv_pred_all1 + cv_pred_all2) / 2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">test_data_sub1.head()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">test_data_sub1['score'] = test_data_sub1['score'].apply(lambda x: int(np.round(x)))<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">test_data_sub1.head()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">test_data_sub1[['id','score']].to_csv('../output/result.csv', index=False)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>HyperOptSklearn调参</title>
      <link href="/2019/03/12/hyperoptsklearn-diao-can/"/>
      <url>/2019/03/12/hyperoptsklearn-diao-can/</url>
      
        <content type="html"><![CDATA[<h1 id="1-机器学习调参工具之HyperOptSklearn"><a href="#1-机器学习调参工具之HyperOptSklearn" class="headerlink" title="1. 机器学习调参工具之HyperOptSklearn"></a>1. 机器学习调参工具之HyperOptSklearn</h1><h2 id="1-1-示例代码："><a href="#1-1-示例代码：" class="headerlink" title="1.1 示例代码："></a>1.1 示例代码：</h2><pre class="line-numbers language-lang-python"><code class="language-lang-python">from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessingfrom sklearn.datasets import load_irisfrom hyperopt import tpeimport numpy as np<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre><code>WARN: OMP_NUM_THREADS=None =&gt;... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely</code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># Download the data and split into training and test setsiris = load_iris()X = iris.datay = iris.targettest_size = int(0.2 * len(y))np.random.seed(13)indices = np.random.permutation(len(X))X_train = X[indices[:-test_size]]y_train = y[indices[:-test_size]]X_test = X[indices[-test_size:]]y_test = y[indices[-test_size:]]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># Instantiate a HyperoptEstimator with the search space and number of evaluationsestim = HyperoptEstimator(classifier=any_classifier('my_clf'),                          preprocessing=any_preprocessing('my_pre'),                          algo=tpe.suggest,                          max_evals=100,                          trial_timeout=120)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># Search the hyperparameter space based on the dataestim.fit( X_train, y_train )<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>100%|██████████| 1/1 [00:00&lt;00:00,  1.59it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  2.03it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  8.80it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  1.28it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  3.07it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  7.68it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00, 12.13it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00, 12.90it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  9.88it/s, best loss: 0.04166666666666663]  0%|          | 0/1 [00:00&lt;?, ?it/s, best loss: ?]/home/hadoop/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.  DeprecationWarning)100%|██████████| 1/1 [00:00&lt;00:00, 13.00it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  2.57it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00, 13.18it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00, 12.58it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  9.96it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00, 15.72it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  1.13it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  8.16it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  2.33it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  9.97it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  6.35it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:02&lt;00:00,  2.89s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  9.30it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  5.56it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:02&lt;00:00,  2.29s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  1.43it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  6.32it/s, best loss: 0.04166666666666663]  0%|          | 0/1 [00:00&lt;?, ?it/s, best loss: ?]/home/hadoop/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.  DeprecationWarning)100%|██████████| 1/1 [00:00&lt;00:00,  6.31it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:03&lt;00:00,  3.20s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  5.44it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  6.14it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:03&lt;00:00,  3.01s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  2.74it/s, best loss: 0.04166666666666663]  0%|          | 0/1 [00:00&lt;?, ?it/s, best loss: ?]/home/hadoop/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.  DeprecationWarning)100%|██████████| 1/1 [00:00&lt;00:00,  8.37it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:03&lt;00:00,  3.17s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:01&lt;00:00,  1.19s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  9.40it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  9.44it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:01&lt;00:00,  1.41s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:01&lt;00:00,  1.89s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  9.26it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  6.86it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  2.03it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:01&lt;00:00,  1.19s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  9.23it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:01&lt;00:00,  1.15s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  6.60it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  2.46it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  8.91it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  4.77it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  9.09it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  5.77it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  1.56it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:01&lt;00:00,  1.10s/it, best loss: 0.04166666666666663]  0%|          | 0/1 [00:00&lt;?, ?it/s, best loss: ?]/home/hadoop/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.  DeprecationWarning)100%|██████████| 1/1 [00:00&lt;00:00,  7.84it/s, best loss: 0.04166666666666663]  0%|          | 0/1 [00:00&lt;?, ?it/s, best loss: ?]/home/hadoop/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.  DeprecationWarning)100%|██████████| 1/1 [00:00&lt;00:00,  6.07it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  6.03it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  3.08it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  6.88it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  3.65it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  6.19it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:02&lt;00:00,  2.11s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:01&lt;00:00,  1.03s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  2.00it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  4.24it/s, best loss: 0.04166666666666663]  0%|          | 0/1 [00:00&lt;?, ?it/s, best loss: ?]/home/hadoop/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.  DeprecationWarning)100%|██████████| 1/1 [00:00&lt;00:00,  8.10it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  6.05it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:02&lt;00:00,  2.37s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  4.22it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:01&lt;00:00,  1.32s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  6.87it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  5.92it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:01&lt;00:00,  1.34s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  1.85it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  4.07it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  5.56it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  9.04it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  6.60it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  8.98it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  8.93it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:01&lt;00:00,  1.00s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  9.08it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  1.30it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  9.02it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  4.11it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  6.58it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  8.87it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  7.09it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  5.95it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  7.00it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:01&lt;00:00,  1.31s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:01&lt;00:00,  1.54s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  1.34it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  1.93it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  3.88it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:01&lt;00:00,  1.48s/it, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:02&lt;00:00,  2.27s/it, best loss: 0.04166666666666663]  0%|          | 0/1 [00:00&lt;?, ?it/s, best loss: ?]/home/hadoop/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.  DeprecationWarning)100%|██████████| 1/1 [00:00&lt;00:00,  7.80it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  8.75it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  5.19it/s, best loss: 0.04166666666666663]100%|██████████| 1/1 [00:00&lt;00:00,  7.03it/s, best loss: 0.04166666666666663]</code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># Show the resultsprint(estim.score(X_test, y_test))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>1.0</code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">print( estim.best_model() )<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>{&#39;learner&#39;: ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion=&#39;gini&#39;,           max_depth=4, max_features=None, max_leaf_nodes=None,           min_impurity_decrease=0.0, min_impurity_split=None,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0.0, n_estimators=590, n_jobs=1,           oob_score=False, random_state=0, verbose=False,           warm_start=False), &#39;preprocs&#39;: (MinMaxScaler(copy=True, feature_range=(0.0, 1.0)),), &#39;ex_preprocs&#39;: ()}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>HyperOpt调参</title>
      <link href="/2019/03/12/hyperopt-diao-can/"/>
      <url>/2019/03/12/hyperopt-diao-can/</url>
      
        <content type="html"><![CDATA[<h1 id="1-机器学习调参工具之HyperOpt"><a href="#1-机器学习调参工具之HyperOpt" class="headerlink" title="1. 机器学习调参工具之HyperOpt"></a>1. 机器学习调参工具之HyperOpt</h1><h2 id="1-1-示例代码："><a href="#1-1-示例代码：" class="headerlink" title="1.1 示例代码："></a>1.1 示例代码：</h2><pre class="line-numbers language-lang-python"><code class="language-lang-python">from hyperopt import hp, fmin, rand, tpe, space_eval, anneal, partial<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 定义目标函数def q (args) :    x, y = args    return x ** 2 + y ** 2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 定义参数空间space = [hp.uniform('x', 0, 1), hp.normal('y', 0, 1)]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 指定搜索算法# algo指定搜索算法，目前支持以下算法：# ①随机搜索(hyperopt.rand.suggest)# ②模拟退火(hyperopt.anneal.suggest)# ③TPE算法（hyperopt.tpe.suggest，算法全称为Tree-structured Parzen Estimator Approach）algo = partial(anneal.suggest,)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 寻找最佳匹配的space,使fn的函数返回值最小best = fmin(q, space, algo=algo,max_evals=100)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>100%|██████████| 100/100 [00:00&lt;00:00, 1026.67it/s, best loss: 7.504195016189939e-06]</code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">print(best)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>{&#39;x&#39;: 0.002299082182183151, &#39;y&#39;: 0.0014894348377011664}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Tensorflow学习笔记</title>
      <link href="/2019/02/20/tensorflow-xue-xi-bi-ji/"/>
      <url>/2019/02/20/tensorflow-xue-xi-bi-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="Tensorflow-学习笔记"><a href="#Tensorflow-学习笔记" class="headerlink" title="Tensorflow 学习笔记"></a>Tensorflow 学习笔记</h1><h2 id="1-设置tensorflow输出日志级别"><a href="#1-设置tensorflow输出日志级别" class="headerlink" title="1. 设置tensorflow输出日志级别"></a>1. 设置tensorflow输出日志级别</h2><pre class="line-numbers language-lang-python"><code class="language-lang-python">import osos.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="2-tf-argmax-函数"><a href="#2-tf-argmax-函数" class="headerlink" title="2. tf.argmax()函数"></a>2. tf.argmax()函数</h2><pre class="line-numbers language-lang-python"><code class="language-lang-python">A = [[1, 3, 4, 5, 6]]B = [[1, 3, 4], [2, 4, 1]]# tf.argmax(y_, 1) 取的是行的最大值对应的下标的索引# tf.argmax(y_, 0) 取的是列的最大值对应的下标的索引with tf.Session() as sess:    print(sess.run(tf.argmax(A, 1)))    print(sess.run(tf.argmax(B, 0)))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行结果：</p><pre><code>[4][1 1 0]</code></pre><h2 id="3-tf-reduce-mean-函数"><a href="#3-tf-reduce-mean-函数" class="headerlink" title="3. tf.reduce_mean() 函数"></a>3. tf.reduce_mean() 函数</h2><ul><li>函数用于计算张量tensor沿着指定的数轴（tensor的某一维度）上的的平均值，主要用作降维或者计算tensor（图像）的平均值。</li></ul><pre class="line-numbers language-lang-python"><code class="language-lang-python">reduce_mean(input_tensor,                axis=None,                keep_dims=False,                name=None,                reduction_indices=None)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>第一个参数input_tensor： 输入的待降维的tensor;</li><li>第二个参数axis： 指定的轴，如果不指定，则计算所有元素的均值;</li><li>第三个参数keep_dims：是否降维度，设置为True，输出的结果保持输入tensor的形状，设置为False，输出结果会降低维度;</li><li>第四个参数name： 操作的名称;</li><li>第五个参数 reduction_indices：在以前版本中用来指定轴，已弃用;</li></ul><h2 id="4-滑动平均-ExponentialMovingAverage"><a href="#4-滑动平均-ExponentialMovingAverage" class="headerlink" title="4. 滑动平均-ExponentialMovingAverage()"></a>4. 滑动平均-ExponentialMovingAverage()</h2><ul><li>神经网络的优化函数</li></ul><pre class="line-numbers language-lang-python"><code class="language-lang-python">tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="5-variables-to-restore-函数"><a href="#5-variables-to-restore-函数" class="headerlink" title="5. variables_to_restore()函数"></a>5. variables_to_restore()函数</h2><blockquote><p>是TensorFlow为滑动平均值提供。之前，也介绍过通过使用滑动平均值可以让神经网络模型更加的健壮。我们也知道，其实在TensorFlow中，变量的滑动平均值都是由影子变量所维护的，如果你想要获取变量的滑动平均值需要获取的是影子变量而不是变量本身。</p></blockquote><pre class="line-numbers language-lang-python"><code class="language-lang-python">variable_averages = tf.train.ExponentialMovingAverage(mnist_train.MOVING_AVERAGE_DECAY)variables_to_restore = variable_averages.variables_to_restore()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Tensorflow </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>GNN论文列表</title>
      <link href="/2019/02/15/gnn-lun-wen-lie-biao/"/>
      <url>/2019/02/15/gnn-lun-wen-lie-biao/</url>
      
        <content type="html"><![CDATA[<h2 id="Must-read-papers-on-GNN"><a href="#Must-read-papers-on-GNN" class="headerlink" title="Must-read papers on GNN"></a>Must-read papers on GNN</h2><p>GNN: graph neural network</p><p>Contributed by Jie Zhou, Ganqu Cui and Zhengyan Zhang.</p><h3 id="Survey-papers"><a href="#Survey-papers" class="headerlink" title="Survey papers"></a>Survey papers</h3><ol><li><p><strong>Graph Neural Networks: A Review of Methods and Applications.</strong><br><em>Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Maosong Sun.</em> 2018. <a href="https://arxiv.org/pdf/1812.08434.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>A Comprehensive Survey on Graph Neural Networks.</strong><br><em>Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, Philip S. Yu.</em> 2019. <a href="https://arxiv.org/pdf/1901.00596.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Deep Learning on Graphs: A Survey.</strong><br><em>Ziwei Zhang, Peng Cui, Wenwu Zhu.</em> 2018. <a href="https://arxiv.org/pdf/1812.04202.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Relational Inductive Biases, Deep Learning, and Graph Networks.</strong><br><em>Battaglia, Peter W and Hamrick, Jessica B and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and others.</em> 2018. <a href="https://arxiv.org/pdf/1806.01261.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Geometric Deep Learning: Going beyond Euclidean data.</strong><br><em>Bronstein, Michael M and Bruna, Joan and LeCun, Yann and Szlam, Arthur and Vandergheynst, Pierre.</em> IEEE SPM 2017. <a href="https://arxiv.org/pdf/1611.08097.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Computational Capabilities of Graph Neural Networks.</strong><br><em>Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele.</em> IEEE TNN 2009. <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=4703190" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Neural Message Passing for Quantum Chemistry.</strong><br><em>Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E.</em> 2017. <a href="https://arxiv.org/pdf/1704.01212.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Non-local Neural Networks.</strong><br><em>Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming.</em> CVPR 2018. <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>The Graph Neural Network Model.</strong><br><em>Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele.</em> IEEE TNN 2009. <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=4700287" target="_blank" rel="noopener">paper</a></p></li></ol><h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h3><ol><li><p><strong>A new model for learning in graph domains.</strong><br><em>Marco Gori, Gabriele Monfardini, Franco Scarselli.</em> IJCNN 2005. <a href="https://www.researchgate.net/profile/Franco_Scarselli/publication/4202380_A_new_model_for_earning_in_raph_domains/links/0c9605188cd580504f000000.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph Neural Networks for Ranking Web Pages.</strong><br><em>Franco Scarselli, Sweah Liang Yong, Marco Gori, Markus Hagenbuchner, Ah Chung Tsoi, Marco Maggini.</em> WI 2005. <a href="https://www.researchgate.net/profile/Franco_Scarselli/publication/221158677_Graph_Neural_Networks_for_Ranking_Web_Pages/links/0c9605188cd5090ede000000/Graph-Neural-Networks-for-Ranking-Web-Pages.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Gated Graph Sequence Neural Networks.</strong><br><em>Yujia Li, Daniel Tarlow, Marc Brockschmidt, Richard Zemel.</em> ICLR 2016. <a href="https://arxiv.org/pdf/1511.05493.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Geometric deep learning on graphs and manifolds using mixture model cnns.</strong><br><em>Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodol�, Jan Svoboda, Michael M. Bronstein.</em> CVPR 2017. <a href="https://arxiv.org/pdf/1611.08402.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Spectral Networks and Locally Connected Networks on Graphs.</strong><br><em>Joan Bruna, Wojciech Zaremba, Arthur Szlam, Yann LeCun.</em> ICLR 2014. <a href="https://arxiv.org/pdf/1312.6203.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Deep Convolutional Networks on Graph-Structured Data.</strong><br><em>Mikael Henaff, Joan Bruna, Yann LeCun.</em> 2015. <a href="https://arxiv.org/pdf/1506.05163.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering.</strong><br><em>Micha�l Defferrard, Xavier Bresson, Pierre Vandergheynst.</em> NIPS 2016. <a href="http://papers.nips.cc/paper/6081-convolutional-neural-networks-on-graphs-with-fast-localized-spectral-filtering.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Learning Convolutional Neural Networks for Graphs.</strong><br><em>Mathias Niepert, Mohamed Ahmed, Konstantin Kutzkov.</em> ICML 2016. <a href="http://proceedings.mlr.press/v48/niepert16.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Semi-Supervised Classification with Graph Convolutional Networks.</strong><br><em>Thomas N. Kipf, Max Welling.</em> ICLR 2017. <a href="https://arxiv.org/pdf/1609.02907.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph Attention Networks.</strong><br><em>Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, Yoshua Bengio.</em> ICLR 2018. <a href="https://mila.quebec/wp-content/uploads/2018/07/d1ac95b60310f43bb5a0b8024522fbe08fb2a482.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Deep Sets.</strong><br><em>Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan Salakhutdinov, Alexander Smola.</em> NIPS 2017. <a href="https://arxiv.org/pdf/1703.06114.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph Partition Neural Networks for Semi-Supervised Classification.</strong><br><em>Renjie Liao, Marc Brockschmidt, Daniel Tarlow, Alexander L. Gaunt, Raquel Urtasun, Richard Zemel.</em> 2018. <a href="https://arxiv.org/pdf/1803.06272.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Covariant Compositional Networks For Learning Graphs.</strong><br><em>Risi Kondor, Hy Truong Son, Horace Pan, Brandon Anderson, Shubhendu Trivedi.</em> 2018. <a href="https://arxiv.org/pdf/1801.02144.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Modeling Relational Data with Graph Convolutional Networks.</strong><br><em>Michael Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, Max Welling.</em> ESWC 2018. <a href="https://arxiv.org/pdf/1703.06103.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Stochastic Training of Graph Convolutional Networks with Variance Reduction.</strong><br><em>Jianfei Chen, Jun Zhu, Le Song.</em> ICML 2018. <a href="http://www.scipaper.net/uploadfile/2018/0716/20180716100330880.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Learning Steady-States of Iterative Algorithms over Graphs.</strong><br><em>Hanjun Dai, Zornitsa Kozareva, Bo Dai, Alex Smola, Le Song.</em> ICML 2018. <a href="http://proceedings.mlr.press/v80/dai18a/dai18a.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Deriving Neural Architectures from Sequence and Graph Kernels.</strong><br><em>Tao Lei, Wengong Jin, Regina Barzilay, Tommi Jaakkola.</em> ICML 2017. <a href="https://arxiv.org/pdf/1705.09037.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Adaptive Graph Convolutional Neural Networks.</strong><br><em>Ruoyu Li, Sheng Wang, Feiyun Zhu, Junzhou Huang.</em> AAAI 2018. <a href="https://arxiv.org/pdf/1801.03226.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph-to-Sequence Learning using Gated Graph Neural Networks.</strong><br><em>Daniel Beck, Gholamreza Haffari, Trevor Cohn.</em> ACL 2018. <a href="https://arxiv.org/pdf/1806.09835.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning.</strong><br><em>Qimai Li, Zhichao Han, Xiao-Ming Wu.</em> AAAI 2018. <a href="https://arxiv.org/pdf/1801.07606.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graphical-Based Learning Environments for Pattern Recognition.</strong><br><em>Franco Scarselli, Ah Chung Tsoi, Marco Gori, Markus Hagenbuchner.</em> SSPR/SPR 2004. <a href="https://link.springer.com/content/pdf/10.1007%2F978-3-540-27868-9_4.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>A Comparison between Recursive Neural Networks and Graph Neural Networks.</strong><br><em>Vincenzo Di Massa, Gabriele Monfardini, Lorenzo Sarti, Franco Scarselli, Marco Maggini, Marco Gori.</em> IJCNN 2006. <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=1716174" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph Neural Networks for Object Localization.</strong><br><em>Gabriele Monfardini, Vincenzo Di Massa, Franco Scarselli, Marco Gori.</em> ECAI 2006. <a href="http://ebooks.iospress.nl/volumearticle/2775" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Knowledge-Guided Recurrent Neural Network Learning for Task-Oriented Action Prediction.</strong><br><em>Liang Lin, Lili Huang, Tianshui Chen, Yukang Gan, Hui Cheng.</em> ICME 2017. <a href="https://arxiv.org/pdf/1707.04677.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Semantic Object Parsing with Graph LSTM.</strong><br><em>Xiaodan LiangXiaohui ShenJiashi FengLiang Lin, Shuicheng Yan.</em> ECCV 2016. <a href="https://link.springer.com/content/pdf/10.1007%2F978-3-319-46448-0_8.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>CelebrityNet: A Social Network Constructed from Large-Scale Online Celebrity Images.</strong><br><em>Li-Jia Li, David A. Shamma, Xiangnan Kong, Sina Jafarpour, Roelof Van Zwol, Xuanhui Wang.</em> TOMM 2015. <a href="https://dl.acm.org/ft_gateway.cfm?id=2801125&amp;ftid=1615097&amp;dwn=1&amp;CFID=38275959&amp;CFTOKEN=6938a464cf972252-DF065FDC-9FED-EB68-3528017EA04F0D29" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Inductive Representation Learning on Large Graphs.</strong><br><em>William L. Hamilton, Rex Ying, Jure Leskovec.</em> NIPS 2017. <a href="https://arxiv.org/pdf/1706.02216.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph Classification using Structural Attention.</strong><br><em>John Boaz Lee, Ryan Rossi, Xiangnan Kong.</em> KDD 18. <a href="https://dl.acm.org/ft_gateway.cfm?id=3219980&amp;ftid=1988883&amp;dwn=1&amp;CFID=38275959&amp;CFTOKEN=6938a464cf972252-DF065FDC-9FED-EB68-3528017EA04F0D29" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Adversarial Attacks on Neural Networks for Graph Data.</strong><br><em>Daniel Z�gner, Amir Akbarnejad, Stephan G�nnemann.</em> KDD 18. <a href="http://delivery.acm.org/10.1145/3230000/3220078/p2847-zugner.pdf?ip=101.5.139.169&amp;id=3220078&amp;acc=ACTIVE%20SERVICE&amp;key=BF85BBA5741FDC6E%2E587F3204F5B62A59%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1545706391_e7484be677293ffb5f18b39ce84a0df9" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Large-Scale Learnable Graph Convolutional Networks.</strong><br><em>Hongyang Gao, Zhengyang Wang, Shuiwang Ji.</em> KDD 18. <a href="http://delivery.acm.org/10.1145/3220000/3219947/p1416-gao.pdf?ip=101.5.139.169&amp;id=3219947&amp;acc=ACTIVE%20SERVICE&amp;key=BF85BBA5741FDC6E%2E587F3204F5B62A59%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1545706457_bb20316c7ce038aefb97afcf4ef9668b" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Contextual Graph Markov Model: A Deep and Generative Approach to Graph Processing.</strong><br><em>Davide Bacciu, Federico Errica, Alessio Micheli.</em> ICML 2018. <a href="https://arxiv.org/pdf/1805.10636.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Diffusion-Convolutional Neural Networks.</strong><br><em>James Atwood, Don Towsley.</em> NIPS 2016. <a href="https://arxiv.org/pdf/1511.02136.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Neural networks for relational learning: an experimental comparison.</strong><br><em>Werner Uwents, Gabriele Monfardini, Hendrik Blockeel, Marco Gori, Franco Scarselli.</em> Machine Learning 2011. <a href="https://link.springer.com/content/pdf/10.1007%2Fs10994-010-5196-5.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling.</strong><br><em>Jie Chen, Tengfei Ma, Cao Xiao.</em> ICLR 2018. <a href="https://arxiv.org/pdf/1801.10247.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Adaptive Sampling Towards Fast Graph Representation Learning.</strong><br><em>Wenbing Huang, Tong Zhang, Yu Rong, Junzhou Huang.</em> NeurIPS 2018. <a href="https://arxiv.org/pdf/1809.05343.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Structure-Aware Convolutional Neural Networks.</strong><br><em>Jianlong Chang, Jie Gu, Lingfeng Wang, Gaofeng Meng, Shiming Xiang, Chunhong Pan.</em> NeurIPS 2018. <a href="http://papers.nips.cc/paper/7287-structure-aware-convolutional-neural-networks.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Bayesian Semi-supervised Learning with Graph Gaussian Processes.</strong><br><em>Yin Cheng Ng, Nicol� Colombo, Ricardo Silva.</em> NeurIPS 2018. <a href="https://arxiv.org/pdf/1809.04379" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Mean-field theory of graph neural networks in graph partitioning.</strong><br><em>Tatsuro Kawamoto, Masashi Tsubaki, Tomoyuki Obuchi.</em> NeurIPS 2018. <a href="http://papers.nips.cc/paper/7689-mean-field-theory-of-graph-neural-networks-in-graph-partitioning.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Hierarchical Graph Representation Learning with Differentiable Pooling.</strong><br><em>Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, Jure Leskovec.</em> NeurIPS 2018. <a href="https://papers.nips.cc/paper/7729-hierarchical-graph-representation-learning-with-differentiable-pooling.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>How Powerful are Graph Neural Networks?</strong><br><em>Keyulu Xu, Weihua Hu, Jure Leskovec, Stefanie Jegelka.</em> ICLR 2019. <a href="https://openreview.net/pdf?id=ryGs6iA5Km" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph Capsule Convolutional Neural Networks.</strong><br><em>Saurabh Verma, Zhi-Li Zhang.</em> ICML 2018 Workshop. <a href="https://arxiv.org/abs/1805.08090" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Capsule Graph Neural Network.</strong><br><em>Zhang Xinyi, Lihui Chen.</em> ICLR 2019. <a href="https://openreview.net/pdf?id=Byl8BnRcYm" target="_blank" rel="noopener">paper</a></p></li></ol><h3 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h3><ol><li><p><strong>Discovering objects and their relations from entangled scene representations.</strong><br><em>David Raposo, Adam Santoro, David Barrett, Razvan Pascanu, Timothy Lillicrap, Peter Battaglia.</em> ICLR Workshop 2017. <a href="https://arxiv.org/pdf/1702.05068.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>A simple neural network module for relational reasoning.</strong><br><em>Adam Santoro, David Raposo, David G.T. Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, Timothy Lillicrap.</em> NIPS 2017. <a href="https://arxiv.org/pdf/1706.01427.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Attend, Infer, Repeat: Fast Scene Understanding with Generative Models.</strong><br><em>S. M. Ali Eslami, Nicolas Heess, Theophane Weber, Yuval Tassa, David Szepesvari, Koray Kavukcuoglu, Geoffrey E. Hinton.</em> NIPS 2016. <a href="https://arxiv.org/pdf/1603.08575.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Beyond Categories: The Visual Memex Model for Reasoning About Object Relationships.</strong><br><em>Tomasz Malisiewicz, Alyosha Efros.</em> NIPS 2009. <a href="http://papers.nips.cc/paper/3647-beyond-categories-the-visual-memex-model-for-reasoning-about-object-relationships.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Understanding Kin Relationships in a Photo.</strong><br><em>Siyu Xia, Ming Shao, Jiebo Luo, Yun Fu.</em> TMM 2012. <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6151163" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph-Structured Representations for Visual Question Answering.</strong><br><em>Damien Teney, Lingqiao Liu, Anton van den Hengel.</em> CVPR 2017. <a href="https://arxiv.org/pdf/1609.05600.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition.</strong><br><em>Sijie Yan, Yuanjun Xiong, Dahua Lin.</em> AAAI 2018. <a href="https://arxiv.org/pdf/1801.07455.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Few-Shot Learning with Graph Neural Networks.</strong><br><em>Victor Garcia, Joan Bruna.</em> ICLR 2018. <a href="https://arxiv.org/pdf/1711.04043.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>The More You Know: Using Knowledge Graphs for Image Classification.</strong><br><em>Kenneth Marino, Ruslan Salakhutdinov, Abhinav Gupta.</em> CVPR 2017. <a href="https://arxiv.org/pdf/1612.04844.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs.</strong><br><em>Xiaolong Wang, Yufei Ye, Abhinav Gupta.</em> CVPR 2018. <a href="https://arxiv.org/pdf/1803.08035.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Rethinking Knowledge Graph Propagation for Zero-Shot Learning.</strong><br><em>Michael Kampffmeyer, Yinbo Chen, Xiaodan Liang, Hao Wang, Yujia Zhang, Eric P. Xing.</em> 2018. <a href="https://arxiv.org/pdf/1805.11724.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Interaction Networks for Learning about Objects, Relations and Physics.</strong><br><em>Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Rezende, Koray Kavukcuoglu.</em> NIPS 2016. <a href="https://arxiv.org/pdf/1612.00222.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>A Compositional Object-Based Approach to Learning Physical Dynamics.</strong><br><em>Michael B. Chang, Tomer Ullman, Antonio Torralba, Joshua B. Tenenbaum.</em> ICLR 2017. <a href="https://arxiv.org/pdf/1612.00341.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Visual Interaction Networks: Learning a Physics Simulator from Vide.o</strong><br><em>Nicholas Watters, Andrea Tacchetti, Th�ophane Weber, Razvan Pascanu, Peter Battaglia, Daniel Zoran.</em> NIPS 2017. <a href="http://papers.nips.cc/paper/7040-visual-interaction-networks-learning-a-physics-simulator-from-video.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Relational neural expectation maximization: Unsupervised discovery of objects and their interactions.</strong><br><em>Sjoerd van Steenkiste, Michael Chang, Klaus Greff, J�rgen Schmidhuber.</em> ICLR 2018. <a href="https://arxiv.org/pdf/1802.10353.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph networks as learnable physics engines for inference and control.</strong><br><em>Alvaro Sanchez-Gonzalez, Nicolas Heess, Jost Tobias Springenberg, Josh Merel, Martin Riedmiller, Raia Hadsell, Peter Battaglia.</em> ICML 2018. <a href="https://arxiv.org/pdf/1806.01242.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Learning Multiagent Communication with Backpropagation.</strong><br><em>Sainbayar Sukhbaatar, Arthur Szlam, Rob Fergus.</em> NIPS 2016. <a href="https://arxiv.org/pdf/1605.07736.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>VAIN: Attentional Multi-agent Predictive Modeling.</strong><br><em>Yedid Hoshen.</em> NIPS 2017 <a href="https://arxiv.org/pdf/1706.06122.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Neural Relational Inference for Interacting Systems.</strong><br><em>Thomas Kipf, Ethan Fetaya, Kuan-Chieh Wang, Max Welling, Richard Zemel.</em> ICML 2018. <a href="https://arxiv.org/pdf/1802.04687.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Translating Embeddings for Modeling Multi-relational Data.</strong><br><em>Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, Oksana Yakhnenko.</em> NIPS 2013. <a href="http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Representation learning for visual-relational knowledge graphs.</strong><br><em>Daniel O�oro-Rubio, Mathias Niepert, Alberto Garc�a-Dur�n, Roberto Gonz�lez, Roberto J. L�pez-Sastre.</em> 2017. <a href="https://arxiv.org/pdf/1709.02314.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Knowledge Transfer for Out-of-Knowledge-Base Entities : A Graph Neural Network Approach.</strong><br><em>Takuo Hamaguchi, Hidekazu Oiwa, Masashi Shimbo, Yuji Matsumoto.</em> IJCAI 2017. <a href="https://arxiv.org/pdf/1706.05674.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Representation Learning on Graphs with Jumping Knowledge Networks.</strong><br><em>Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, Stefanie Jegelka.</em> ICML 2018. <a href="https://arxiv.org/pdf/1806.03536.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Multi-Label Zero-Shot Learning with Structured Knowledge Graphs.</strong><br><em>Chung-Wei Lee, Wei Fang, Chih-Kuan Yeh, Yu-Chiang Frank Wang.</em> CVPR 2018. <a href="https://arxiv.org/pdf/1711.06526.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Dynamic Graph Generation Network: Generating Relational Knowledge from Diagrams.</strong><br><em>Daesik Kim, Youngjoon Yoo, Jeesoo Kim, Sangkuk Lee, Nojun Kwak.</em> CVPR 2018. <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Kim_Dynamic_Graph_Generation_CVPR_2018_paper.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Deep Reasoning with Knowledge Graph for Social Relationship Understanding.</strong><br><em>Zhouxia Wang, Tianshui Chen, Jimmy Ren, Weihao Yu, Hui Cheng, Liang Lin.</em> IJCAI 2018. <a href="https://arxiv.org/pdf/1807.00504.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Constructing Narrative Event Evolutionary Graph for Script Event Prediction.</strong><br><em>Zhongyang Li, Xiao Ding, Ting Liu.</em> IJCAI 2018. <a href="https://arxiv.org/pdf/1805.05081.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Modeling Semantics with Gated Graph Neural Networks for Knowledge Base Question Answering.</strong><br><em>Daniil Sorokin, Iryna Gurevych.</em> COLING 2018. <a href="https://arxiv.org/pdf/1808.04126.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Convolutional networks on graphs for learning molecular fingerprints.</strong><br><em>David Duvenaud, Dougal Maclaurin, Jorge Aguilera-Iparraguirre, Rafael G�mez-Bombarelli, Timothy Hirzel, Al�n Aspuru-Guzik, Ryan P. Adams.</em> NIPS 2015. <a href="https://arxiv.org/pdf/1509.09292.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Molecular Graph Convolutions: Moving Beyond Fingerprints.</strong><br><em>Steven Kearnes, Kevin McCloskey, Marc Berndl, Vijay Pande, Patrick Riley.</em> Journal of computer-aided molecular design 2016. <a href="https://arxiv.org/pdf/1603.00856.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Protein Interface Prediction using Graph Convolutional Networks.</strong><br><em>Alex Fout, Jonathon Byrd, Basir Shariat, Asa Ben-Hur.</em> NIPS 2017. <a href="http://papers.nips.cc/paper/7231-protein-interface-prediction-using-graph-convolutional-networks.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Traffic Graph Convolutional Recurrent Neural Network: A Deep Learning Framework for Network-Scale Traffic Learning and Forecasting.</strong><br><em>Zhiyong Cui, Kristian Henrickson, Ruimin Ke, Yinhai Wang.</em> 2018. <a href="https://arxiv.org/pdf/1802.07007.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting.</strong><br><em>Bing Yu, Haoteng Yin, Zhanxing Zhu.</em> IJCAI 2018. <a href="https://arxiv.org/pdf/1709.04875.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Semi-supervised User Geolocation via Graph Convolutional Networks.</strong><br><em>Afshin Rahimi, Trevor Cohn, Timothy Baldwin.</em> ACL 2018. <a href="https://arxiv.org/pdf/1804.08049.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Dynamic Graph CNN for Learning on Point Clouds.</strong><br><em>Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. Sarma, Michael M. Bronstein, Justin M. Solomon.</em> CVPR 2018. <a href="https://arxiv.org/pdf/1801.07829.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation.</strong><br><em>Charles R. Qi, Hao Su, Kaichun Mo, Leonidas J. Guibas.</em> CVPR 2018. <a href="https://arxiv.org/pdf/1612.00593.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>3D Graph Neural Networks for RGBD Semantic Segmentation.</strong><br><em>Xiaojuan Qi, Renjie Liao, Jiaya Jia, Sanja Fidler, Raquel Urtasun.</em> CVPR 2017. <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Qi_3D_Graph_Neural_ICCV_2017_paper.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Iterative Visual Reasoning Beyond Convolutions.</strong><br><em>Xinlei Chen, Li-Jia Li, Li Fei-Fei, Abhinav Gupta.</em> CVPR 2018. <a href="https://arxiv.org/pdf/1803.11189" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs.</strong><br><em>Martin Simonovsky, Nikos Komodakis.</em> CVPR 2017. <a href="https://arxiv.org/pdf/1704.02901" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Situation Recognition with Graph Neural Networks.</strong><br><em>Ruiyu Li, Makarand Tapaswi, Renjie Liao, Jiaya Jia, Raquel Urtasun, Sanja Fidler.</em> ICCV 2017. <a href="https://arxiv.org/pdf/1708.04320" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Conversation Modeling on Reddit using a Graph-Structured LSTM.</strong><br><em>Vicky Zayats, Mari Ostendorf.</em> TACL 2018. <a href="https://arxiv.org/pdf/1704.02080" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph Convolutional Networks for Text Classification.</strong><br><em>Liang Yao, Chengsheng Mao, Yuan Luo.</em> AAAI 2019. <a href="https://arxiv.org/pdf/1809.05679.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Attention Is All You Need.</strong><br><em>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin.</em> NIPS 2017. <a href="https://arxiv.org/pdf/1706.03762" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Self-Attention with Relative Position Representations.</strong><br><em>Peter Shaw, Jakob Uszkoreit, Ashish Vaswani.</em> NAACL 2018. <a href="https://arxiv.org/pdf/1803.02155" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Hyperbolic Attention Networks.</strong><br><em>Caglar Gulcehre, Misha Denil, Mateusz Malinowski, Ali Razavi, Razvan Pascanu, Karl Moritz Hermann, Peter Battaglia, Victor Bapst, David Raposo, Adam Santoro, Nando de Freitas</em> 2018. <a href="https://arxiv.org/pdf/1805.09786" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Effective Approaches to Attention-based Neural Machine Translation.</strong><br><em>Minh-Thang Luong, Hieu Pham, Christopher D. Manning.</em> EMNLP 2015. <a href="https://arxiv.org/pdf/1508.04025" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph Convolutional Encoders for Syntax-aware Neural Machine Translation.</strong><br><em>Joost Bastings, Ivan Titov, Wilker Aziz, Diego Marcheggiani, Khalil Sima’an.</em> EMNLP 2017. <a href="https://arxiv.org/pdf/1704.04675" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>NerveNet: Learning Structured Policy with Graph Neural Networks.</strong><br><em>Tingwu Wang, Renjie Liao, Jimmy Ba, Sanja Fidler.</em> ICLR 2018. <a href="https://openreview.net/pdf?id=S1sqHMZCb" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Metacontrol for Adaptive Imagination-Based Optimization.</strong><br><em>Jessica B. Hamrick, Andrew J. Ballard, Razvan Pascanu, Oriol Vinyals, Nicolas Heess, Peter W. Battaglia.</em> ICLR 2017. <a href="https://arxiv.org/pdf/1705.02670" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Learning model-based planning from scratch.</strong><br><em>Razvan Pascanu, Yujia Li, Oriol Vinyals, Nicolas Heess, Lars Buesing, Sebastien Racani�re, David Reichert, Th�ophane Weber, Daan Wierstra, Peter Battaglia.</em> 2017. <a href="https://arxiv.org/pdf/1707.06170" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Structured Dialogue Policy with Graph Neural Networks.</strong><br><em>Lu Chen, Bowen Tan, Sishan Long and Kai Yu.</em> ICCL 2018. <a href="http://www.aclweb.org/anthology/C18-1107" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Relational inductive bias for physical construction in humans and machines.</strong><br><em>Jessica B. Hamrick, Kelsey R. Allen, Victor Bapst, Tina Zhu, Kevin R. McKee, Joshua B. Tenenbaum, Peter W. Battaglia.</em> CogSci 2018. <a href="https://arxiv.org/abs/1806.01203" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Relational Deep Reinforcement Learning.</strong><br><em>Vinicius Zambaldi, David Raposo, Adam Santoro, Victor Bapst, Yujia Li, Igor Babuschkin, Karl Tuyls, David Reichert, Timothy Lillicrap, Edward Lockhart, Murray Shanahan, Victoria Langston, Razvan Pascanu, Matthew Botvinick, Oriol Vinyals, Peter Battaglia.</em> 2018. <a href="https://arxiv.org/abs/1806.01830" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Action Schema Networks: Generalised Policies with Deep Learning.</strong><br><em>Sam Toyer, Felipe Trevizan, Sylvie Thi�baux, Lexing Xie.</em> AAAI 2018. <a href="https://arxiv.org/abs/1709.04271" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Neural Combinatorial Optimization with Reinforcement Learning.</strong><br><em>Irwan Bello, Hieu Pham, Quoc V. Le, Mohammad Norouzi, Samy Bengio.</em> 2016. <a href="https://arxiv.org/abs/1611.09940" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>A Note on Learning Algorithms for Quadratic Assignment with Graph Neural Networks.</strong><br><em>Alex Nowak, Soledad Villar, Afonso S. Bandeira, Joan Bruna.</em> PADL 2017. <a href="https://www.padl.ws/papers/Paper%2017.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Learning Combinatorial Optimization Algorithms over Graphs.</strong><br><em>Hanjun Dai, Elias B. Khalil, Yuyu Zhang, Bistra Dilkina, Le Song.</em> NIPS 2017. <a href="https://arxiv.org/abs/1704.01665" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Attention Solves Your TSP, Approximately.</strong><br><em>Wouter Kool, Herke van Hoof, Max Welling.</em> 2018. <a href="https://arxiv.org/abs/1803.08475" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Learning a SAT Solver from Single-Bit Supervision.</strong><br><em>Daniel Selsam, Matthew Lamm, Benedikt B�nz, Percy Liang, Leonardo de Moura, David L. Dill.</em> 2018. <a href="https://arxiv.org/abs/1802.03685" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Learning to Represent Programs with Graphs.</strong><br><em>Miltiadis Allamanis, Marc Brockschmidt, Mahmoud Khademi.</em> ICLR 2018. <a href="https://arxiv.org/abs/1711.00740" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Learning Graphical State Transitions.</strong><br><em>Daniel D. Johnson.</em> ICLR 2017. <a href="https://openreview.net/forum?id=HJ0NvFzxl" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Inference in Probabilistic Graphical Models by Graph Neural Networks.</strong><br><em>KiJung Yoon, Renjie Liao, Yuwen Xiong, Lisa Zhang, Ethan Fetaya, Raquel Urtasun, Richard Zemel, Xaq Pitkow.</em> ICLR Workshop 2018. <a href="https://arxiv.org/abs/1803.07710" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Learning deep generative models of graphs.</strong><br><em>Yujia Li, Oriol Vinyals, Chris Dyer, Razvan Pascanu, Peter Battaglia.</em> ICLR Workshop 2018. <a href="https://arxiv.org/abs/1803.03324" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>MolGAN: An implicit generative model for small molecular graphs.</strong><br><em>Nicola De Cao, Thomas Kipf.</em> 2018. <a href="https://arxiv.org/abs/1805.11973" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models.</strong><br><em>Jiaxuan You, Rex Ying, Xiang Ren, William L. Hamilton, Jure Leskovec.</em> ICML 2018. <a href="https://arxiv.org/abs/1802.08773" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>NetGAN: Generating Graphs via Random Walks.</strong><br><em>Aleksandar Bojchevski, Oleksandr Shchur, Daniel Z�gner, Stephan G�nnemann.</em> ICML 2018. <a href="https://arxiv.org/abs/1803.00816" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Adversarial Attack on Graph Structured Data.</strong><br><em>Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, Le Song.</em> ICML 2018. <a href="https://arxiv.org/abs/1806.02371" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph Convolutional Neural Networks for Web-Scale Recommender Systems.</strong><br><em>Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, Jure Leskovec.</em> KDD 2018. <a href="https://arxiv.org/abs/1806.01973" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks.</strong><br><em>Kai Sheng Tai, Richard Socher, Christopher D. Manning.</em> ACL 2015. <a href="https://www.aclweb.org/anthology/P15-1150" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Neural Module Networks.</strong><br><em>Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein.</em> CVPR 2016. <a href="https://arxiv.org/pdf/1511.02799.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling.</strong><br><em>Diego Marcheggiani, Ivan Titov.</em> EMNLP 2017. <a href="https://arxiv.org/abs/1703.04826" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph Convolutional Networks with Argument-Aware Pooling for Event Detection.</strong><br><em>Thien Huu Nguyen, Ralph Grishman.</em> AAAI 2018. <a href="http://ix.cs.uoregon.edu/~thien/pubs/graphConv.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Geometric Matrix Completion with Recurrent Multi-Graph Neural Networks.</strong><br><em>Federico Monti, Michael M. Bronstein, Xavier Bresson.</em> NIPS 2017. <a href="https://arxiv.org/abs/1704.06803" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph Convolutional Matrix Completion.</strong><br><em>Rianne van den Berg, Thomas N. Kipf, Max Welling.</em> 2017. <a href="https://arxiv.org/abs/1706.02263" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Hybrid Approach of Relation Network and Localized Graph Convolutional Filtering for Breast Cancer Subtype Classification.</strong><br><em>Sungmin Rhee, Seokjun Seo, Sun Kim.</em> IJCAI 2018. <a href="https://arxiv.org/abs/1711.05859" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Modeling polypharmacy side effects with graph convolutional networks.</strong><br><em>Marinka Zitnik, Monica Agrawal, Jure Leskovec.</em> ISMB 2018. <a href="https://arxiv.org/abs/1802.00543" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>DeepInf: Modeling influence locality in large social networks.</strong><br><em>Jiezhong Qiu, Jian Tang, Hao Ma, Yuxiao Dong, Kuansan Wang, Jie Tang.</em> KDD 2018. <a href="https://arxiv.org/pdf/1807.05560.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks.</strong><br><em>Diego Marcheggiani, Joost Bastings, Ivan Titov.</em> NAACL 2018. <a href="http://www.aclweb.org/anthology/N18-2078" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Exploring Graph-structured Passage Representation for Multi-hop Reading Comprehension with Graph Neural Networks.</strong><br><em>Linfeng Song, Zhiguo Wang, Mo Yu, Yue Zhang, Radu Florian, Daniel Gildea.</em> 2018. <a href="https://arxiv.org/abs/1809.02040" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph Convolution over Pruned Dependency Trees Improves Relation Extraction.</strong><br><em>Yuhao Zhang, Peng Qi, Christopher D. Manning.</em> EMNLP 2018. <a href="https://arxiv.org/abs/1809.10185" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>N-ary relation extraction using graph state LSTM.</strong><br><em>Linfeng Song, Yue Zhang, Zhiguo Wang, Daniel Gildea.</em> EMNLP 18. <a href="https://arxiv.org/abs/1808.09101" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>A Graph-to-Sequence Model for AMR-to-Text Generation.</strong><br><em>Linfeng Song, Yue Zhang, Zhiguo Wang, Daniel Gildea.</em> ACL 2018. <a href="https://arxiv.org/abs/1805.02473" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Cross-Sentence N-ary Relation Extraction with Graph LSTMs.</strong><br><em>Nanyun Peng, Hoifung Poon, Chris Quirk, Kristina Toutanova, Wen-tau Yih.</em> TACL. <a href="https://arxiv.org/abs/1708.03743" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Sentence-State LSTM for Text Representation.</strong><br><em>Yue Zhang, Qi Liu, Linfeng Song.</em>  ACL 2018. <a href="https://arxiv.org/abs/1805.02474" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures.</strong><br><em>Makoto Miwa, Mohit Bansal.</em> ACL 2016. <a href="https://arxiv.org/abs/1601.00770" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Learning Human-Object Interactions by Graph Parsing Neural Networks.</strong><br><em>Siyuan Qi, Wenguan Wang, Baoxiong Jia, Jianbing Shen, Song-Chun Zhu.</em> ECCV 2018. <a href="https://arxiv.org/pdf/1808.07962.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Multiple Events Extraction via Attention-based Graph Information Aggregation.</strong><br><em>Xiao Liu, Zhunchen Luo, Heyan Huang.</em> EMNLP 2018. <a href="https://arxiv.org/pdf/1809.09078.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks.</strong><br><em>Zhichun Wang, Qingsong Lv, Xiaohan Lan, Yu Zhang.</em> EMNLP 2018. <a href="http://www.aclweb.org/anthology/D18-1032" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph Convolution over Pruned Dependency Trees Improves Relation Extraction.</strong><br><em>Yuhao Zhang, Peng Qi, Christopher D. Manning.</em> EMNLP 2018. <a href="https://arxiv.org/pdf/1809.10185" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Recurrent Relational Networks.</strong><br><em>Rasmus Palm, Ulrich Paquet, Ole Winther.</em> NeurIPS 2018. <a href="http://papers.nips.cc/paper/7597-recurrent-relational-networks.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation.</strong><br><em>Jiaxuan You, Bowen Liu, Rex Ying, Vijay Pande, Jure Leskovec.</em> NeurIPS 2018. <a href="https://arxiv.org/pdf/1806.02473" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Learning Conditioned Graph Structures for Interpretable Visual Question Answering.</strong><br><em>Will Norcliffe-Brown, Efstathios Vafeias, Sarah Parisot.</em> NeurIPS 2018. <a href="https://arxiv.org/pdf/1806.07243" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search.</strong><br><em>Zhuwen Li, Qifeng Chen, Vladlen Koltun.</em> NeurIPS 2018. <a href="http://papers.nips.cc/paper/7335-combinatorial-optimization-with-graph-convolutional-networks-and-guided-tree-search.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Symbolic Graph Reasoning Meets Convolutions.</strong><br><em>Xiaodan Liang, Zhiting Hu, Hao Zhang, Liang Lin, Eric P. Xing.</em> NeurIPS 2018. <a href="http://papers.nips.cc/paper/7456-symbolic-graph-reasoning-meets-convolutions.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering.</strong><br><em>Medhini Narasimhan, Svetlana Lazebnik, Alexander Schwing.</em> NeurIPS 2018. <a href="http://papers.nips.cc/paper/7531-out-of-the-box-reasoning-with-graph-convolution-nets-for-factual-visual-question-answering.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Constrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders.</strong><br><em>Tengfei Ma, Jie Chen, Cao Xiao.</em> NeurIPS 2018. <a href="https://papers.nips.cc/paper/7942-constrained-generation-of-semantically-valid-graphs-via-regularizing-variational-autoencoders.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Structural-RNN: Deep Learning on Spatio-Temporal Graphs.</strong><br><em>Ashesh Jain, Amir R. Zamir, Silvio Savarese, Ashutosh Saxena.</em> CVPR 2016. <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Jain_Structural-RNN_Deep_Learning_CVPR_2016_paper.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Relation Networks for Object Detection.</strong><br><em>Han Hu, Jiayuan Gu, Zheng Zhang, Jifeng Dai, Yichen Wei.</em> CVPR 2018. <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers_backup/Hu_Relation_Networks_for_CVPR_2018_paper.pdf" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Learning Region features for Object Detection.</strong><br><em>Jiayuan Gu, Han Hu, Liwei Wang, Yichen Wei, Jifeng Dai.</em> ECCV 2018. <a href="https://arxiv.org/pdf/1803.07066" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Deep Graph Infomax.</strong><br><em>Petar Veli?kovi?, William Fedus, William L. Hamilton, Pietro Li�, Yoshua Bengio, R Devon Hjelm.</em> ICLR 2019. <a href="https://openreview.net/pdf?id=rklz9iAcKQ" target="_blank" rel="noopener">paper</a></p></li><li><p><strong>Combining Neural Networks with Personalized PageRank for Classification on Graphs.</strong><br><em>Johannes Klicpera, Aleksandar Bojchevski, Stephan G�nnemann.</em> ICLR 2019. <a href="https://arxiv.org/pdf/1810.05997.pdf" target="_blank" rel="noopener">paper</a></p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>工程数学笔记</title>
      <link href="/2019/01/18/gong-cheng-shu-xue-bi-ji/"/>
      <url>/2019/01/18/gong-cheng-shu-xue-bi-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="数值计算笔记"><a href="#数值计算笔记" class="headerlink" title="数值计算笔记"></a>数值计算笔记</h1><p><img src="https://i.loli.net/2019/01/18/5c41bbb523a79.jpg" alt="微信图片_201901181119471.jpg"></p><p><img src="https://i.loli.net/2019/01/18/5c41bbb386ec9.jpg" alt="微信图片_201901181119461.jpg"></p><p><img src="https://i.loli.net/2019/01/18/5c41bbb34958f.jpg" alt="微信图片_201901181119473.jpg"></p><p><img src="https://i.loli.net/2019/01/18/5c41bbb25a089.jpg" alt="微信图片_201901181119472.jpg"></p><p><img src="https://i.loli.net/2019/01/18/5c41bbb4a94d4.jpg" alt="微信图片_20190118111947.jpg"></p><p><img src="https://i.loli.net/2019/01/18/5c41bbb4c7d16.jpg" alt="微信图片_20190118111946.jpg"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>算法分析与设计</title>
      <link href="/2019/01/01/suan-fa-fen-xi-yu-she-ji/"/>
      <url>/2019/01/01/suan-fa-fen-xi-yu-she-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h1><ol><li><strong>最大公约数算法</strong>：<ul><li>gcd(m, n) = gcd(n, m mod n)</li><li>结束条件是 m%n = 0</li></ul></li></ol><h1 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h1><ol><li><strong>算法时间效率度量</strong> —— 基本操作的执行次数。</li><li><strong>渐进符号</strong>（可以按照复杂程度记忆，最简单的为上界，最复杂的为下界）<br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqvq0dr35j30zv0matd7.jpg" alt="1"></li><li>斐波那契数列<br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqw4dwrf0j30kh0f5jss.jpg" alt="2"><ul><li>参数 α，β 可以通过 F(1)、F(2)联立方程组解出来</li></ul></li></ol><h1 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h1><ol><li><p><strong>选择排序</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqwaev3q0j312a0rjtfl.jpg" alt="3"></p></li><li><p><strong>冒泡排序</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqwdhyujzj313z0r410o.jpg" alt="4"></p></li><li><p><strong>幻方</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqwoxzdqpj310j0psq73.jpg" alt="5"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqwpl5gufj313c0pxjxd.jpg" alt="6"></p></li></ol><h1 id="第四章"><a href="#第四章" class="headerlink" title="第四章"></a>第四章</h1><ol><li><p><strong>分治法</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqxjm0uujj31040ts10h.jpg" alt="7"></p></li><li><p><strong>合并排序</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqy3tlh99j30z30ondip.jpg" alt="8"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyqy2s4152j30yp0r4n1t.jpg" alt="9"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1ieyoxdj312s0qlq5k.jpg" alt="10"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1jbpuyjj31050rqtcj.jpg" alt="11"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1kum4eej311d0jeju8.jpg" alt="12"></p></li><li><p><strong>快速排序</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1qw61urj30us0os44s.jpg" alt="13"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1s0tmt1j30uq0mvae2.jpg" alt="14"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1snlhkjj30v60n9tga.jpg" alt="15"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1tlh17cj30w70nwgra.jpg" alt="16"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr1ucolzrj30up0or42w.jpg" alt="17"></p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">#include<iostream>using namespace std;int a[5], n;void quickSort(int left, int right){    if (left >= right)        return;    int i, j, t, temp;    i = left;    j = right;    temp = a[left];    while (true){        while (a[j] >= temp && i < j){            j--;        }        while (a[i] <= temp && i < j){            i++;        }        if (i < j){            t = a[i];            a[i] = a[j];            a[j] = t;        }        else            break;    }    a[left] = a[j];    a[j] = temp;    quickSort(left, i - 1);    quickSort(i + 1, right);}int main(){    for (int i = 1; i <= 5; i++){        cin >> a[i];    }    quickSort(1, n);    for (int i = 1; i <= 5; i++){        cout << a[i] << " ";    }    cout << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>大整数乘法</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr51lds72j30se0j0juu.jpg" alt="18"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr52dd56wj30tv0jt42l.jpg" alt="19"></p></li><li><p><strong>Strassen 矩阵乘法</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr5lam69mj30uc0lt0vr.jpg" alt="20"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr5m107vij30th0krjul.jpg" alt="21"></p></li></ol><h1 id="第五章"><a href="#第五章" class="headerlink" title="第五章"></a>第五章</h1><ol><li><strong>减治算法</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr6ph0mzgj31170rrguo.jpg" alt="22"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr6qh01sej30y90pfjx6.jpg" alt="23"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyr6rcg9jtj31090pun41.jpg" alt="24"></li></ol><h1 id="第六章"><a href="#第六章" class="headerlink" title="第六章"></a>第六章</h1><ol><li><p><strong>平衡二叉树</strong></p><blockquote><p>这里的 LR 旋转是相对的概念, 意思是先变成左子树再向右旋转。</p></blockquote><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyre3ydw8cj30u0140tj8.jpg" alt="25"></p></li><li><p><strong>2-3 树</strong></p><blockquote><p>2-3 树是一种特殊的高度平衡树，允许结点最多包含两个关键字。<br>❑ 2-node:包含一个关键字，两个子节点<br>❑ 3-node:包含两个关键字，三个子节点</p></blockquote><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyreus7u67j30qn0hdakf.jpg" alt="26"></p></li><li><p><strong>Horner 法则</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyrf3av83ej30z00jldiw.jpg" alt="27"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyrfsexfvhj310u0mtk54.jpg" alt="28"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyrf59pwg5j310z0rgdkh.jpg" alt="29"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyrft1qi8yj30mq06gdjp.jpg" alt="30"></p></li></ol><h1 id="第七章"><a href="#第七章" class="headerlink" title="第七章"></a>第七章</h1><ol><li><p><strong>计数排序</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fysbvkrghoj312s0r6n1t.jpg" alt="31"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fysbwb7q37j30kw0oj76t.jpg" alt="32"></p></li><li><p><strong>分布计数排序</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fysd6sdp2uj30ya0myq6k.jpg" alt="33"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fysd9p1jdgj30y70nrae5.jpg" alt="34"></p><p>实现代码：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++"> #include<iostream> using namespace std; int a[10], l, u, D[10], S[10]; void DistributeSort(){     for (int i = 0; i <= u - l; i++){         D[i] = 0;     }     for (int i = 0; i < 10; i++){         D[a[i] - l]++;     }     for (int i = 1; i <= u - l; i++){         D[i] += D[i - 1];     }     for (int i = 9; i >= 0; i--){         int j = a[i] - l;         S[D[j] - 1] = a[i];         D[j] -= 1;     }     for (int i = 0; i < 10; i++){         cout << S[i] << " ";     } } int main() {     l = 1, u = 3;     for (int i = 0; i < 10; i++){         cin >> a[i]; // 1 2 3 1 2 3 1 2 3 1     }     DistributeSort();     return 0; }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>软件过程重点知识梳理</title>
      <link href="/2018/12/28/ruan-jian-guo-cheng-chong-dian-zhi-shi-shu-li/"/>
      <url>/2018/12/28/ruan-jian-guo-cheng-chong-dian-zhi-shi-shu-li/</url>
      
        <content type="html"><![CDATA[<h1 id="高级软件开发过程重点知识"><a href="#高级软件开发过程重点知识" class="headerlink" title="高级软件开发过程重点知识"></a>高级软件开发过程重点知识</h1><h2 id="1-绪论"><a href="#1-绪论" class="headerlink" title="1. 绪论"></a>1. 绪论</h2><ul><li><strong>软件过程定义</strong>：从软件需求定义开始到软件废弃为止，跨越整个生命周期内的系统开发、运行、维护等全部活动及其相关项的总和。</li><li><strong>软件发展三阶段</strong>：程序设计、软件工程、软件过程</li><li><strong>软件过程能力评估标准和改进方案</strong>：CMM, ISO, 6 西格玛</li><li><strong>生命周期模型</strong>：瀑布模型、原型模型、螺旋模型、喷泉模型</li><li><strong>软件过程与软件工程的关系</strong>：包含关系</li><li><strong>软件过程模式的意义</strong>：<ul><li>四要素</li><li>快速把握软件过程的本质、原则、规范、特点、策略等</li><li>分析优缺点</li></ul></li></ul><h2 id="2-Rational-统一开发过程"><a href="#2-Rational-统一开发过程" class="headerlink" title="2. Rational 统一开发过程"></a>2. Rational 统一开发过程</h2><ul><li><strong>三大特点</strong>：<ul><li>用力驱动</li><li>以架构为中心</li><li>迭代与增量</li></ul></li><li>工作流程不仅仅指活动，还表明了角色、活动、工件是一个逻辑整体。</li><li><p><strong>RUP 二维结构图</strong><br><img src="https://pic002.cnblogs.com/images/2012/444673/2012091916323986.png" alt="RUP"></p><ul><li>静态特征：纵轴的内容组织</li><li>动态特征：横轴的时间组织</li><li>RUP 独特的地方<ul><li>并行化</li><li>阶段内部迭代</li><li>工作流中多出的几个新的概念</li><li>明确的里程碑</li></ul></li></ul></li><li><p><strong>九大核心工作流程</strong></p><ul><li>核心过程<ul><li>业务建模</li><li>需求</li><li>分析设计</li><li>实施</li><li>测试</li><li>部署</li></ul></li><li>核心支持<ul><li>配置、变更管理</li><li>项目管理</li><li>环境</li></ul></li></ul></li><li><strong>工件</strong>：模型、元素、文档、源代码、可执行文件、工具等。</li><li><p><strong>四阶段</strong>：</p><ul><li>先启（目标）</li><li>精化（架构）</li><li>构建（初始化、产品是否稳定、迭代次数最多）</li><li>产品化（产品发布、用户是否满意）</li></ul></li><li><p><strong>五大角色</strong></p><ul><li>分析员</li><li>开发人员</li><li>测试员</li><li>经理</li><li>其他角色</li></ul></li><li><p><strong>角色的意义</strong>（两步走）：</p><ul><li>迭代计划时，确定角色</li><li>人员计划时，考虑个体的技能特长，分配角色</li></ul></li><li><strong>角色方面的缺陷</strong>：未给出角色的组织管理方式、角色之间的地位和交互关系。</li><li><strong>用例的缺点及其解决方法</strong>：非功能性需求表现不足，可用补充说明文档解决。</li><li><p><strong>架构视图</strong>：</p><ul><li>用例模型视图</li><li>分析模型视图</li><li>设计模型视图</li><li>实施模型视图</li><li>实现模型视图</li><li>补充【<strong>架构必须留有复用和进化空间</strong>】</li></ul></li><li><p><strong>RUP 的优点</strong></p><ul><li>二维迭代，有利于降低风险，适应新需求</li><li>可配置，具有通用性</li><li>包含四要素的详尽的阐述</li><li>有现成的使用工具，具有操作性、可实现性</li></ul></li><li><p><strong>RUP 的缺点</strong></p><ul><li>四要素关系及其优先级未给出</li><li>生命周期各元素的关旭和优先级未给出</li><li>人员之间的优先级和协作方式未给出</li><li>产品和方法之间的优先级未给出</li></ul></li></ul><h2 id="3-敏捷开发过程"><a href="#3-敏捷开发过程" class="headerlink" title="3. 敏捷开发过程"></a>3. 敏捷开发过程</h2><ul><li><p><strong>4 条基本价值观</strong></p><ul><li>个体和交互胜过过程和工具（人员、生命周期、方法）</li><li>可以工作的软件胜过面面俱到的文档（产品）</li><li>客户合作胜过合同谈判（人员）</li><li>响应变化胜过遵循计划（方法）</li></ul></li><li><p><strong>12 条基本原则</strong><br>1、我们的最高目标是，通过尽早和持续地交付有价值的软件来满足客户。<br>2、欢迎对需求提出变更——即使是在项目开发后期。要善于利用需求变更，帮助客户获得竞争优势。<br>3、要不断交付可用的软件，周期从几周到几个月不等，且越短越好。<br>4、项目过程中，业务人员与开发人员必须在一起工作。<br>5、要善于激励项目人员，给他们以所需要的环境和支持，并相信他们能够完成任务。<br>6、无论是团队内还是团队间，最有效的沟通方法是面对面的交谈。<br>7、可用的软件是衡量进度的主要指标。<br>8、敏捷过程提倡可持续的开发。项目方、开发人员和用户应该能够保持恒久稳定的进展速度。<br>9、对技术的精益求精以及对设计的不断完善将提升敏捷性。<br>10、要做到简洁，即尽最大可能减少不必要的工作。这是一门艺术。<br>11、最佳的架构、需求和设计出自于自组织的团队。<br>12、团队要定期反省如何能够做到更有效，并相应地调整团队的行为。</p><ul><li>分类：<ul><li>生命周期(1,3,7,8)</li><li>人员(4,5,6,11,12)</li><li>产品(无)</li><li>方法(2,9,10)</li></ul></li></ul></li><li><p>计划游戏（制定细致度逐渐降低的计划）</p></li><li>持续集成</li><li>结对编程</li><li>隐喻（全局视图、未来影像）</li></ul><h2 id="4-微软开发过程"><a href="#4-微软开发过程" class="headerlink" title="4. 微软开发过程"></a>4. 微软开发过程</h2><ul><li><p><strong>术语</strong></p><ul><li>项目前景与项目范围</li><li>功能说明书</li><li>程序经理</li></ul></li><li><p><strong>过程原则</strong></p><ul><li>制定计划时兼顾未来的不确定因素</li><li>通过有效的风险管理减少不确定因素的影响</li><li>经常生成过度版本，并进行快速测试来提高产品的稳定性和可预测性</li><li>快速循环、递进的开发过程</li><li>从产品特性和成本能控制出发创造性的工作</li><li>创建确定的进度表</li><li>使用小型项目组并发的完成工作，并设置多个同步点</li><li>将大型项目分解为多个可管理的单元，以便快速的发布产品</li><li>用产品的前景目标和概要说明指导项目开发工作——先基线化，后冻结</li><li>避免产品走形</li><li>使用原型验证概念，进行开发前的测试</li><li>零缺陷观念</li><li>非责难式的里程碑评审会</li></ul></li><li><p><strong>组队原则</strong></p><ul><li>小型的、多元化的项目组</li><li>角色依赖、职责共享</li><li>专深的技术水平和业务技能</li><li>以产品发布为中心</li><li>明确的目标</li><li>客户的主动参与</li><li>分享产品的前景</li><li>所有人都参与设计</li><li>认真从过去的项目中吸取经验</li><li>共同管理、共同决策</li><li>项目组成员在同一地点办公</li><li>大型项目组也像小型项目组那样运作</li></ul></li><li><p><strong>微软过程生命周期</strong></p><blockquote><p>相当于 RUP 的生命周期的精简版，但是微软生命周期的特色在于其每个阶段设置的缓冲时间</p></blockquote><ul><li>构想（先启）</li><li>计划（精化）</li><li>开发（精化）</li><li>稳定（构建）</li><li>发布（产品化）</li></ul></li><li><p><strong>微软角色划分</strong></p><blockquote><p>以前的项目经理被拆分为产品经理和程序经理，因为这项目经理往往身兼两个角色，而这两个角色之间存在着矛盾。</p></blockquote><ul><li>产品经理</li><li>程序经理</li><li>开发工程师</li><li>测试工程师</li><li>用户体验人员</li><li>发布管理人员</li></ul></li><li><p><strong>角色间的关系</strong></p><ul><li>对等</li><li>相互协作的方式是交流和沟通</li></ul><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fymjksrsvlj30k40jbatu.jpg" alt="微软项目结构"></p></li><li><p><strong>角色合并原则</strong></p><ul><li>开发人员不能兼任其他角色</li><li>不能试图合并两个有明显利益冲突或制约关系的职能角色</li></ul><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fymjbpk5g0j30vj0eynmf.jpg" alt="微软组对合并原则"></p></li><li><p><strong>角色合并结论</strong></p><ul><li>最小的项目组需要 3 个成员：产品经理、程序经理、开发工程师</li></ul></li><li><p><strong>微软均衡三角形</strong></p><blockquote><p>结论：四要素之间相互制约，任何一条边的改变都会对剩余的边造成影响。</p></blockquote><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fymj353schj30bd0a10w8.jpg" alt="均衡三角形"></p></li><li><p><strong>微软项目均衡矩阵</strong><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fymjf48wkyj30vj0m17wh.jpg" alt="项目均衡矩阵"></p><ul><li>执行方法</li></ul><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fymjifl64rj30xz0d14ee.jpg" alt="执行"></p></li><li><p><strong>RUP/AP/微软过程的关系</strong></p><blockquote><p>三者相互交叉、相互重叠，又相互区别互不包含</p></blockquote><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fymjjm74dxj30p00dlara.jpg" alt="三者之间的关系"></p></li><li><p><strong>微软每日编译生成机制</strong></p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 软件开发过程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>湖南大学工程数学试题</title>
      <link href="/2018/12/24/hu-nan-da-xue-gong-cheng-shu-xue-shi-ti/"/>
      <url>/2018/12/24/hu-nan-da-xue-gong-cheng-shu-xue-shi-ti/</url>
      
        <content type="html"><![CDATA[<h1 id="1-第一套"><a href="#1-第一套" class="headerlink" title="1. 第一套"></a>1. 第一套</h1><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyhlgl7pkoj30qe0eu7c3.jpg" alt="1"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyhlj49ddsj30yb0et7c9.jpg" alt="2"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyhlk70mrpj30zj0hm7gh.jpg" alt="3"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyhllfkzglj313308xjxc.jpg" alt="4"></p><h1 id="2-第二套"><a href="#2-第二套" class="headerlink" title="2. 第二套"></a>2. 第二套</h1><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyhlmwrofrj30kf0k6gsu.jpg" alt="1"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyhlnq6kqlj30g30kijwv.jpg" alt="2"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 试卷 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>最优二叉查找树</title>
      <link href="/2018/12/23/zui-you-er-cha-cha-zhao-shu/"/>
      <url>/2018/12/23/zui-you-er-cha-cha-zhao-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="最优二叉查找树（动态规划）"><a href="#最优二叉查找树（动态规划）" class="headerlink" title="最优二叉查找树（动态规划）"></a>最优二叉查找树（动态规划）</h1><p><strong>_参考文章_</strong></p><blockquote><p><a href="https://blog.csdn.net/xiajun07061225/article/details/8088784" target="_blank" rel="noopener">https://blog.csdn.net/xiajun07061225/article/details/8088784</a></p></blockquote><h2 id="1-算法简介"><a href="#1-算法简介" class="headerlink" title="1.算法简介"></a>1.算法简介</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygsozze4hj30zn0mm45d.jpg" alt="1"></p><h2 id="2-算法分析"><a href="#2-算法分析" class="headerlink" title="2.算法分析"></a>2.算法分析</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygspvi2g7j31390ovgxn.jpg" alt="2"></p><h2 id="3-算法举例"><a href="#3-算法举例" class="headerlink" title="3.算法举例"></a>3.算法举例</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygsrny2bnj313y0mw7e3.jpg" alt="3"></p><h2 id="4-算法伪代码"><a href="#4-算法伪代码" class="headerlink" title="4.算法伪代码"></a>4.算法伪代码</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygsshdaajj31320ob7a5.jpg" alt="4"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>模式匹配算法</title>
      <link href="/2018/12/23/mo-shi-pi-pei-suan-fa/"/>
      <url>/2018/12/23/mo-shi-pi-pei-suan-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="Horspool-算法"><a href="#Horspool-算法" class="headerlink" title="Horspool 算法"></a>Horspool 算法</h1><p><strong>_参考文章_</strong></p><blockquote><p><a href="https://www.cnblogs.com/en-heng/p/5095542.html" target="_blank" rel="noopener">https://www.cnblogs.com/en-heng/p/5095542.html</a> <a href="https://blog.csdn.net/appleprince88/article/details/11881323" target="_blank" rel="noopener">https://blog.csdn.net/appleprince88/article/details/11881323</a></p></blockquote><h2 id="1-移动距离"><a href="#1-移动距离" class="headerlink" title="1.移动距离"></a>1.移动距离</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygh4xycbzj311q0n6afk.jpg" alt="1"></p><h2 id="2-算法步骤"><a href="#2-算法步骤" class="headerlink" title="2.算法步骤"></a>2.算法步骤</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygh5xofr6j30zb0hqdm5.jpg" alt="2"></p><h2 id="3-算法伪代码"><a href="#3-算法伪代码" class="headerlink" title="3.算法伪代码"></a>3.算法伪代码</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygh8z9ja0j310u0j249t.jpg" alt="3"></p><h1 id="Boyer-Moore-算法"><a href="#Boyer-Moore-算法" class="headerlink" title="Boyer-Moore 算法"></a>Boyer-Moore 算法</h1><h2 id="1-算法流程图"><a href="#1-算法流程图" class="headerlink" title="1. 算法流程图"></a>1. 算法流程图</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygixqld6hj30f30k30u9.jpg" alt="4"></p><h2 id="2-算法步骤-1"><a href="#2-算法步骤-1" class="headerlink" title="2. 算法步骤"></a>2. 算法步骤</h2><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygiy99eftj30si0i9k4b.jpg" alt="5"></p><h2 id="3-算法举例"><a href="#3-算法举例" class="headerlink" title="3. 算法举例"></a>3. 算法举例</h2><p><strong>解析</strong>：</p><blockquote><ul><li>k=2 时，后缀为 AB，此时模式串中找不到另一个 AB 串，而模式串第一个字符 B 又和 AB 串的最后一个字符匹配，因此这里为了避免错误，将 B 与 AB 中的 B 对齐, 所以 d2=5.</li><li>d2 这里的 k 代表的是匹配的个数</li></ul></blockquote><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fygiyui3fsj30va0lmtg9.jpg" alt="6"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>堆排序算法</title>
      <link href="/2018/12/22/dui-pai-xu-suan-fa/"/>
      <url>/2018/12/22/dui-pai-xu-suan-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="1-堆排序"><a href="#1-堆排序" class="headerlink" title="1. 堆排序"></a>1. 堆排序</h1><h2 id="1-1-堆的定义"><a href="#1-1-堆的定义" class="headerlink" title="1.1 堆的定义"></a>1.1 堆的定义</h2><blockquote><p><strong>堆是一棵二叉树，树中节点包含键，满足下面两个条件</strong>:</p></blockquote><ul><li><strong>树的形状为完全二叉树</strong></li><li><strong>父母的优势：每个节点的键都要大于或等于它子女的键</strong></li></ul><h2 id="1-2-自底向上堆构造算法"><a href="#1-2-自底向上堆构造算法" class="headerlink" title="1.2 自底向上堆构造算法"></a>1.2 自底向上堆构造算法</h2><blockquote><p><strong>按照自下而上，从右至左的顺序（最后的父母节点开始，到根为止）检查父母优势条件。如果不满足则调换父子结点的位置</strong>。</p></blockquote><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyfr7woq7xj31090c3gn5.jpg" alt="1"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyfre6d60lj30zb0byq4h.jpg" alt="2"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyfrdnjrxyj30z80bmjsw.jpg" alt="3"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyfrelvx0tj30z60brq4g.jpg" alt="4"></p><h2 id="1-3-删除堆中最大的键（即根节点）"><a href="#1-3-删除堆中最大的键（即根节点）" class="headerlink" title="1.3 删除堆中最大的键（即根节点）"></a>1.3 删除堆中最大的键（即根节点）</h2><blockquote><p><strong>步骤如下</strong>：</p></blockquote><ul><li><strong>把待删除结点与堆中最后一个键 K 对调。</strong></li><li><strong>执行删除操作并把堆的大小减一。</strong></li><li><strong>对删除后的堆进行调整直到满足堆的约束条件。</strong></li></ul><p><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyfro0erzwj311t0kr77e.jpg" alt="5"><br><img src="https://ws1.sinaimg.cn/large/006wCagogy1fyfroguncmj30yu0m8tam.jpg" alt="6"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>快速排序算法图解</title>
      <link href="/2018/12/22/kuai-su-pai-xu-suan-fa-tu-jie/"/>
      <url>/2018/12/22/kuai-su-pai-xu-suan-fa-tu-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="1-快速排序（过程图解）"><a href="#1-快速排序（过程图解）" class="headerlink" title="1.快速排序（过程图解）"></a>1.快速排序（过程图解）</h1><p>假设我们现在对“6 1 2 7 9 3 4 5 10 8”这个 10 个数进行排序。首先在这个序列中随便找一个数作为基准数（不要被这个名词吓到了，就是一个用来参照的数，待会你就知道它用来做啥的了）。为了方便，就让第一个数 6 作为基准数吧。接下来，需要将这个序列中所有比基准数大的数放在 6 的右边，比基准数小的数放在 6 的左边，类似下面这种排列。<br>3 1 2 5 4 6 9 7 10 8</p><p>在初始状态下，数字 6 在序列的第 1 位。我们的目标是将 6 挪到序列中间的某个位置，假设这个位置是 k。现在就需要寻找这个 k，并且以第 k 位为分界点，左边的数都小于等于 6，右边的数都大于等于 6。想一想，你有办法可以做到这点吗？</p><p>给你一个提示吧。请回忆一下冒泡排序，是如何通过“交换”，一步步让每个数归位的。此时你也可以通过“交换”的方法来达到目的。具体是如何一步步交换呢？怎样交换才既方便又节省时间呢？先别急着往下看，拿出笔来，在纸上画画看。我高中时第一次学习冒泡排序算法的时候，就觉得冒泡排序很浪费时间，每次都只能对相邻的两个数进行比较，这显然太不合理了。于是我就想了一个办法，后来才知道原来这就是“快速排序”，请允许我小小的自恋一下(^o^)。</p><p>方法其实很简单：分别从初始序列“6 1 2 7 9 3 4 5 10 8”两端开始“探测”。先从右往左找一个小于 6 的数，再从左往右找一个大于 6 的数，然后交换他们。这里可以用两个变量 i 和 j，分别指向序列最左边和最右边。我们为这两个变量起个好听的名字“哨兵 i”和“哨兵 j”。刚开始的时候让哨兵 i 指向序列的最左边（即 i=1），指向数字 6。让哨兵 j 指向序列的最右边（即 j=10），指向数字 8。</p><p><img src="http://bbs.ahalei.com/data/attachment/forum/201402/26/094811yilrz1tkzkvlrriz.png" alt="1"></p><p>首先哨兵 j 开始出动。因为此处设置的基准数是最左边的数，所以需要让哨兵 j 先出动，这一点非常重要（请自己想一想为什么）。哨兵 j 一步一步地向左挪动（即 j—），直到找到一个小于 6 的数停下来。接下来哨兵 i 再一步一步向右挪动（即 i++），直到找到一个数大于 6 的数停下来。最后哨兵 j 停在了数字 5 面前，哨兵 i 停在了数字 7 面前。</p><p><img src="http://bbs.ahalei.com/data/attachment/forum/201402/26/095430axy0qkhxxkktkktk.png" alt="2"></p><p><img src="http://bbs.ahalei.com/data/attachment/forum/201402/26/095437kdandfxhbtokk2qh.png" alt="3"></p><p>现在交换哨兵 i 和哨兵 j 所指向的元素的值。交换之后的序列如下。</p><pre><code>6  1  2  5  9 3  4  7  10  8</code></pre><p><img src="http://bbs.ahalei.com/data/attachment/forum/201402/26/095448k1kevwlz41373e7k.png" alt="4"></p><p>到此，第一次交换结束。接下来开始哨兵 j 继续向左挪动（再友情提醒，每次必须是哨兵 j 先出发）。他发现了 4（比基准数 6 要小，满足要求）之后停了下来。哨兵 i 也继续向右挪动的，他发现了 9（比基准数 6 要大，满足要求）之后停了下来。此时再次进行交换，交换之后的序列如下。</p><pre><code>6  1  2 5  4  3  9  7 10  8</code></pre><p>第二次交换结束，“探测”继续。哨兵 j 继续向左挪动，他发现了 3（比基准数 6 要小，满足要求）之后又停了下来。哨兵 i 继续向右移动，糟啦！此时哨兵 i 和哨兵 j 相遇了，哨兵 i 和哨兵 j 都走到 3 面前。说明此时“探测”结束。我们将基准数 6 和 3 进行交换。交换之后的序列如下。</p><pre><code>3  1 2  5  4  6  9 7  10  8</code></pre><p><img src="http://bbs.ahalei.com/data/attachment/forum/201402/26/095506uz7e1uuukcblhkxv.png" alt="a"></p><p><img src="http://bbs.ahalei.com/data/attachment/forum/201402/26/095514cag5fumuqqg5jnsw.png" alt="a"></p><p><img src="http://bbs.ahalei.com/data/attachment/forum/201402/26/095530e0jf6p0y6aaaw2ir.png" alt="a"></p><p>到此第一轮“探测”真正结束。此时以基准数 6 为分界点，6 左边的数都小于等于 6，6 右边的数都大于等于 6。回顾一下刚才的过程，其实哨兵 j 的使命就是要找小于基准数的数，而哨兵 i 的使命就是要找大于基准数的数，直到 i 和 j 碰头为止。<br>OK，解释完毕。现在基准数 6 已经归位，它正好处在序列的第 6 位。此时我们已经将原来的序列，以 6 为分界点拆分成了两个序列，左边的序列是“3 1 2 5 4”，右边的序列是“9 7 10 8”。接下来还需要分别处理这两个序列。因为 6 左边和右边的序列目前都还是很混乱的。不过不要紧，我们已经掌握了方法，接下来只要模拟刚才的方法分别处理 6 左边和右边的序列即可。现在先来处理 6 左边的序列现吧。</p><p>左边的序列是“3 1 2 5 4”。请将这个序列以 3 为基准数进行调整，使得 3 左边的数都小于等于 3，3 右边的数都大于等于 3。好了开始动笔吧。</p><p>如果你模拟的没有错，调整完毕之后的序列的顺序应该是。</p><pre><code>2  1  3  5  4</code></pre><p>OK，现在 3 已经归位。接下来需要处理 3 左边的序列“2 1”和右边的序列“5 4”。对序列“2 1”以 2 为基准数进行调整，处理完毕之后的序列为“1 2”，到此 2 已经归位。序列“1”只有一个数，也不需要进行任何处理。至此我们对序列“2 1”已全部处理完毕，得到序列是“1 2”。序列“5 4”的处理也仿照此方法，最后得到的序列如下。</p><pre><code>1  2  3 4  5  6 9  7  10  8</code></pre><p>对于序列“9 7 10 8”也模拟刚才的过程，直到不可拆分出新的子序列为止。最终将会得到这样的序列，如下。</p><pre><code>1  2  3 4  5  6  7  8 9  10</code></pre><p>到此，排序完全结束。细心的同学可能已经发现，快速排序的每一轮处理其实就是将这一轮的基准数归位，直到所有的数都归位为止，排序就结束了。下面上个霸气的图来描述下整个算法的处理过程。<br><img src="http://bbs.ahalei.com/data/attachment/forum/201402/25/232129ogop8gk0r8y7l70k.png" alt="aa"></p><p>快速排序之所比较快，因为相比冒泡排序，每次交换是跳跃式的。每次排序的时候设置一个基准点，将小于等于基准点的数全部放到基准点的左边，将大于等于基准点的数全部放到基准点的右边。这样在每次交换的时候就不会像冒泡排序一样每次只能在相邻的数之间进行交换，交换的距离就大的多了。因此总的比较和交换次数就少了，速度自然就提高了。当然在最坏的情况下，仍可能是相邻的两个数进行了交换。因此快速排序的最差时间复杂度和冒泡排序是一样的都是 O(N2)，它的平均时间复杂度为 O(NlogN)。</p><h1 id="2-代码"><a href="#2-代码" class="headerlink" title="2.代码"></a>2.代码</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c"># include <stdio.h>int a[101],n;//定义全局变量，这两个变量需要在子函数中使用void quicksort(int left, int right) {    int i, j, t, temp;    if(left > right)        return;    temp = a[left]; //temp中存的就是基准数    i = left;    j = right;    while(i != j) { //顺序很重要，要先从右边开始找        while(a[j] >= temp && i < j)            j--;        while(a[i] <= temp && i < j)//再找右边的            i++;        if(i < j)//交换两个数在数组中的位置        {            t = a[i];            a[i] = a[j];            a[j] = t;        }    }    //最终将基准数归位    a[left] = a[i];    a[i] = temp;    quicksort(left, i-1);//继续处理左边的，这里是一个递归的过程    quicksort(i+1, right);//继续处理右边的 ，这里是一个递归的过程}int main() {    int i;    //读入数据    scanf("%d", &n);    for(i = 1; i <= n; i++)        scanf("%d", &a[i]);    quicksort(1, n); //快速排序调用    //输出排序后的结果    for(i = 1; i < n; i++)        printf("%d ", a[i]);    printf("%d\n", a[n]);    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>翻墙技术大全</title>
      <link href="/2018/12/21/fan-qiang-ji-zhu-da-quan/"/>
      <url>/2018/12/21/fan-qiang-ji-zhu-da-quan/</url>
      
        <content type="html"><![CDATA[<h1 id="1-翻墙方法合集"><a href="#1-翻墙方法合集" class="headerlink" title="1.翻墙方法合集"></a>1.翻墙方法合集</h1><hr><p><strong>SSR 各版本下载</strong></p><blockquote><ul><li>SSR windows 版本：<a href="https://www.hyjsos.net/ssr-download/ssr-win.7z" target="_blank" rel="noopener">https://www.hyjsos.net/ssr-download/ssr-win.7z</a></li><li>SSR android 版本：<a href="https://www.hyjsos.net/ssr-download/ssr-android.apk" target="_blank" rel="noopener">https://www.hyjsos.net/ssr-download/ssr-android.apk</a></li><li>SSR MacOS 版本：<a href="https://www.hyjsos.net/ssr-download/ssr-mac.dmg" target="_blank" rel="noopener">https://www.hyjsos.net/ssr-download/ssr-mac.dmg</a></li><li>SSR iphone/ipad 版本：<a href="https://blog.hyjsos.vip/?id=3" target="_blank" rel="noopener">https://blog.hyjsos.vip/?id=3</a></li></ul></blockquote><p><strong>其他软件下载</strong></p><blockquote><ul><li>蓝灯软件下载地址 (<a href="https://github.com/getlantern/lantern/releases/tag/latest" target="_blank" rel="noopener">https://github.com/getlantern/lantern/releases/tag/latest</a>)</li><li>host 文件下载地址（<a href="https://laod.cn/hosts" target="_blank" rel="noopener">https://laod.cn/hosts</a>)</li></ul></blockquote><hr><h1 id="2-Shadowsocks-免费服务器配置见如下网址：-软件下载见上面-zip-文件）"><a href="#2-Shadowsocks-免费服务器配置见如下网址：-软件下载见上面-zip-文件）" class="headerlink" title="2. Shadowsocks 免费服务器配置见如下网址：(软件下载见上面 zip 文件）"></a>2. Shadowsocks 免费服务器配置见如下网址：(软件下载见上面 zip 文件）</h1><blockquote><ul><li>在系统图标那里找到该软件，右键“二维码扫描”，二维码见下面的网址中找到 Free SS，另外记得勾选“服务器负载均衡”和“PAC 代理模式”</li><li>免费账号请见：<a href="https://global.ishadowx.net/" target="_blank" rel="noopener">https://global.ishadowx.net/</a></li><li>收费服务器（请<a href="http://github.com/zscdumin" target="_blank" rel="noopener">QQ</a>联系本人，合租大概每人 5 元/月）</li></ul></blockquote><h1 id="3-效果截图如下"><a href="#3-效果截图如下" class="headerlink" title="3.效果截图如下"></a>3.效果截图如下</h1><p><img src="https://img-blog.csdnimg.cn/20181219223743219.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIwMDAxOTQx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="4-Android-设备支持"><a href="#4-Android-设备支持" class="headerlink" title="4. Android 设备支持"></a>4. Android 设备支持</h1><p><img src="https://raw.githubusercontent.com/ZSCDumin/VPN/master/4.png" alt=""></p><h1 id="5-觉得赞就打赏我吧"><a href="#5-觉得赞就打赏我吧" class="headerlink" title="5.觉得赞就打赏我吧"></a>5.觉得赞就打赏我吧</h1><p><img src="https://github.com/ZSCDumin/ZhiXinApp/raw/master/screenshoot/17.png" alt="image"></p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>Mybatis分页插件的局限性解决方案</title>
      <link href="/2018/12/14/mybatis-fen-ye-cha-jian-de-ju-xian-xing-jie-jue-fang-an/"/>
      <url>/2018/12/14/mybatis-fen-ye-cha-jian-de-ju-xian-xing-jie-jue-fang-an/</url>
      
        <content type="html"><![CDATA[<h1 id="Java自定义分页工具类"><a href="#Java自定义分页工具类" class="headerlink" title="Java自定义分页工具类"></a>Java自定义分页工具类</h1><h2 id="1、为什么要写这个工具类："><a href="#1、为什么要写这个工具类：" class="headerlink" title="1、为什么要写这个工具类："></a>1、为什么要写这个工具类：</h2><blockquote><p><strong>Mybatis 分页插件只能够对mapper的select返回的数据进行分页操作，而要对分页数据进行包装的话，目前只能自定义工具类了，我还没有找到合适的解决办法。</strong></p></blockquote><h2 id="2、代码实现如下："><a href="#2、代码实现如下：" class="headerlink" title="2、代码实现如下："></a>2、代码实现如下：</h2><pre class="line-numbers language-lang-java"><code class="language-lang-java">import java.util.ArrayList;import java.util.List;/** * @author ZSCDumin * @version 1.0 * @description: 自定义分页工具类：传递参数只需要(要分页的数组,当前页,每页大小) * @date 2018/12/13 21:10 */public class MyPageHelper<T> {    private List<T> list;//要分页的数组    private Integer total; //总个数    private Integer currentPage; //当前页    private Integer totalPages; //总页数    private Integer pageSize; // 每页个数大小    private Integer previousPage; //前一页    private Integer nextPage;//后一页    public Integer getPreviousPage() {        return previousPage;    }    public void setPreviousPage() {        this.previousPage = currentPage > 0 ? currentPage - 1 : currentPage;    }    public Integer getNextPage() {        return nextPage;    }    public void setNextPage() {        this.nextPage = currentPage < totalPages ? currentPage + 1 : currentPage;    }    public List<T> getList() {        return list;    }    public void setList(List<T> list) {        this.list = list;    }    public Integer getTotal() {        return total;    }    public void setTotal() {        this.total = list.size();    }    public Integer getCurrentPage() {        return currentPage;    }    public void setCurrentPage(Integer currentPage) {        this.currentPage = currentPage;    }    public Integer getTotalPages() {        return totalPages;    }    public void setTotalPages() {        this.totalPages = (int) Math.ceil(1.0 * total / pageSize);    }    public Integer getPageSize() {        return pageSize;    }    public void setPageSize(Integer pageSize) {        this.pageSize = pageSize;    }    /**     * @param list     * @param currentPage     * @param pageSize     */    public MyPageHelper(List<T> list, Integer currentPage, Integer pageSize) {        this.list = list;        this.currentPage = currentPage;        this.pageSize = pageSize;        setTotal();        setTotalPages();        setNextPage();        setPreviousPage();        getResult();    }    /**     * 获取结果     */    public void getResult() {        if (pageSize < total && pageSize > 0) {// 每页小于总数目            int start = 0, end = 0;            if (currentPage < totalPages - 1 && currentPage >= 0) {                start = currentPage * pageSize;                end = (currentPage + 1) * pageSize - 1;                setData(start, end);            } else if (currentPage == totalPages - 1) {                start = currentPage * pageSize;                end = total - 1;                setData(start, end);            }        }    }    /**     * 获取数组指定位置的元素     *     * @param start 起始位置     * @param end   截止位置     * @return     */    void setData(int start, int end) {        if (start >= 0 && end < total) {            List<T> list1 = new ArrayList<>();            for (int i = start; i <= end; i++) {                list1.add(list.get(i));            }            this.list.clear();            setList(list1);        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3、使用方式"><a href="#3、使用方式" class="headerlink" title="3、使用方式"></a>3、使用方式</h2><pre class="line-numbers language-lang-java"><code class="language-lang-java">MyPageHelper<User> myPageHelper = new MyPageHelper<>(list, pageNum, pageSize);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Java SpringBoot 分页 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CCF历年题解</title>
      <link href="/2018/12/06/ccf-li-nian-ti-jie/"/>
      <url>/2018/12/06/ccf-li-nian-ti-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="出现次数最多的数"><a href="#出现次数最多的数" class="headerlink" title="出现次数最多的数"></a>出现次数最多的数</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include<iostream>#include<cstdio>using namespace std;int main() {    int num[10001] = { 0 };    int n;    cin >> n;    for (int i = 0; i < n; i++)    {        int t;        cin >> t;        num[t] ++;    }    int max = 0, index = 0;    for (int i = 10000; i >= 0; i--)    {        if (num[i] >= max){            max = num[i];            index = i;        }    }    cout << index << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="ISBN-号码"><a href="#ISBN-号码" class="headerlink" title="ISBN 号码"></a>ISBN 号码</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include<cstring>using namespace std;int main() {    char s[20];    int num[20] = { 0 };    int index = 0;    cin >> s;    int len = strlen(s);    for (int i = 0; i < len; i++){        if (s[i] == '-'){            continue;        }        else{            num[index++] = s[i] - '0';        }    }    int sum = 0;    for (int i = 0; i < index - 1; i++){        sum += num[i] * (i + 1);    }    sum = sum % 11;    if (sum == 10 && s[len - 1] == 'X' || sum == num[index - 1]){        cout << "Right" << endl;    }    else{        if (sum == 10)            s[len - 1] = 'X';        else            s[len - 1] = sum + '0';        cout << s << endl;    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="跳一跳"><a href="#跳一跳" class="headerlink" title="跳一跳"></a>跳一跳</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>using namespace std;int main() {    int num[31];    int t,index=0;    while(1) {        cin >> t;        num[index++]=t;        if(t==0) {            break;        }    }    int sum=0;    int count =1;    for(int i=0; i<index; i++) {        if(num[i]==1) {            sum+=1;            count=1;        } else if(num[i]==2) {            sum+=count*2;            count ++;        } else {            break;        }    }    cout<<sum <<endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="碰撞的小球"><a href="#碰撞的小球" class="headerlink" title="碰撞的小球"></a>碰撞的小球</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>using namespace std;int num[105];int main() {    int dire[105];    int n, L, t;    cin >> n >> L >> t;    for (int i = 0; i < n; i++) {        cin >> num[i];        dire[i] = 1;    }    for (int i = 1; i <= t; i++) { //计时器        for (int j = 0; j < n; j++) {            //判断方向            if (num[j] == L && dire[j] == 1 || num[j] == 0 && dire[j] == -1){                dire[j] *= -1;            }            else {                for (int k = 0; k < n; k++){                    if (num[k] == num[j] && k != j){                        dire[j] *= -1;                        dire[k] *= -1;                    }                }            }            //移动            num[j] += dire[j];        }    }    for (int j = 0; j < n; j++) {//输出结果        if (j == n - 1)            cout << num[j] << endl;        else            cout << num[j] << " ";    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="最小差值"><a href="#最小差值" class="headerlink" title="最小差值"></a>最小差值</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cmath>#include <algorithm>using namespace std;int num[1005];int main() {    int n;    cin >> n;    for (int i = 0; i < n; i++){        cin >> num[i];    }    sort(num, num + n);    int min = 99999;    for (int i = 0; i < n - 1; i++){        if (num[i] == num[i + 1]){            min = 0;            break;        }        if (min > abs(num[i] - num[i + 1]))        {            min = abs(num[i] - num[i + 1]);        }    }    cout << min << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="游戏"><a href="#游戏" class="headerlink" title="游戏"></a>游戏</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cmath>#include <queue>#include <algorithm>using namespace std;int num[1005];int main() {    int N, K, num = 1;    queue<int> list;    cin >> N >> K;    for (int i = 1; i <= N; i++){        list.push(i);    }    while (list.size() > 1){        int top = list.front(); //取第一个元素        list.pop();  //删除第一个元素        if (num % K != 0 && (num % 10) != K){            list.push(top);        }        num++;    }    cout << list.front();    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="版本二-有点瑕疵-样例-3-1-通不过"><a href="#版本二-有点瑕疵-样例-3-1-通不过" class="headerlink" title="版本二(有点瑕疵,样例: 3 1 通不过)"></a>版本二(有点瑕疵,样例: 3 1 通不过)</h2><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cmath>#include <algorithm>using namespace std;int num[1005];int main() {    int n, k;    cin >> n >> k;    int resNum = n;    for (int i = 0; i < n; i++){        num[i] = i + 1;    }    int count = 0;    while (resNum > 1){        for (int i = 0; i < n; i++){            if (num[i] != -1){                count++;                if (count % k == 0 || count % 10 == k)                {                    resNum--;                    num[i] = -1;                }            }        }    }    for (int i = 0; i < n; i++){        if (num[i] != -1){            cout << num[i];            break;        }    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="修订版"><a href="#修订版" class="headerlink" title="修订版"></a>修订版</h2><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cmath>#include <algorithm>using namespace std;int num[1005];int main() {    int n, k;    cin >> n >> k;    int resNum = n;    for (int i = 0; i < n; i++){        num[i] = i + 1;    }    int count = 0;    for (int i = 0;; i++){        if (resNum <= 1){            break;        }        if (num[i%n] != -1){            count++;            if (count % k == 0 || count % 10 == k)            {                resNum--;                num[i%n] = -1;            }        }    }    for (int i = 0; i < n; i++){        if (num[i] != -1){            cout << num[i];            break;        }    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="分蛋糕"><a href="#分蛋糕" class="headerlink" title="分蛋糕"></a>分蛋糕</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cmath>#include <queue>#include <algorithm>using namespace std;int num[1005];int main() {    int n, k;    int count = 0;    cin >> n >> k;    for (int i = 0; i < n; i++){        cin >> num[i];    }    int sum = 0;    for (int i = 0; i < n; i++){        if (i == n - 1 && sum + num[i] < k){            count++;        }        else        {            sum += num[i];            if (sum >= k){                count++;                sum = 0;            }        }    }    cout << count << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="中间数"><a href="#中间数" class="headerlink" title="中间数"></a>中间数</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cmath>#include <queue>#include <algorithm>using namespace std;int num[1005];int main() {    int n;    int flag = 0;    cin >> n;    for (int i = 0; i < n; i++){        cin >> num[i];    }    for (int i = 0; i < n; i++){        int re1 = 0, re2 = 0;        for (int j = 0; j < n; j++){            if (i != j){                if (num[i] < num[j])                    re1++;                if (num[i] > num[j])                    re2++;            }        }        if (re1 == re2)        {            flag = 1;            cout << num[i] << endl;            break;        }    }    if (flag == 0)        cout << "-1" << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="最大波动"><a href="#最大波动" class="headerlink" title="最大波动"></a>最大波动</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cmath>#include <queue>#include <algorithm>using namespace std;int num[1005];int main() {    int n;    int flag = 0;    cin >> n;    for (int i = 0; i < n; i++){        cin >> num[i];    }    int max = -1;    for (int i = 0; i < n-1; i++){        if (max < abs(num[i] - num[i + 1])){            max = abs(num[i] - num[i + 1]);        }    }    cout << max << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="折点计算"><a href="#折点计算" class="headerlink" title="折点计算"></a>折点计算</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cmath>#include <queue>#include <algorithm>using namespace std;int num[1005];int main() {    int n;    cin >> n;    for (int i = 0; i < n; i++){        cin >> num[i];    }    int count = 0;    int before = num[0] > num[1] ? 0 : 1;    int after = 0;    for (int i = 1; i < n - 1; i++){        if (num[i] > num[i + 1]){            after = 0;        }        else        {            after = 1;        }        if (before != after){            count++;        }        before = after;    }    cout << count << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="整数之和"><a href="#整数之和" class="headerlink" title="整数之和"></a>整数之和</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cstring>using namespace std;int main() {    char n[30];    cin >> n;    int sum = 0;    for (int i = 0; i < strlen(n); i++){        sum += n[i] - '0';    }    cout << sum << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="数列分段"><a href="#数列分段" class="headerlink" title="数列分段"></a>数列分段</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cstring>using namespace std;int num[1005];int main() {    int n;    cin >> n;    for (int i = 0; i < n; i++){        cin >> num[i];    }    int sum = 1;    for (int i = 0; i < n-1; i++){        if (num[i] != num[i + 1]){            sum++;        }    }    cout << sum << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="图像旋转"><a href="#图像旋转" class="headerlink" title="图像旋转"></a>图像旋转</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cstring>using namespace std;int num[1005][1005];int main() {    int n, m;    cin >> n >> m;    for (int i = 0; i < n; i++){        for (int j = 0; j < m; j++){            cin >> num[i][j];        }    }    int sum = 1;    for (int i = 0; i < n - 1; i++){        if (num[i] != num[i + 1]){            sum++;        }    }    for (int i = m - 1; i >= 0; i--){        for (int j = 0; j < n; j++){            cout << num[j][i] << " ";        }        cout << endl;    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="门禁系统"><a href="#门禁系统" class="headerlink" title="门禁系统"></a>门禁系统</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cstring>using namespace std;int num[1005];int res[1005];int main() {    int n;    cin >> n;    for (int i = 0; i < n; i++){        cin >> num[i];        res[i] = 1;    }    for (int i = 1; i < n; i++){        for (int j = 0; j < i; j++){            if (num[i] == num[j])                res[i]++;        }    }    for(int i = 0; i < n; i++){        cout << res[i] << " ";    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="相邻数对"><a href="#相邻数对" class="headerlink" title="相邻数对"></a>相邻数对</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cmath>using namespace std;int num[1005];int main() {    int n;    cin >> n;    for (int i = 0; i < n; i++){        cin >> num[i];    }    int count = 0;    for (int i = 0; i < n; i++){        for (int j = 0; j < n; j++){            if (i != j)            {                if (abs(num[i] - num[j]) == 1)                {                    count++;                }            }        }    }    cout << count / 2 << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="相反数"><a href="#相反数" class="headerlink" title="相反数"></a>相反数</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cmath>using namespace std;int num[1005];int main() {    int n;    cin >> n;    for (int i = 0; i < n; i++){        cin >> num[i];    }    int count = 0;    for (int i = 0; i < n; i++){        for (int j = 0; j < n; j++){            if (i != j)            {                if (num[i] + num[j] == 0)                {                    count++;                }            }        }    }    cout << count / 2 << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="公共钥匙盒"><a href="#公共钥匙盒" class="headerlink" title="公共钥匙盒"></a>公共钥匙盒</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cmath>#include <algorithm>using namespace std;int num[1005];struct keys{    int keyNum;    int startTime;    int endTime;    int flag;}keySet[1005];int flag[1005];bool compare(keys key1, keys key2){    return key1.startTime < key2.startTime;}int main() {    int n, k;    cin >> n >> k;    int maxLength = 0;    for (int i = 0; i < k; i++){        cin >> keySet[i].keyNum >> keySet[i].startTime >> keySet[i].endTime;        keySet[i].flag = 0;        flag[i] = i + 1;        if (maxLength < keySet[i].startTime + keySet[i].endTime){            maxLength = keySet[i].startTime + keySet[i].endTime;        }    }    sort(keySet, keySet + k, compare);    /*for (int i = 0; i < k; i++){        cout << keySet[i].keyNum << " " << keySet[i].startTime << " " << keySet[i].endTime << endl;        }*/    for (int i = 1; i <= maxLength; i++){        for (int j = 1; j <= n; j++){            if (keySet[j].flag == 0 && keySet[j].startTime >= i && keySet[j].endTime <= i){                keySet[j].flag = 1;                flag[keySet[j].keyNum] = -1;            }            if (keySet[j].flag == 1 && i > keySet[j].endTime + keySet[j].startTime){                for (int k = 0; k < n; k++){                    if (flag[k] == -1){                        flag[k] = keySet[j].keyNum;                        keySet[j].flag = 0;                        break;                    }                }            }        }    }    for (int i = 0; i < n; i++){        cout << flag[i] << endl;    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="除法"><a href="#除法" class="headerlink" title="除法"></a>除法</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <algorithm>using namespace std;long long tree[101024];int n, m, a[101024];int lowbit(int x){    return -x&x;}void update(int x, int v){    for (int i = x; i <= n; i += lowbit(i))        tree[i] += v;}long long getsum(int x){    long long ans = 0;    for (int i = x; i > 0; i -= lowbit(i))        ans += tree[i];    return ans;}int main(){    int op, l, r;    int v;    cin >> n >> m;    for (int i = 1; i <= n; ++i)    {        cin >> a[i];        update(i, a[i]);    }    for (int i = 0; i < m; i++)    {        cin >> op;        if (op == 1)        {            cin >> l >> r >> v;            if (v == 1)                continue;            while (l <= r)            {                if (a[l] >= v&&a[l] % v == 0)                {                    update(l, -(a[l] - a[l] / v));                    a[l] /= v;                }                ++l;            }        }        else if (op == 2)        {            cin >> l >> r;            cout << getsum(r) - getsum(l - 1) << endl;        }    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="字符串匹配"><a href="#字符串匹配" class="headerlink" title="字符串匹配"></a>字符串匹配</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <string>#include <algorithm>using namespace std;string a[105];string str;int n, m;int main(){    string::size_type idx;    getline(cin, str);    cin >> n;    cin >> m;    getchar();    for (int i = 0; i < m; i++){        getline(cin, a[i]);    }    if (n == 0){        transform(str.begin(), str.end(), str.begin(), ::tolower);        for (int i = 0; i < m; i++){            string t = a[i];            transform(a[i].begin(), a[i].end(), a[i].begin(), ::tolower);            idx = a[i].find(str);            if (idx != string::npos){                cout << t << endl;            }        }    }    else    {        for (int i = 0; i < m; i++){            idx = a[i].find(str);            if (idx != string::npos){                cout << a[i] << endl;            }        }    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="数字排序"><a href="#数字排序" class="headerlink" title="数字排序"></a>数字排序</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <string>#include <algorithm>using namespace std;int n;struct my{    int num;    int count;}nums[1005];int compare(my s1, my s2){    if (s1.count == s2.count)        return s1.num < s2.num;    else        return s1.count > s2.count;}int main(){    int num[1005] = { 0 };    cin >> n;    for (int i = 0; i < n; i++){        int t;        cin >> t;        num[t]++;    }    int k = 0;    for (int i = 0; i < 1001; i++){        if (num[i] >= 1){            nums[k].num = i;            nums[k].count = num[i];            k++;        }    }    sort(nums, nums + k, compare);    for (int i = 0; i < k; i++){        cout << nums[i].num << " " << nums[i].count << endl;    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="Z-形扫描"><a href="#Z-形扫描" class="headerlink" title="Z 形扫描"></a>Z 形扫描</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <string>using namespace std;int n;int num[505][505];const int RIGHT = 1; //向右走const int DOWN = 2; //向下走const int LEFTDOWN = 3; //向做下走const int RIGHTUP = 4;  //向右上走#define max 505string to_String(int n){    int m = n;    int i = 0, j = 0;    char s[max];    char ss[max];    while (m > 0)    {        s[i++] = m % 10 + '0';        m /= 10;    }    s[i] = '\0';    i = i - 1;    while (i >= 0)    {        ss[j++] = s[i--];    }    ss[j] = '\0';    return ss;}void run(){    //从第一个位置开始，x为横坐标，y为纵坐标，注意x,y在二维数组中的位置    int x = 0;    int y = 0;    //输出要求有空格隔开    string result = to_String(num[y][x]) + " ";    //方向变量的初始值    int direction = 0;    //下面就开始出发走咯    while (!(x == n - 1 && y == n - 1)){//循环直至到达终点（最右下角的位置）        //先判断下一步往哪个方向走        if (direction == 0){   //为0说明还没走出第一步，所以接着应该往右边走一步            direction = RIGHT;        }        else if (direction == RIGHT){ //上一次方向向右，下一步应该向左下或者右上            if (x - 1 >= 0 && y + 1 < n){    //左下可走                direction = LEFTDOWN;            }            else {  //只能走右上了                direction = RIGHTUP;            }        }        else if (direction == DOWN){   //上一次方向向下，下一步应该向左下或者右上            if (x - 1 >= 0 && y + 1 < n){    //左下可走                direction = LEFTDOWN;            }            else {  //只能走右上了                direction = RIGHTUP;            }        }        else if (direction == LEFTDOWN){   //上一次向左下，如果可以，下一步应该继续向左下，否则 向右或者向下走            if (y + 1 < n && x - 1 >= 0){    //先判断能否继续向左下                direction = LEFTDOWN;            }            else if (y + 1 < n){  //然后判断能否向下走                direction = DOWN;            }            else {      //最后只能向右走了                direction = RIGHT;            }        }        else if (direction == RIGHTUP){    //上一次向右上，如果可以，下一步应该继续向右上，否则向右或者下走            if (x + 1 < n && y - 1 >= 0){  //先判断能否继续向右上                direction = RIGHTUP;            }            else if (x + 1 < n){  //然后判断能否向右走                direction = RIGHT;            }            else{            //最后只能向下走了                direction = DOWN;            }        }        //根据上面确定的方向来走出下一步        switch (direction){        case RIGHT: x = x + 1; break;        case DOWN: y = y + 1; break;        case LEFTDOWN: x = x - 1; y = y + 1; break;        case RIGHTUP: x = x + 1; y = y - 1; break;        }        //读取当前走到位置的数字.注意x和y的位置        result += to_String(num[y][x]) + " ";    }    cout << result << endl;}int main(){    cin >> n;    for (int i = 0; i < n; i++){        for (int j = 0; j < n; j++){            cin >> num[i][j];        }    }    run();    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="日期计算"><a href="#日期计算" class="headerlink" title="日期计算"></a>日期计算</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <string>using namespace std;int n, m;int month1[12] = { 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 };int month2[12] = { 31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 };bool isLeapYear(int year){    if (year % 4 == 0 && year % 100 != 0 || year % 400 == 0){        return true;    }    else{        return false;    }}void printMonthAndDay(int flag, int m){    int days = m;    int month = 1;    int day = 0;    int i = 0;    if (flag == 0){        while (days - month1[i] > 0)        {            days -= month1[i++];            month++;        }        cout << month << "\n" << days << endl;    }    else{        while (days - month2[i] > 0)        {            days -= month2[i++];            month++;        }        cout << month << "\n" << days << endl;    }}int main(){    cin >> n >> m;    int flag = isLeapYear(n);    printMonthAndDay(flag, m);    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="火车票"><a href="#火车票" class="headerlink" title="火车票"></a>火车票</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>using namespace std;int n;int num[105];int seat[20][5];int main(){    cin >> n;    for (int i = 0; i < n; i++)    {        cin >> num[i];    }    for (int i = 0; i < n; i++){        int res = num[i];        int t[100];        int flag = 0;        for (int j = 0; j < 20; j++){            int count = 0;            int backup[20][5] = { 0 };            for (int k = 0; k < 5; k++){                if (seat[j][k] == 0){                    backup[j][k] = 1;                    t[count++] = j * 5 + k + 1;                    for (int l = 1; l < res; l++){                        k++;                        if (seat[j][k] == 1 || k >= 5 || count >= res)                        {                            break;                        }                        else                        {                            t[count++] = j * 5 + k + 1;                            backup[j][k] = 1;                        }                    }                    if (count == res){ //座位够分                        for (int s = 0; s < count; s++){                            cout << t[s] << " ";                        }                        cout << endl;                        for (int x = 0; x < 20; x++){                            for (int y = 0; y < 5; y++){                                if (backup[x][y] == 1)                                {                                    seat[x][y] = 1;                                }                            }                        }                        flag = 1;                        break;                    }                    else{ //座位不够分                        break;                    }                }            }            if (flag == 1)                break;        }        if (flag == 0){            for (int j = 0; j < 20; j++){                for (int k = 0; k < 5; k++){                    if (seat[j][k] == 0 && res>0){                        seat[j][k] = 1;                        res--;                        cout << j * 5 + k + 1 << " ";                    }                }            }            cout << endl;        }    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="俄罗斯方块"><a href="#俄罗斯方块" class="headerlink" title="俄罗斯方块"></a>俄罗斯方块</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>const int ROW = 15;const int COL = 10;const int N = 4;int board[ROW + 1][COL];int block[N][N];struct {    int row, col;} coords[N];using namespace std;int main(){    int row, col;    // 输入数据    for (int i = 0; i < ROW; i++)    for (int j = 0; j < COL; j++)        cin >> board[i][j];    for (int i = 0; i < N; i++)    for (int j = 0; j < N; j++)        cin >> block[i][j];    cin >> col;    // 底边全放1    for (int j = 0; j < COL; j++)        board[ROW][j] = 1;    // 提取小方块坐标    int k = 0;    for (int i = N - 1; i >= 0; i--)    for (int j = 0; j < N; j++)    if (block[i][j] == 1) {        coords[k].row = i;        coords[k].col = j;        k++;    }    // 模拟小方块落下过程（选取参考点原点进行搜索，从当前坐标点开始加上小矩阵元素为1的坐标，    //判断其位置是否为1 ，位置上为1则停止）    row = 1;    col--;    bool checkflag;    for (;;) {        checkflag = false;        for (int i = 0; i < N; i++)        if (board[row + coords[i].row][col + coords[i].col] == 1) {            checkflag = true;            break;        }        if (checkflag)            break;        row++;    }    row--;    // 合并小方块到方格    for (int i = 0; i < N; i++)        board[row + coords[i].row][col + coords[i].col] = 1;    // 输出结果    for (int i = 0; i < ROW; i++) {        for (int j = 0; j < COL; j++) {            if (j != 0)                cout << " ";            cout << board[i][j];        }        cout << endl;    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="消除类游戏"><a href="#消除类游戏" class="headerlink" title="消除类游戏"></a>消除类游戏</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>using namespace std;int num[50][50];int backup[50][50];int n, m;int main(){    cin >> n >> m;    for (int i = 0; i < n; i++){        for (int j = 0; j < m; j++){            cin >> num[i][j];            backup[i][j] = num[i][j];        }    }    // 行扫描    for (int i = 0; i < n; i++){        for (int j = 0; j < m - 1; j++){            int t = num[i][j];            int count = 1;            for (int k = j + 1; k < m; k++){                if (num[i][k] != t)                    break;                else                    count++;            }            if (count >= 3){                for (int k = j; k < j + count; k++){                    backup[i][k] = 0;                }            }        }    }    // 列扫描    for (int i = 0; i < m; i++){        for (int j = 0; j < n - 1; j++){            int t = num[j][i];            int count = 1;            for (int k = j + 1; k < n; k++){                if (num[k][i] != t)                    break;                else                    count++;            }            if (count >= 3){                for (int k = j; k < j + count; k++){                    backup[k][i] = 0;                }            }        }    }    // 输出    for (int i = 0; i < n; i++){        for (int j = 0; j < m; j++){            if (j == m - 1)                cout << backup[i][j];            else                cout << backup[i][j] << " ";        }        cout << endl;    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="学生排队"><a href="#学生排队" class="headerlink" title="学生排队"></a>学生排队</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <vector>#include <algorithm>using namespace std;int n, m;vector<int> v;int find(int num){    for (int i = 0; i < v.size(); i++){        if (num == v[i])            return i+1;    }    return -1;}int main(){    cin >> n;    cin >> m;    for (int i = 0; i < n; i++){        v.push_back(i + 1);    }    for (int i = 0; i < m; i++){        int p, q;        cin >> p >> q;        int pos = find(p);        //cout << pos << endl;        if (q >= 0){            //cout << *v.begin() << endl;            v.insert(v.begin() + pos + q, p);            v.erase(v.begin() + pos - 1);        }        else{            //cout << *v.begin() << endl;            v.insert(v.begin() + pos - 1 + q, p);            v.erase(v.begin() + pos);        }    }    for (int i = 0; i < v.size(); i++){        cout << v[i] << " ";    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="地铁修建"><a href="#地铁修建" class="headerlink" title="地铁修建"></a>地铁修建</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c"># include <iostream># include <queue># include <functional>using namespace std;typedef pair<int, int> pii;const int maxn = 100000 + 100;const int INF = INT_MAX;struct node{    int from, to, dist;    node(int from, int to, int dist) :from(from), to(to), dist(dist){}};int n, m;vector<node> edges;vector<int> g[maxn];bool visited[maxn];int d[maxn];void AddEdge(int from, int to, int dist){    edges.push_back(node(from, to, dist));    g[from].push_back(edges.size() - 1);}void dij(int start){    priority_queue<pii, vector<pii>, greater<pii> >q;//d和from    for (int i = 0; i<n; i++) d[i] = INF;    d[start] = 0;    memset(visited, 0, sizeof(visited));    q.push(make_pair(0, start));    while (!q.empty()){        pii x = q.top(); q.pop();        int u = x.second;        if (visited[u]) continue;        visited[u] = true;        for (int i = 0; i<g[u].size(); i++){            node &e = edges[g[u][i]];            //if (d[e.to]>max(d[u], e.dist)){//改变松弛策略            //    d[e.to] = max(d[u], e.dist);            //    q.push(make_pair(d[e.to], e.to));            //}            if (d[e.to]> d[u] + e.dist){//改变松弛策略                d[e.to] = d[u] + e.dist;                q.push(make_pair(d[e.to], e.to));            }        }    }}int main(){    cin >> n >> m;    for (int i = 0; i<m; i++){        int a, b, c;        cin >> a >> b >> c;        AddEdge(a - 1, b - 1, c);// 只写一个代表：有向图        //AddEdge(b - 1, a - 1, c); //两个同时写代表：无向图    }    dij(0);    cout << d[n - 1] << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="棋局评估"><a href="#棋局评估" class="headerlink" title="棋局评估"></a>棋局评估</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>#include <cstring>#include <map>using namespace std;int a[9];map<int, int> mymap;int isover(){    for (int i = 0; i < 3; i++){    //检测列，仔细计算下，容易出错        if (a[i] == a[i + 3] && a[i] == a[i + 6] && a[i])            return a[i];    }    for (int i = 0; i < 9; i += 3){//检测行        if (a[i] == a[i + 1] && a[i] == a[i + 2] && a[i])            return a[i];    }    if (a[0] == a[4] && a[0] == a[8] && a[0])//检测对角        return a[0];    if (a[2] == a[4] && a[2] == a[6] && a[2])        return a[2];    return 0;}int dp(){    int aa = 0; //状态    for (int i = 0; i < 9; i++){        aa = aa * 10 + a[i];    }    if (mymap.find(aa) != mymap.end()){ //记忆化搜索，若当前状态出现过，则不再重新计算。        return mymap[aa];    }    int ct = 0;    for (int i = 0; i < 9; i++) //找空余的0    if (a[i])        ct++;    int rt = isover();    if (rt == 1) //Alice赢        return 10 - ct;    if (rt == 2) // Bob赢        return -(10 - ct);    if (ct == 9 && rt == 0) //下满了，并且未分出胜负，则平局        return 0;    int an = 0;    if (ct % 2 == 0){ //轮到Alice        an = -100;        for (int i = 0; i < 9; i++){            if (a[i] == 0){    //遍历所有空格                a[i] = 1;                int s = dp();                if (an < s){  //找到得分最高的                    an = s;                }                a[i] = 0;            }        }    }    else{   //轮到Bob        an = 100;        for (int i = 0; i < 9; i++){            if (a[i] == 0){                a[i] = 2;                int s = dp();                if (an > s){//找到得分最低的                    an = s;                }                a[i] = 0;            }        }    }    return mymap[aa] = an;}int main(){    int t;    cin >> t;    while (t--){        mymap.erase(mymap.begin(), mymap.end());        for (int i = 0; i < 9; i++)   {            cin >> a[i];        }        cout << dp() << endl;    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="最大的矩形"><a href="#最大的矩形" class="headerlink" title="最大的矩形"></a>最大的矩形</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include<iostream>#include <vector>#include <algorithm>using namespace std;int n;int num[1005];int find_min(int i, int j){    int min = 99999999;    for (int k = i; k <= j; k++){        if (num[k] < min){            min = num[k];        }    }    return min;}int main(){    cin >> n;    for (int i = 0; i < n; i++){        cin >> num[i];    }    int max = -99999;    for (int i = 0; i < n-1; i++){        for (int j = i+1; j < n; j++){            int res = find_min(i, j) * (j-i+1);            if (res > max){                max = res;            }        }    }    cout << max << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="有趣的数"><a href="#有趣的数" class="headerlink" title="有趣的数"></a>有趣的数</h1><pre class="line-numbers language-lang-c"><code class="language-lang-c">#include <iostream>using namespace std;/* 状态分析： states[i][0]表示第i位状态为0的情况0－－用了2，剩0，1，31－－用了0，2，剩1，32－－用了2，3，剩0，13－－用了0，1，2，剩34－－用了0，2，3，剩15－－全部用了*/long long states[1005][6];int main(){    long mod = 1000000007;    int n;    cin >> n;    for (int i = 0; i<6; i++)        states[0][i] = 0;    for (int i = 1; i <= n; i++)    {        int j = i - 1;        //只能以2开头，所以只存在一种情况        states[i][0] = 1;        //1、可以由第i-1步状态为0到达状态第i步的状态1        //2、可以由第i-1步状态为1到达状态第i步的状态1，此时第i位只能填2或0。        states[i][1] = (states[j][0] + states[j][1] * 2) % mod;        //1、可以由第i-1步状态为0到达状态第i步的状态2        //2、可以由第i-1步状态为2到达状态第i步的状态2，此时第i位只能填3。        states[i][2] = (states[j][0] + states[j][2]) % mod;        //1、可以由第i-1步状态为1到达状态第i步的状态3。        //2、可以由第i-1步状态为3到达状态第i步的状态3，此时第i位只能填3或1。        states[i][3] = (states[j][1] + states[j][3] * 2) % mod;        //1、可以由第i-1步状态为1或者2到达状态第i步的状态4。        //2、可以由第i-1步状态为4到达状态第i步的状态4，此时第i位只能填3或1。        states[i][4] = (states[j][1] + states[j][2] + states[j][4] * 2) % mod;        //1、第i-1步只剩一个数字到达第i步的状态,此时第i位只能填1或3。        //2、第i-1步不剩任何数字到达第i步的状态，此时此时第i位只能填3或1。        states[i][5] = (states[j][3] + states[j][4] + states[j][5] * 2) % mod;    }    cout << states[n][5] << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> CCF c </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>英语翻译作业</title>
      <link href="/2018/12/06/ying-yu-fan-yi-zuo-ye/"/>
      <url>/2018/12/06/ying-yu-fan-yi-zuo-ye/</url>
      
        <content type="html"><![CDATA[<h1 id="英语翻译作业"><a href="#英语翻译作业" class="headerlink" title="英语翻译作业"></a>英语翻译作业</h1><hr><h2 id="第一单元"><a href="#第一单元" class="headerlink" title="第一单元"></a>第一单元</h2><h3 id="英翻中"><a href="#英翻中" class="headerlink" title="英翻中"></a>英翻中</h3><ol><li>德.汤说过，一切进步，一切发展均来自挑战及由此引起的反应。没有挑战就没有反应，没有发展，没有自由。所以，我们首先应该在我们孩子的能力允许的范围内为他们开设最严格最富有挑战性的课程。</li><li>我们可以向我们的孩子提供第二个机会是允许他们有失败的权力。德.纽伊写道：“不仅是一种特权，也是一种考验。”如果没有人可以失败，那它算什么考验，算什么自由呢？美国可以向所有在高中读者完四年课程而不管其是否取得任何明显收获的学生发放毕业文凭的日子已经一去不复返了。我们现在生活在一个外变得很狭隘的世界里，我们必须同对现实保持警觉，有所认识；而现实主义要求树立一个要么成功要么失败的标准。这些话听起来很刺耳，但都是残酷的事实。如果我们剥夺了孩子的失败权力，实际上我们就剥夺了他们如实地认识世界的机会。</li></ol><h3 id="中翻英"><a href="#中翻英" class="headerlink" title="中翻英"></a>中翻英</h3><ol><li>Today’s university students are struggling to establish themselves, but they still have ambiguous feelings about their future.</li><li>A man can not find himself without finding a center beyond him. So the idealism of the undergraduate experience must help the student transcend himself.</li><li>We eagerly hope that the lessons leaned in the university will reveal themselves in our performance in the workplace and further education.</li><li>It cannot go unchallenged to say that the 4-year undergraduate experience is the only path to success in life.</li><li>We run the risk of making critical decisions, not on the basis of what we know, the findings of investigations, and the data of experiments, but on the basis of blind faith in professed experts.</li><li>Our task needs a large group of well-informed, caring young people who can band together, learn from each other, and actively participate in the four modernizations.</li><li>If it is to endure, the new school should help the students not only acquire a solid basic education and become competent in a specific field, but also be ready to commit themselves to others.</li><li>It is not too much to say that if undergraduates excessively devote themselves to examinations, the will push competence and commitment to the fringes.</li><li>I didn’t even speak to him; much less discuss the reconstruction of your school with him.</li><li>Some people think examinations are second to none, but some think examinations have a lot of disadvantages. Examinations leave us an open essential question —- what influence do examinations exert on education?</li></ol><h2 id="第二单元"><a href="#第二单元" class="headerlink" title="第二单元"></a>第二单元</h2><h3 id="英翻中-1"><a href="#英翻中-1" class="headerlink" title="英翻中"></a>英翻中</h3><ol><li>业主/企业创建者不仅进取心强，而且精力充沛。他们往往擅长于多种技能。在很多情况之下，他们即是生产专家又是营销天才或经验丰富的金融家。要接替他们的工作则需要很多的人。因此家庭企业主应当通过制定组织机构图来明确规定该企业怎样运作。参予交接过程的每个主要成员也应当制定他们自己的组织构图。然后, 对它们进行比较。各机构之间的不同点将表明管理体制上的差异、存在误会的主要方面及观念上分歧。</li><li>没有忠心耿耿雇员,很少企业能够发展壮大，即使是家庭企业也是如此。这些尽职的雇员多半担任了主要管理职务。因此，应当将关于产业继承的长远计划随时通报给他们，而主要的企业管理人员必须清楚知道他们在产业交接管理机构中的职责。改进企业的劳保福利制度以吸引和留住主要部门经理,激发他们的积极性,使他们能为企业和业主的最大利益而工作</li></ol><h3 id="中翻英-1"><a href="#中翻英-1" class="headerlink" title="中翻英"></a>中翻英</h3><ol><li>He is an experienced banker and an acknowledged trade expert, not to mention an excellent managing director.</li><li>Regardless of danger, volunteers from an Italian organization for peace have gone to Baghdad, the capital of Iraq, to form a “body shield” for the purpose of preventing the US from bombing the place.</li><li>Nobody in the family is more dedicated to operating the real estate business than Judy.</li><li>Because of the economic depression, real estate agents are in the dilemma of whether to lower prices or let sales fall off.</li><li>More often than not, Mr. Smith earns great profits by careful investment of his capital.</li><li>John did not make much of a mark in his studies at school, but he excelled at sports.</li><li>Ordrly transition of responsibilities is a condition for the long-range prosperity of a family business.</li><li>You had better have a clear picture of prospects before formulating a plan for investment.</li><li>Although sculpture is a time-consuming art, there are still some people following it as a profession.</li><li>The software company is in the midst of being transformed from an individual proprietorship to a joint venture.</li></ol><h2 id="第三单元"><a href="#第三单元" class="headerlink" title="第三单元"></a>第三单元</h2><h3 id="英翻中-2"><a href="#英翻中-2" class="headerlink" title="英翻中"></a>英翻中</h3><ol><li>在历史上，吉普车以其能适应各种路况的出众性能而著称于世。这种美名可以追溯到二战期间，当时由威利斯公司提供的最初型号的吉普车载着盟军部队驰骋于太平洋沿岸及欧洲战场。</li><li>&lt;&lt;麦氏汽车驾驶大全&gt;&gt;一书认为，“吉普”这个名字起源于美国军队决定把这种车辆叫做 GP（for General Purpose）即多功能车之意。而后，GP 这两个字母的读音被误发成为“吉普”，并成为威利斯公司享有的商标名称。</li><li>1988 年吉普为克莱斯勒公司所有，此后该公司投入了大量资金更新改造吉普车的生产设备，提高吉普车的产量并开发各种新车型应市。克莱斯勒公司称吉普车在战争年代享有的盛名以及其坚固耐用的形象无疑会有助于它在和平时期树立其作为休闲娱乐车的新形象。该公司说，吉普为休闲，越野车开发了新市场，它有强劲的 4 轮牵引装置（商业上称为 4 轮驱动），过去军用吉普车曾因此而享誉四方。</li></ol><h3 id="中翻英-2"><a href="#中翻英-2" class="headerlink" title="中翻英"></a>中翻英</h3><ol><li>The automobile was improved very rapidly after it was invented and soon displaced horses.</li><li>We may have to cut down on the number of privately owned cars and depend more on public mass transit systems because cars pollute and maim or even kill people.</li><li>While wheels (automobiles) have brought with them better or more convenient transportation, they are guilty of many sins(问题、罪行), such as air pollution, traffic accidents and traffic congestion.</li><li>Americans are noted for their love for cars and great job mobility.</li><li>If only advances in fuel quality and efficiency and in technology would radically reduce the emissions from automobiles.</li><li>A highly developed highway network has made possible the easy movement from coast to coast in the United States.</li><li>The very thought of the speed at which the beautiful avenue was constructed electrified every visitor; the road had only recently been torn up to lay drain-pipes not long ago.</li><li>Environmentalists have denounced automobiles, believing they are a major factor in the production of dirty air.</li><li>Many new residential complexes have risen up in the suburbs of metropolitan cities because of the availability of convenient public transportation.</li><li>Despite their love for cars, many people lend credence to the extensive use of the public transport system, which can cut down on traffic congestion.</li></ol><h2 id="第四单元"><a href="#第四单元" class="headerlink" title="第四单元"></a>第四单元</h2><h3 id="英翻中-3"><a href="#英翻中-3" class="headerlink" title="英翻中"></a>英翻中</h3><ol><li>一些观察家提出，我们正在看到的这种现象根本就不是什么重大变化，或许它和性革命一样，不是人们行为上的而是表达方式上的一种剧变。一位住在康涅狄格州的精神分析学家说，“也许，一直就有那么一群与众不同的人存着。只不过他们现在从隐蔽外走了出来，公开 表明了他们的观点，就像同性恋者那样。我们这一时代的潮流就是干你想干的事而不是加以掩饰。这些人身上所反映的不是什么变革而是人们现在越来越坦率直言的这样一个现象。</li><li>在最近几十年的时间里，人们渐渐地明白了一个事实，那就是：为数不多的妇女已不再接受并愿意扮演深居简出的传统母亲角色。许多人认为家庭的重要性正日益消失。妇女受教育程度的提高是造成这一文化的重要因素。如今，百分之八十的妇女完成了四年制的高中学习。而在 1940 年，完成这一阶段学习的妇女仅占百分之三十。这与现在美国妇女平均晚一年结婚有关。二十岁至二十四岁未婚者从 1960 年的 28%上升到 20 世纪 70 年代的 40%。人们推迟了生儿育女的时间，只有不到 10%的妇女是在结婚后两年内生孩子。除此之外，越来越多的妇女不想要孩子。工作、晚婚、不要孩子是近年来妇女作用发生变化的主要表现。</li></ol><h3 id="中翻英-3"><a href="#中翻英-3" class="headerlink" title="中翻英"></a>中翻英</h3><ol><li>Some professional observers believe that young people today are no longer interested in politics and causes, but rather, have become increasingly preoccupied with issues closer to themselves.</li><li>The higher a woman’s educational attainment, the more likely she is to go out of the private setting of the nuclear family and to realize herself in the community.</li><li>As far as I am concerned, what really lies behind the decision of some married couples not to start a family is that they are so narcissistic and have no margin of love to spare others.</li><li>The company put on the market a registered invention even without asking the inventor’s permission, which goes against the patent law.</li><li>Urged by some other countries, the United Nations has pressured the country to give up developing and using nuclear weapons.</li><li>According to the rule that every member should remain childless, Mr. And Ms white have no alternative but to withdraw from the Non-Parent Association, for they will attain parenthood soon.</li><li>He expects to reveal, by presenting a soap opera, the complexity implicit in real life.</li><li>In virtually every country, drug abuse, alcohol abuse and child abuse loom as most challenging social problems.</li><li>When interviewed, these elderly people rationalized why they were ambivalent about today’s young people.</li><li>Many college students are far more concerned with how to get a highly-paid job on graduation and how to receive a quick promotion in the competitive society.</li></ol><h2 id="第五单元"><a href="#第五单元" class="headerlink" title="第五单元"></a>第五单元</h2><h3 id="英翻中-4"><a href="#英翻中-4" class="headerlink" title="英翻中"></a>英翻中</h3><ol><li>在不少拉丁美洲和亚洲的国家,老年化和贫困将引起许多新问题, 而这些问题对于工业化国家来说并不陌生, 但是这些国家拥有资源少得多。在使用有限资源时所遇到伦理道德问题将更为突出,为医疗保健和养老金提供资金可能成为这些国家面临的一件棘手的事。</li><li>在许多国家,老年人的人数太少,政治上多半相当被动,以致无法成为一个能对长期政策施加有效压力来促进自身利益的团体。但随着其数量增多,这种状况正在改变，他们知道需要集结政治力量。到 2030 年将没有一个政治家大胆到敢于忽略三分之一这部份老年选民——特别老年选民一般参加投票的人数要比其他选民多。</li></ol><h3 id="中翻英-4"><a href="#中翻英-4" class="headerlink" title="中翻英"></a>中翻英</h3><ol><li>Generally, people have become more compassionate and quite a few families have taken in an orphan from the municipal orphanage.</li><li>It is a demanding task for a workingwoman to look after her parents and her children while holding down a job.</li><li>At first we were worried about their first stay in a foreign country but things there worked out much better for them.</li><li>Today’s middle-aged people have fewer children than their parents did and the aging population problem may weigh on them in about 40 years.</li><li>It is hoped that the current reform in education will better set students up to meet the challenges from society.</li><li>The government intends to transfer some of the health-care burden to the individual family but family members are not always available for the task because they cannot break away from their jobs to look after the sick elderly.</li><li>There is an increasing demand for beds in the nursing home, and we have to try every possible means to free them up.</li><li>With the large elderly population in this country, financing of health care and pensions could scare the devil out of the government.</li><li>The young couple has to make some sacrifice to avoid letting their old beloved father down.</li><li>What they had gone through in looking after their sick old father made them more compassionate, and they made a donation to the nursing home.</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 英语 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mybatis_sql片段</title>
      <link href="/2018/12/04/mybatis-sql-pian-duan/"/>
      <url>/2018/12/04/mybatis-sql-pian-duan/</url>
      
        <content type="html"><![CDATA[<h1 id="Mybatis-sql-片段使用"><a href="#Mybatis-sql-片段使用" class="headerlink" title="Mybatis sql 片段使用"></a>Mybatis sql 片段使用</h1><h2 id="1、在-mybatis-中通过使用-SQL-片段可以提高代码的重用性，如下情景："><a href="#1、在-mybatis-中通过使用-SQL-片段可以提高代码的重用性，如下情景：" class="headerlink" title="1、在 mybatis 中通过使用 SQL 片段可以提高代码的重用性，如下情景："></a>1、在 mybatis 中通过使用 SQL 片段可以提高代码的重用性，如下情景：</h2><ol><li>创建动态 SQL</li></ol><pre class="line-numbers language-lang-sql"><code class="language-lang-sql"><sql id="sql_count">select count(*)</sql><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol><li>使用代码</li></ol><pre class="line-numbers language-lang-sql"><code class="language-lang-sql"><select id="selectListCountByParam" parameterType="map" resultType="String">　　<include refid="sql_count"/> from table_name</select><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol><li>解析</li></ol><blockquote><p>在使用 sql 片段时使用 include 标签通过 sql 片段的 id 进行引用，sql 片段的 ID 在当前空间必须为唯一的。当然，sql 片段中也可以写其他的内容，只要符合语法规范都是可以的。如下：</p></blockquote><pre class="line-numbers language-lang-sql"><code class="language-lang-sql"><sql id="sql_where">　　<trim prefix="WHERE" prefixoverride="AND | OR">　　　　<if test="id != null">AND id=#{id}</if>　　　　　　<if test="name != null and name.length()>0">AND name=#{name}</if>　　　　　　<if test="gender != null and gender.length()>0">AND gender=#{gender}</if>　　</trim></sql><select id="updateByKey" parameterType="Map" resultType="List">　　　select * from user <include refid="sql_where"></select><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> mybatis </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>BIRCH聚类算法</title>
      <link href="/2018/09/09/birch-ju-lei-suan-fa/"/>
      <url>/2018/09/09/birch-ju-lei-suan-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="BIRCH聚类算法原理"><a href="#BIRCH聚类算法原理" class="headerlink" title="BIRCH聚类算法原理"></a>BIRCH聚类算法原理</h1><h2 id="1-BIRCH概述"><a href="#1-BIRCH概述" class="headerlink" title="1. BIRCH概述"></a>1. BIRCH概述</h2><blockquote><ul><li><p>BIRCH的全称是利用层次方法的平衡迭代规约和聚类（Balanced Iterative Reducing and Clustering Using Hierarchies），名字实在是太长了，不过没关系，其实只要明白它是用层次方法来聚类和规约数据就可以了。刚才提到了，BIRCH只需要单遍扫描数据集就能进行聚类，那它是怎么做到的呢？</p></li><li><p>BIRCH算法利用了一个树结构来帮助我们快速的聚类，这个数结构类似于平衡B+树，一般将它称之为聚类特征树(Clustering Feature Tree，简称CF Tree)。这颗树的每一个节点是由若干个聚类特征(Clustering Feature，简称CF)组成。从下图我们可以看看聚类特征树是什么样子的：每个节点包括叶子节点都有若干个CF，而内部节点的CF有指向孩子节点的指针，所有的叶子节点用一个双向链表链接起来。</p></li></ul></blockquote><p><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161214141510979-1110473944.png" alt=""></p><h2 id="2-聚类特征CF与聚类特征树CF-Tree"><a href="#2-聚类特征CF与聚类特征树CF-Tree" class="headerlink" title="2. 聚类特征CF与聚类特征树CF Tree"></a>2. 聚类特征CF与聚类特征树CF Tree</h2><blockquote><ul><li>在聚类特征树中，一个聚类特征CF是这样定义的：每一个CF是一个三元组，可以用（N，LS，SS）表示。其中N代表了这个CF中拥有的样本点的数量，这个好理解；LS代表了这个CF中拥有的样本点各特征维度的和向量，SS代表了这个CF中拥有的样本点各特征维度的平方和。举个例子如下图，在CF Tree中的某一个节点的某一个CF中，有下面5个样本(3,4), (2,6), (4,5), (4,7), (3,8)。则它对应的N=5， LS=(3+2+4+4+3,4+6+5+7+8)=(16,30), SS =(32+22+42+42+32+42+62+52+72+82)=(54+190)=244</li></ul></blockquote><p><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161214142636542-611911122.png" alt=""></p><blockquote><ul><li>CF有一个很好的性质，就是满足线性关系，也就是CF1+CF2=(N1+N2,LS1+LS2,SS1+SS2)。这个性质从定义也很好理解。如果把这个性质放在CF Tree上，也就是说，在CF Tree中，对于每个父节点中的CF节点，它的(N,LS,SS)三元组的值等于这个CF节点所指向的所有子节点的三元组之和。如下图所示：</li></ul></blockquote><p><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161214143717151-481214189.png" alt=""></p><blockquote><ul><li><p>从上图中可以看出，根节点的CF1的三元组的值，可以从它指向的6个子节点（CF7 - CF12）的值相加得到。这样我们在更新CF Tree的时候，可以很高效。</p></li><li><p>对于CF Tree，我们一般有几个重要参数，第一个参数是每个内部节点的最大CF数B，第二个参数是每个叶子节点的最大CF数L，第三个参数是针对叶子节点中某个CF中的样本点来说的，它是叶节点每个CF的最大样本半径阈值T，也就是说，在这个CF中的所有样本点一定要在半径小于T的一个超球体内。对于上图中的CF Tree，限定了B=7， L=5， 也就是说内部节点最多有7个CF，而叶子节点最多有5个CF。</p></li></ul></blockquote><h2 id="3-聚类特征树CF-Tree的生成"><a href="#3-聚类特征树CF-Tree的生成" class="headerlink" title="3. 聚类特征树CF Tree的生成"></a>3. 聚类特征树CF Tree的生成</h2><blockquote><ul><li><p>下面我们看看怎么生成CF Tree。我们先定义好CF Tree的参数： 即内部节点的最大CF数B， 叶子节点的最大CF数L， 叶节点每个CF的最大样本半径阈值T</p></li><li><p>在最开始的时候，CF Tree是空的，没有任何样本，我们从训练集读入第一个样本点，将它放入一个新的CF三元组A，这个三元组的N=1，将这个新的CF放入根节点，此时的CF Tree如下图：<br><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161214145741042-147956564.png" alt=""></p></li><li><p>现在我们继续读入第二个样本点，我们发现这个样本点和第一个样本点A，在半径为T的超球体范围内，也就是说，他们属于一个CF，我们将第二个点也加入CF A,此时需要更新A的三元组的值。此时A的三元组中N=2。此时的CF Tree如下图：<br><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161214150223589-1415245002.png" alt=""></p></li><li><p>此时来了第三个节点，结果我们发现这个节点不能融入刚才前面的节点形成的超球体内，也就是说，我们需要一个新的CF三元组B，来容纳这个新的值。此时根节点有两个CF三元组A和B，此时的CF Tree如下图：<br><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161214150650073-546336265.png" alt=""></p></li><li><p>当来到第四个样本点的时候，我们发现和B在半径小于T的超球体，这样更新后的CF Tree如下图：<br><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161214150838964-947659827.png" alt=""></p></li><li><p>那个什么时候CF Tree的节点需要分裂呢？假设我们现在的CF Tree 如下图， 叶子节点LN1有三个CF， LN2和LN3各有两个CF。我们的叶子节点的最大CF数L=3。此时一个新的样本点来了，我们发现它离LN1节点最近，因此开始判断它是否在sc1,sc2,sc3这3个CF对应的超球体之内，但是很不幸，它不在，因此它需要建立一个新的CF，即sc8来容纳它。问题是我们的L=3，也就是说LN1的CF个数已经达到最大值了，不能再创建新的CF了，怎么办？此时就要将LN1叶子节点一分为二了。<br><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161214151047042-954364496.png" alt=""></p></li><li><p>我们将LN1里所有CF元组中，找到两个最远的CF做这两个新叶子节点的种子CF，然后将LN1节点里所有CF sc1, sc2, sc3，以及新样本点的新元组sc8划分到两个新的叶子节点上。将LN1节点划分后的CF Tree如下图：<br><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161214152939667-962958903.png" alt=""></p></li><li><p>　如果我们的内部节点的最大CF数B=3，则此时叶子节点一分为二会导致根节点的最大CF数超了，也就是说，我们的根节点现在也要分裂，分裂的方法和叶子节点分裂一样，分裂后的CF Tree如下图：<br><img src="https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161214152939667-962958903.png" alt=""></p></li></ul><p>有了上面这一系列的图，相信大家对于CF Tree的插入就没有什么问题了，总结下CF Tree的插入：</p></blockquote><ol><li><p>从根节点向下寻找和新样本距离最近的叶子节点和叶子节点里最近的CF节点</p></li><li><p>如果新样本加入后，这个CF节点对应的超球体半径仍然满足小于阈值T，则更新路径上所有的CF三元组，插入结束。否则转入3.</p></li><li><p>如果当前叶子节点的CF节点个数小于阈值L，则创建一个新的CF节点，放入新样本，将新的CF节点放入这个叶子节点，更新路径上所有的CF三元组，插入结束。否则转入4。</p></li><li><p>将当前叶子节点划分为两个新叶子节点，选择旧叶子节点中所有CF元组里超球体距离最远的两个CF元组，分布作为两个新叶子节点的第一个CF节点。将其他元组和新样本元组按照距离远近原则放入对应的叶子节点。依次向上检查父节点是否也要分裂，如果需要按和叶子节点分裂方式相同。</p></li></ol><h2 id="4-BIRCH算法"><a href="#4-BIRCH算法" class="headerlink" title="4. BIRCH算法"></a>4. BIRCH算法</h2><blockquote><p>上面讲了半天的CF Tree，终于我们可以步入正题BIRCH算法，其实将所有的训练集样本建立了CF Tree，一个基本的BIRCH算法就完成了，对应的输出就是若干个CF节点，每个节点里的样本点就是一个聚类的簇。也就是说BIRCH算法的主要过程，就是建立CF Tree的过程。</p><p>当然，真实的BIRCH算法除了建立CF Tree来聚类，其实还有一些可选的算法步骤的，现在我们就来看看 BIRCH算法的流程。</p></blockquote><ul><li><p>将所有的样本依次读入，在内存中建立一颗CF Tree, 建立的方法参考上一节。</p></li><li><p>将第一步建立的CF Tree进行筛选，去除一些异常CF节点，这些节点一般里面的样本点很少。对于一些超球体距离非常近的元组进行合并</p></li><li>利用其它的一些聚类算法比如K-Means对所有的CF元组进行聚类，得到一颗比较好的CF Tree.这一步的主要目的是消除由于样本读入顺序导致的不合理的树结构，以及一些由于节点CF个数限制导致的树结构分裂。</li><li>利用第三步生成的CF Tree的所有CF节点的质心，作为初始质心点，对所有的样本点按距离远近进行聚类。这样进一步减少了由于CF Tree的一些限制导致的聚类不合理的情况。</li></ul><blockquote><p>从上面可以看出，BIRCH算法的关键就是步骤1，也就是CF Tree的生成，其他步骤都是为了优化最后的聚类结果。</p></blockquote><h2 id="5-BIRCH算法小结"><a href="#5-BIRCH算法小结" class="headerlink" title="5. BIRCH算法小结"></a>5. BIRCH算法小结</h2><blockquote><p>BIRCH算法可以不用输入类别数K值，这点和K-Means，Mini Batch K-Means不同。如果不输入K值，则最后的CF元组的组数即为最终的K，否则会按照输入的K值对CF元组按距离大小进行合并。</p><p>一般来说，BIRCH算法适用于样本量较大的情况，这点和Mini Batch K-Means类似，但是BIRCH适用于类别数比较大的情况，而Mini Batch K-Means一般用于类别数适中或者较少的时候。BIRCH除了聚类还可以额外做一些异常点检测和数据初步按类别规约的预处理。但是如果数据特征的维度非常大，比如大于20，则BIRCH不太适合，此时Mini Batch K-Means的表现较好。</p><p>对于调参，BIRCH要比K-Means，Mini Batch K-Means复杂，因为它需要对CF Tree的几个关键的参数进行调参，这几个参数对CF Tree的最终形式影响很大。</p><p>最后总结下BIRCH算法的优缺点：</p><blockquote><p>BIRCH算法的主要优点有：</p></blockquote></blockquote><ul><li><p>节约内存，所有的样本都在磁盘上，CF Tree仅仅存了CF节点和对应的指针。</p></li><li><p>聚类速度快，只需要一遍扫描训练集就可以建立CF Tree，CF Tree的增删改都很快。</p></li><li><p>可以识别噪音点，还可以对数据集进行初步分类的预处理</p></li></ul><blockquote><blockquote><p>BIRCH算法的主要缺点有：</p></blockquote></blockquote><ul><li><p>由于CF Tree对每个节点的CF个数有限制，导致聚类的结果可能和真实的类别分布不同.</p></li><li><p>对高维特征的数据聚类效果不好。此时可以选择Mini Batch K-Means</p></li><li><p>如果数据集的分布簇不是类似于超球体，或者说不是凸的，则聚类效果不好。</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 大数据经典算法 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Apriori算法</title>
      <link href="/2018/08/12/apriori-suan-fa/"/>
      <url>/2018/08/12/apriori-suan-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="Apriori算法解析"><a href="#Apriori算法解析" class="headerlink" title="Apriori算法解析"></a>Apriori算法解析</h1><p><img src="https://images2015.cnblogs.com/blog/659319/201511/659319-20151128123526249-2019227294.png" alt=""></p><h2 id="参考原文"><a href="#参考原文" class="headerlink" title="参考原文"></a>参考原文</h2><blockquote><p><a href="https://www.cnblogs.com/90zeng/p/apriori.html" target="_blank" rel="noopener">参考博文的文章链接</a></p></blockquote><h2 id="参考代码"><a href="#参考代码" class="headerlink" title="参考代码"></a>参考代码</h2><pre class="line-numbers language-lang-python"><code class="language-lang-python"># -*- coding: utf-8 -*-"""Apriori算法测试.@author: ZSCDumin"""def loadDataSet():    '''    创建简单的数据集    '''    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]def createC1(dataSet):    """    函数说明：C1 是大小为1的所有候选项集的集合,是不重复的frozenset集合.    """    C1 = []    for transaction in dataSet:        for item in transaction:            if not [item] in C1:                C1.append([item])    C1.sort()    return list(map(frozenset, C1))def scanD(D, Ck, minSupport):    """    函数说明：该函数用于从大小为1的所有候选项集的集合C1生成频繁项集列表L1，即retList。    数据集:D    候选项集列表:Ck    最小支持度:minSupport    返回值： 频繁项集列表：retList            包含支持度值的字典：supportData    """    ssCnt = {}    for tid in D:        for can in Ck:            if can.issubset(tid):                if not can in ssCnt:                    ssCnt[can] = 1                else:                    ssCnt[can] += 1    numItems = float(len(D))    reList = []    supportData = {}    for key in ssCnt:        # 每个项集的支持度        support = ssCnt[key] / numItems        # 将满足最小支持度的项集，加入到reList        if support >= minSupport:            reList.insert(0, key)        # 汇总支持度数据        supportData[key] = support    return reList, supportData# Aprior算法def aprioriGen(Lk, k):    '''    由初始候选项集的集合Lk生成新的生成候选项集，    k表示生成的新项集中所含有的元素个数    '''    retList = []    lenLk = len(Lk)    for i in range(lenLk):        for j in range(i + 1, lenLk):            L1 = list(Lk[i])[: k - 2]            L2 = list(Lk[j])[: k - 2]            L1.sort()            L2.sort()            if L1 == L2:                retList.append(Lk[i] | Lk[j])    return retListdef apriori(dataSet, minSupport=0.5):    # 构建初始候选项集C1    C1 = createC1(dataSet)    # 将dataSet集合化，以满足scanD的格式要求    D = list(map(set, dataSet))    # 构建初始的频繁项集，即所有项集只有一个元素    L1, suppData = scanD(D, C1, minSupport)    L = [L1]    # 最初的L1中的每个项集含有一个元素，新生成的    # 项集应该含有2个元素，所以 k=2    k = 2    while (len(L[k - 2]) > 0):        Ck = aprioriGen(L[k - 2], k)        Lk, supK = scanD(D, Ck, minSupport)        # 将新的项集的支持度数据加入原来的总支持度字典中        suppData.update(supK)        # 将符合最小支持度要求的项集加入L        L.append(Lk)        # 新生成的项集中的元素个数应不断增加        k += 1    # 返回所有满足条件的频繁项集的列表，和所有候选项集的支持度信息    return L, suppDatadef calcConf(freqSet, H, supportData, brl, minConf=0.7):    '''    计算规则的可信度，返回满足最小可信度的规则。    freqSet(frozenset):频繁项集    H(frozenset):频繁项集中所有的元素    supportData(dic):频繁项集中所有元素的支持度    brl(tuple):满足可信度条件的关联规则    minConf(float):最小可信度    '''    prunedH = []    for conseq in H:        conf = supportData[freqSet] / supportData[freqSet - conseq]        if conf >= minConf:            print(freqSet - conseq, '-->', conseq, 'conf:', conf)            brl.append((freqSet - conseq, conseq, conf))            prunedH.append(conseq)    return prunedHdef rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):    '''    对频繁项集中元素超过2的项集进行合并。    freqSet(frozenset):频繁项集    H(frozenset):频繁项集中的所有元素，即可以出现在规则右部的元素    supportData(dict):所有项集的支持度信息    brl(tuple):生成的规则    '''    m = len(H[0])    # 查看频繁项集是否大到移除大小为 m　的子集    if len(freqSet) > m + 1:        Hmp1 = aprioriGen(H, m + 1)        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)        # 如果不止一条规则满足要求，进一步递归合并        if len(Hmp1) > 1:            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)# 生成关联规则def generateRules(L, supportData, minConf=0.7):    # 频繁项集列表、包含那些频繁项集支持数据的字典、最小可信度阈值    bigRuleList = []  # 存储所有的关联规则    for i in range(1, len(L)):  # 只获取有两个或者更多集合的项目，从1,即第二个元素开始，L[0]是单个元素的        # 两个及以上的才可能有关联一说，单个元素的项集不存在关联问题        for freqSet in L[i]:            H1 = [frozenset([item]) for item in freqSet]            # 该函数遍历L中的每一个频繁项集并对每个频繁项集创建只包含单个元素集合的列表H1            if i > 1:                # 如果频繁项集元素数目超过2,那么会考虑对它做进一步的合并                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)            else:  # 第一层时，后件数为1                calcConf(freqSet, H1, supportData,                         bigRuleList, minConf)    return bigRuleListif __name__ == '__main__':    # # 导入数据集    # myDat = loadDataSet()    # # 选择频繁项集    # L, suppData = apriori(myDat)    # # 生成规则    # rules = generateRules(L, suppData, minConf=0.7)    # print("规则：", rules)    # 毒蘑菇案例分析    mushDataSet = [line.split() for line in open(        './mushroom.dat').readlines()]    L, supportData = apriori(mushDataSet, minSupport=0.3)    for item in L[3]:        if '2' in item:            print(item)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>考研经验分享</title>
      <link href="/2018/07/14/kao-yan-jing-yan-fen-xiang/"/>
      <url>/2018/07/14/kao-yan-jing-yan-fen-xiang/</url>
      
        <content type="html"><![CDATA[<h1 id="2019考研复习书籍推荐-针对数学二"><a href="#2019考研复习书籍推荐-针对数学二" class="headerlink" title="2019考研复习书籍推荐(针对数学二)"></a>2019考研复习书籍推荐(针对数学二)</h1><h2 id="1-政治"><a href="#1-政治" class="headerlink" title="1.政治"></a>1.政治</h2><ul><li>蒋中挺——复习全书+800题</li><li>任燕翔——主观题应试宝典</li><li>还有他们俩在”一直播”和”腾讯直播”的免费直播课</li></ul><h2 id="2-英语"><a href="#2-英语" class="headerlink" title="2.英语"></a>2.英语</h2><ul><li>何凯文——1575词汇</li><li>何凯文——考研英语阅读理解</li><li>何凯文——长难句解析</li><li>何凯文——写作指导</li><li>一直播</li></ul><h2 id="3-数学"><a href="#3-数学" class="headerlink" title="3.数学"></a>3.数学</h2><ul><li>汤家凤复习全书+1800题（前期看他的考研数学基础视频）</li><li>李永乐复习全书（前期不建议直接看他的，难度有点大，后面强化再看也行）</li><li>一直播</li></ul><h2 id="4-专业课"><a href="#4-专业课" class="headerlink" title="4.专业课"></a>4.专业课</h2><ul><li>C语言程序设计(谭浩强)</li><li>数据库系统概论(王珊)</li></ul><h2 id="5-考研需要注意的几点"><a href="#5-考研需要注意的几点" class="headerlink" title="5.考研需要注意的几点"></a>5.考研需要注意的几点</h2><ul><li>选择比努力更重要。</li><li>坚定自我，不要受他人的干扰。</li><li>注意把握重点，考研复习基本上没有人能够把所有的东西复习完。</li><li>以最小的代价来取得最后的结果。</li><li>考研不仅是智慧的比拼，更是体力的较量。</li><li>你认为自己能成功，才有可能成功。</li><li>做一个孤独的奋斗者，考研就是一次孤独的旅程。</li><li>不要求快，所谓的刷书的遍数不是和最后的结果成正比，结果反而更糟糕。脚踏实地，才能取得最后的成功。</li><li>坚持到最后一刻，初试只是完成了一小步，复试才是更大的挑战，其中的套路远比你想的更深。(考985的学生注意了)</li><li>任燕翔老师可以说是考研前的定心丸，说的话是真的在理，等你看了他的直播就知道了，不愧是北大的博士后，气度不凡。</li></ul><h2 id="6-考研辅导视频资料"><a href="#6-考研辅导视频资料" class="headerlink" title="6.考研辅导视频资料"></a>6.考研辅导视频资料</h2><ul><li>B站上全有，自行查看</li><li>附加资料：<a href="https://github.com/ZSCDumin/HunanUniversity" target="_blank" rel="noopener">https://github.com/ZSCDumin/HunanUniversity</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 考研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 考研 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>手写数字识别之卷积神经网络版</title>
      <link href="/2018/06/26/shou-xie-shu-zi-shi-bie-zhi-juan-ji-shen-jing-wang-luo-ban/"/>
      <url>/2018/06/26/shou-xie-shu-zi-shi-bie-zhi-juan-ji-shen-jing-wang-luo-ban/</url>
      
        <content type="html"><![CDATA[<h1 id="参考代码如下："><a href="#参考代码如下：" class="headerlink" title="参考代码如下："></a>参考代码如下：</h1><pre class="line-numbers language-lang-python"><code class="language-lang-python">import numpyfrom keras.datasets import mnistfrom keras.models import Sequentialfrom keras.layers import Densefrom keras.layers import Dropoutfrom keras.layers import Flattenfrom keras.layers.convolutional import Conv2Dfrom keras.layers.convolutional import MaxPooling2Dfrom keras.utils import np_utilsfrom keras import backend as K   # backend 是一个后端引擎，主要有三种：Theano/Tensorflow/CNTKK.set_image_dim_ordering('th') # th与tf的区别就是参数填写位置的区别: th(28,28,3), tf(3,28,28) 【3代表通道数，其他两个参数代表图片像素大小】<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 随机种子确保结果可再现seed = 7numpy.random.seed(seed)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 加载数据(X_train, y_train), (X_test, y_test) = mnist.load_data() # X_train 代表一张图片，y_train 代表图片对应的数字；X_test 代表一张图片，y_test 代表图片对应的数字# 重新改变大小为： [样本数目][通道数][图片宽][图片高]X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 将灰度值0-255范围归一化映射为0-1之间X_train = X_train / 255X_test = X_test / 255# 模型的输出是对每个类别的打分预测，对于分类结果从0-9的每个类别都有一个预测分值，表示将模型输入预测为该类的概率大小，概率越大可信度越高。# 由于原始的数据标签是0-9的整数值，通常将其表示成0ne-hot向量。如第一个训练数据的标签为5，one-hot表示为[0,0,0,0,0,1,0,0,0,0]。y_train = np_utils.to_categorical(y_train)y_test = np_utils.to_categorical(y_test)num_classes = y_test.shape[1] # y_test.shape(10000,10)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 定义模型函数def baseline_model():    # 创建模型    model = Sequential()    # 设置模型参数    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu')) # 32个filter ,每个filter大小为5 x 5；单通道，图片大小28 x 28    model.add(MaxPooling2D(pool_size=(2, 2))) # 最大池化矩阵 2 x 2，池化的最主要作用就是压缩数据和参数。    model.add(Dropout(0.3))  # 控制需要断开的链接的比例，可以减轻过拟合现象，一般设为0.3或者0.5。    model.add(Flatten())# Flatten层用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡。    model.add(Dense(128, activation='relu')) # 全连接层128个单元    model.add(Dense(num_classes, activation='softmax')) # 输出层只能为10个单元    # 编译模型    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #选择了交叉编译，Adam优化器    return model<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 开始编译模型model = baseline_model()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 训练模型model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)# 评估模型loss , scores = model.evaluate(X_test, y_test, verbose=1)# 输出Loss值和评分print("Loss: ", loss)print("scores: ", scores)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Train on 60000 samples, validate on 10000 samplesEpoch 1/10 - 6s - loss: 0.2400 - acc: 0.9314 - val_loss: 0.0837 - val_acc: 0.9740Epoch 2/10 - 6s - loss: 0.0779 - acc: 0.9765 - val_loss: 0.0482 - val_acc: 0.9843Epoch 3/10 - 6s - loss: 0.0560 - acc: 0.9827 - val_loss: 0.0431 - val_acc: 0.9861Epoch 4/10 - 6s - loss: 0.0433 - acc: 0.9866 - val_loss: 0.0423 - val_acc: 0.9857Epoch 5/10 - 6s - loss: 0.0363 - acc: 0.9883 - val_loss: 0.0333 - val_acc: 0.9884Epoch 6/10 - 6s - loss: 0.0301 - acc: 0.9906 - val_loss: 0.0310 - val_acc: 0.9893Epoch 7/10 - 6s - loss: 0.0246 - acc: 0.9922 - val_loss: 0.0316 - val_acc: 0.9888Epoch 8/10 - 6s - loss: 0.0232 - acc: 0.9927 - val_loss: 0.0296 - val_acc: 0.9896Epoch 9/10 - 6s - loss: 0.0195 - acc: 0.9937 - val_loss: 0.0284 - val_acc: 0.9906Epoch 10/10 - 6s - loss: 0.0164 - acc: 0.9949 - val_loss: 0.0282 - val_acc: 0.991110000/10000 [==============================] - 1s 85us/stepLoss:  0.0281819745783scores:  0.9911</code></pre>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>谷歌翻译函数实现</title>
      <link href="/2018/05/10/gu-ge-fan-yi-han-shu-shi-xian/"/>
      <url>/2018/05/10/gu-ge-fan-yi-han-shu-shi-xian/</url>
      
        <content type="html"><![CDATA[<h1 id="谷歌翻译函数实现"><a href="#谷歌翻译函数实现" class="headerlink" title="谷歌翻译函数实现"></a>谷歌翻译函数实现</h1><h2 id="代码如下："><a href="#代码如下：" class="headerlink" title="代码如下："></a>代码如下：</h2><pre class="line-numbers language-lang-C#"><code class="language-lang-C#">using System;using System.Collections.Generic;using System.IO;using System.Linq;using System.Net;using System.Text;using System.Threading.Tasks;using System.Security.Cryptography.X509Certificates;using System.Net.Security;using System.Text.RegularExpressions;namespace ConsoleApplication1{    class Program    {        static void Main(string[] args)        {            string text = "Artificial intelligence is a branch of computer science. Artificial intelligence is a branch of computer science.";            string text1 = "Artificial [intelligence] is a branch of computer science.";            string text2 = "Artificial intelligence is a branch of computer science Tom said.";            Console.WriteLine(googleTranslation(text));            Console.WriteLine(googleTranslation(text1));            Console.WriteLine(googleTranslation(text2));        }        public static string googleTranslation(string text)        {            if (text == "" || text == null)            {                return "";            }            else            {                string result = "";                string url = "https://translate.google.cn/translate_a/single?client=gtx&sl=en&tl=zh-CN&dt=t&q=" + text;                string jsonData = GetInfo(url);                string pattern = "\"([^\"]*)\"";                int count = Regex.Matches(jsonData, pattern).Count;                MatchCollection matches = Regex.Matches(jsonData, pattern);                for (int i = 0; i < count - 1; i += 2)                {                    result += matches[i].Value.Trim().Replace("\"", "");                }                return result;            }        }        public static string GetInfo(string url)        {            ServicePointManager.ServerCertificateValidationCallback = new RemoteCertificateValidationCallback(CheckValidationResult);            //访问http方法              string strBuff = "";            Uri httpURL = new Uri(url);            ///HttpWebRequest类继承于WebRequest，并没有自己的构造函数，需通过WebRequest的Creat方法建立，并进行强制的类型转换                 HttpWebRequest httpReq = (HttpWebRequest)WebRequest.Create(httpURL);            ///通过HttpWebRequest的GetResponse()方法建立HttpWebResponse,强制类型转换                 HttpWebResponse httpResp = (HttpWebResponse)httpReq.GetResponse();            ///GetResponseStream()方法获取HTTP响应的数据流,并尝试取得URL中所指定的网页内容                 ///若成功取得网页的内容，则以System.IO.Stream形式返回，若失败则产生ProtoclViolationException错误。在此正确的做法应将以下的代码放到一个try块中处理。这里简单处理                 Stream respStream = httpResp.GetResponseStream();            ///返回的内容是Stream形式的，所以可以利用StreamReader类获取GetResponseStream的内容，并以                 //StreamReader类的Read方法依次读取网页源程序代码每一行的内容，直至行尾（读取的编码格式：UTF8）                 StreamReader respStreamReader = new StreamReader(respStream, Encoding.UTF8);            strBuff = respStreamReader.ReadToEnd();            return strBuff;        }        public static bool CheckValidationResult(object sender, X509Certificate certificate, X509Chain chain, SslPolicyErrors errors)        {            //直接确认，否则打不开              return true;        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>数据库系统概论</title>
      <link href="/2018/03/28/shu-ju-ku-xi-tong-gai-lun/"/>
      <url>/2018/03/28/shu-ju-ku-xi-tong-gai-lun/</url>
      
        <content type="html"><![CDATA[<h1 id="数据库系统概论复习知识点"><a href="#数据库系统概论复习知识点" class="headerlink" title="数据库系统概论复习知识点"></a>数据库系统概论复习知识点</h1><h4 id="1、数据-数据库-数据库管理系统-数据库系统的概念："><a href="#1、数据-数据库-数据库管理系统-数据库系统的概念：" class="headerlink" title="1、数据/数据库/数据库管理系统/数据库系统的概念："></a>1、数据/数据库/数据库管理系统/数据库系统的概念：</h4><blockquote><ul><li>数据库系统是一个人-机系统，而数据库是用于存储数据的。</li></ul></blockquote><h4 id="2、数据库系统的好处："><a href="#2、数据库系统的好处：" class="headerlink" title="2、数据库系统的好处："></a>2、数据库系统的好处：</h4><blockquote><ul><li>提高开发效率</li><li>少量修改应用程序</li><li>减轻DBA维护负担</li></ul></blockquote><h4 id="3、文件系统和数据库系统的区别："><a href="#3、文件系统和数据库系统的区别：" class="headerlink" title="3、文件系统和数据库系统的区别："></a>3、文件系统和数据库系统的区别：</h4><blockquote><ul><li><p><strong>区别</strong></p><pre><code>- 前者冗余度大，后者相反- 前者共享性差，后者相反- 前者独立性差，后者相反- 前者面向某一个应用，后者面向整个组织或企业- 文件记录有结构，整体无结构- 数据库数据是完全结构化的 </code></pre></li><li><p><strong>联系</strong> </p><pre><code>- 都是管理数据的软件- 数据库中数据的组织和存储通过文件系统来实现</code></pre></li></ul></blockquote><h4 id="4、数据库系统的特点"><a href="#4、数据库系统的特点" class="headerlink" title="4、数据库系统的特点"></a>4、数据库系统的特点</h4><blockquote><ul><li>数据结构化</li><li>数据的共享性高，冗余度低，易扩充</li><li>数据的独立性高</li><li>数据由DBMS统一管理和控制</li></ul></blockquote><h4 id="5、DBMS的主要功能·"><a href="#5、DBMS的主要功能·" class="headerlink" title="5、DBMS的主要功能·"></a>5、DBMS的主要功能·</h4><blockquote><ul><li>数据库定义功能</li><li>数据组织、存储和管理功能</li><li>数据操纵功能</li><li>数据库的事务管理和运行管理</li><li>数据库的建立和维护功能</li><li>其他功能，如不同数据库之间的互访和互操作功能</li></ul></blockquote><h4 id="6、概念模型及其作用"><a href="#6、概念模型及其作用" class="headerlink" title="6、概念模型及其作用"></a>6、概念模型及其作用</h4><blockquote><ul><li><strong>定义：</strong>用于信息世界的建模</li><li><strong>作用：</strong>方便设计人员与用户交流</li></ul></blockquote><h4 id="7、数据模型的概念、数据模型的作用和数据模型的三要素"><a href="#7、数据模型的概念、数据模型的作用和数据模型的三要素" class="headerlink" title="7、数据模型的概念、数据模型的作用和数据模型的三要素"></a>7、数据模型的概念、数据模型的作用和数据模型的三要素</h4><blockquote><ul><li>概念：用于对现实世界的抽象的工具，用于提供信息表示和操作手段的形式架构</li><li>作用：数据模型是数据库系统的基础</li><li>三要素：数据结构、数据操作、完整性约束</li></ul></blockquote><h4 id="8、层次模型定义及优-缺点"><a href="#8、层次模型定义及优-缺点" class="headerlink" title="8、层次模型定义及优/缺点"></a>8、层次模型定义及优/缺点</h4><blockquote><ul><li><strong>定义：</strong><pre><code> - 有且仅有一个节点有双亲，代表根节点 - 根以外的其他节点有且仅有一个双亲节点</code></pre></li><li><strong>优点：</strong><pre><code> -  数据结构简单清晰 -  查询效率高 -  良好的完整性支持</code></pre></li><li><strong>缺点：</strong><pre><code> - 无法表达非层次性的联系 - 对用户要求比较高</code></pre></li></ul></blockquote><h4 id="9、网状模型定义及优-缺点"><a href="#9、网状模型定义及优-缺点" class="headerlink" title="9、网状模型定义及优/缺点"></a>9、网状模型定义及优/缺点</h4><blockquote><ul><li><strong>定义：</strong><pre><code> - 允许一个以上的节点无双亲 - 一个节点可以有多于一个的双亲</code></pre></li><li><strong>优点：</strong><pre><code> -  能直更为直接描述世界 -  存取效率高</code></pre></li><li><strong>缺点：</strong><pre><code> - 结构复杂 - 数据定义语言、数据操纵语言比较复杂，要求用户掌握数据库结构和存取路径，不容易使用</code></pre></li></ul></blockquote><h4 id="10、关系模型的优点-缺点"><a href="#10、关系模型的优点-缺点" class="headerlink" title="10、关系模型的优点/缺点"></a>10、关系模型的优点/缺点</h4><blockquote><ul><li><strong>优点：</strong><pre><code> -  严格的数学基础 -  概念单一 -  存取路径对用户透明，具有更高的数据独立性、更好的安全保密性，简化开发的工作</code></pre></li><li><strong>缺点：</strong><pre><code> -  查询效率不如非关系数据模型</code></pre></li></ul></blockquote><h4 id="11、三级模式的定义及其优点-缺点"><a href="#11、三级模式的定义及其优点-缺点" class="headerlink" title="11、三级模式的定义及其优点/缺点"></a>11、三级模式的定义及其优点/缺点</h4><blockquote><ul><li><strong>定义：</strong><pre><code> - 外模式——子模式或用户模式 - 模式——逻辑模式 - 内模式——存储模式</code></pre></li><li><strong>优点：</strong><pre><code> -  外模式/模式映象和模式/内模式映像（两级映像）使得数据具有较高的逻辑独立性和物理独立性</code></pre></li></ul></blockquote><h4 id="12、数据库系统的组成"><a href="#12、数据库系统的组成" class="headerlink" title="12、数据库系统的组成"></a>12、数据库系统的组成</h4><blockquote><ul><li>数据库</li><li>数据库管理系统</li><li>应用系统</li><li>数据库管理员</li><li>用户</li></ul></blockquote><h4 id="13、数据库管理员、系统分析员、数据库设计人员、应用程序员的职责"><a href="#13、数据库管理员、系统分析员、数据库设计人员、应用程序员的职责" class="headerlink" title="13、数据库管理员、系统分析员、数据库设计人员、应用程序员的职责"></a>13、数据库管理员、系统分析员、数据库设计人员、应用程序员的职责</h4><blockquote><ul><li><strong>数据库管理员：</strong><pre><code> - 决定数据库信息和内容 - 决定数据库的存储结构和存取策略 - 定义数据安全性和完整性要求 - 监控数据库使用和运行 - 数据库改进和重组</code></pre></li><li><strong>系统分析员：</strong><pre><code> - 应用系统的需求分析和规范说明 - 数据库系统的概要设计</code></pre></li><li><strong>数据库设计人员：</strong><pre><code> - 数据的确定和数据库各级模式的设计 - 参与用户需求调查和系统分析，然后进行数据库设计</code></pre></li><li><strong>应用程序员的职责：</strong> <pre><code> - 设计和编写应用系统的程序设计，并进行调试和安装</code></pre></li></ul></blockquote><h4 id="14、ALPHA语言"><a href="#14、ALPHA语言" class="headerlink" title="14、ALPHA语言"></a>14、ALPHA语言</h4><blockquote><ul><li>语法格式：GET 工作空间名 (表达式1) [：条件] [DOWN | UP 表达式2 ] </li><li>例子：<pre><code> - 查询信息系(IS)中年龄小于20岁的学生的学号和年龄     - GET  W  (Student.Sno，Student.Sage): Student.Sdept=&#39;IS&#39;∧ Student.Sage&lt;20 - 查询计算机科学系(CS)学生的学号、年龄，结果按年龄降序排序     - GET  W  (Student.Sno，Student.Sage): Student.Sdept=&#39;CS‘ DOWN Student.Sage </code></pre></li></ul></blockquote><h4 id="15、SQL语言特点"><a href="#15、SQL语言特点" class="headerlink" title="15、SQL语言特点"></a>15、SQL语言特点</h4><blockquote><ul><li>综合统一：数据定义、操纵、控制于一体</li><li>高度非过程化</li><li>面向集合的操作方式</li><li>自含式语言、嵌入式语言</li><li>语言简洁，易学易用</li></ul></blockquote><h4 id="16、RESTRICT和CASCADE的区别"><a href="#16、RESTRICT和CASCADE的区别" class="headerlink" title="16、RESTRICT和CASCADE的区别"></a>16、RESTRICT和CASCADE的区别</h4><blockquote><ul><li>RESTRICT：表的删除是有限制的，如有依赖，则删除失败</li><li>CASCADE：表的删除是没有限制的，如有依赖，一并删除</li></ul></blockquote><h4 id="17、视图的优点"><a href="#17、视图的优点" class="headerlink" title="17、视图的优点"></a>17、视图的优点</h4><blockquote><ul><li>简化用户操作</li><li>多角度看待同一数据</li><li>一定的逻辑独立性</li><li>安全保护</li></ul></blockquote><h4 id="18、视图的更新"><a href="#18、视图的更新" class="headerlink" title="18、视图的更新"></a>18、视图的更新</h4><blockquote><ul><li>基本表的行列子集视图一般可更新</li><li>若视图的属性来自聚集函数、表达式，则肯定不可更新</li></ul></blockquote><h4 id="19、数据库安全性控制的常用方法与技术"><a href="#19、数据库安全性控制的常用方法与技术" class="headerlink" title="19、数据库安全性控制的常用方法与技术"></a>19、数据库安全性控制的常用方法与技术</h4><blockquote><ul><li>用户身份鉴别</li><li>多层存取控制</li><li>视图技术</li><li>审计</li><li>数据加密</li></ul></blockquote><h4 id="20、自主存取控制、强制存取控制"><a href="#20、自主存取控制、强制存取控制" class="headerlink" title="20、自主存取控制、强制存取控制"></a>20、自主存取控制、强制存取控制</h4><blockquote><ul><li>自主存取控制(B2)：各个用户对不同数据对象的存取权限</li><li>强制存取控制(B2)：每个数据对象被标以一定的密级，每个用户也被授予某一个级别的许可证</li><li>自主的含义：用户可以自主地将权限授予别人</li></ul></blockquote><h4 id="21、权限授予与回收"><a href="#21、权限授予与回收" class="headerlink" title="21、权限授予与回收"></a>21、权限授予与回收</h4><blockquote><ul><li>GRANT语句的一般格式： <pre><code> GRANT &lt;权限&gt;[,&lt;权限&gt;]...   ON &lt;对象类型&gt; &lt;对象名&gt;[,&lt;对象类型&gt; &lt;对象名&gt;]…  TO &lt;用户&gt;[,&lt;用户&gt;]...  [WITH GRANT OPTION]; </code></pre></li><li>WITH GRANT OPTION子句: <pre><code> 指定：可以再授予  没有指定：不能传播</code></pre></li><li>将角色R1授予用户U1，并且U1可继续授权给其他用户<pre><code> GRANT R1 TO U1 WITH ADMIN OPTION</code></pre></li></ul></blockquote><h4 id="22、MAC机制中主体、客体、敏感度标记的含义"><a href="#22、MAC机制中主体、客体、敏感度标记的含义" class="headerlink" title="22、MAC机制中主体、客体、敏感度标记的含义"></a>22、MAC机制中主体、客体、敏感度标记的含义</h4><blockquote><ul><li>主体：系统中的活动实体，包括实际用户和用户进程</li><li>客体：系统中的被动实体，包括文件、基本表、视图、索引</li><li>敏感度标记：绝密、机密、可信、公开</li><li>主体敏感度标记：许可证级别</li><li>客体敏感度标记：密级</li></ul></blockquote><h4 id="23、DBMS的完整性控制机制的三方面功能"><a href="#23、DBMS的完整性控制机制的三方面功能" class="headerlink" title="23、DBMS的完整性控制机制的三方面功能"></a>23、DBMS的完整性控制机制的三方面功能</h4><blockquote><ul><li>定义功能</li><li>检查功能</li><li>违约处理功能</li></ul></blockquote><h4 id="24、定义完整性约束"><a href="#24、定义完整性约束" class="headerlink" title="24、定义完整性约束"></a>24、定义完整性约束</h4><blockquote><ul><li>CONSTRAINT 名称 CHECK (条件)</li><li>constraint 名称 foreign key(Deptno) references DEPT(Deptno)</li></ul></blockquote><h4 id="25、断言"><a href="#25、断言" class="headerlink" title="25、断言"></a>25、断言</h4><blockquote><ul><li>创建断言的语句格式<br>   CREATE ASSERTION&lt;断言名&gt;<check 子句=""></check></li><li>示例<pre><code>CREATE ASSERTION ASSE_SC_CNUM1 CHECK(60 &gt;= ALL    (SELECT count(*)     FROM SC    GROUP by cno));</code></pre></li></ul></blockquote><h4 id="26、数据库设计的过程"><a href="#26、数据库设计的过程" class="headerlink" title="26、数据库设计的过程"></a>26、数据库设计的过程</h4><blockquote><ul><li>需求分析</li><li>概念结构设计(模式)</li><li>逻辑结构设计(外模式)</li><li>数据库物理设计(内模式)</li><li>数据库实施</li><li>数据库运维</li></ul></blockquote><h4 id="27、需求分析阶段的设计目标？调查的内容是什么？"><a href="#27、需求分析阶段的设计目标？调查的内容是什么？" class="headerlink" title="27、需求分析阶段的设计目标？调查的内容是什么？"></a>27、需求分析阶段的设计目标？调查的内容是什么？</h4><blockquote><ul><li>目标：了解原系统的工作概况，明确用户需求，确定新系统的功能</li><li>内容：“数据“ 和 “处理”<ul><li>信息需求</li><li>处理要求</li><li>安全性与完整性要求</li></ul></li></ul></blockquote><h4 id="28、数据字典的内容和作用："><a href="#28、数据字典的内容和作用：" class="headerlink" title="28、数据字典的内容和作用："></a>28、数据字典的内容和作用：</h4><blockquote><ul><li>数据项、数据结构、数据流、数据存储、处理过程</li><li>对数据的描述，在需求分析阶段建立，概念设计的基础，不断修改、充实、完善</li></ul></blockquote><h4 id="29、数据库的概念结构的定义、特点和设计策略"><a href="#29、数据库的概念结构的定义、特点和设计策略" class="headerlink" title="29、数据库的概念结构的定义、特点和设计策略"></a>29、数据库的概念结构的定义、特点和设计策略</h4><blockquote><ul><li>定义：信息世界的结构，既概念模型</li><li>特点：<ul><li>真实反映</li><li>易于理解</li><li>易于转换（成网状、层次）</li><li>易于更改</li></ul></li><li>策略：<ul><li>自顶向上</li><li>自底向上</li><li>逐步扩张</li><li>混合策略</li></ul></li></ul></blockquote><h4 id="30、逻辑结构设计及其设计步骤"><a href="#30、逻辑结构设计及其设计步骤" class="headerlink" title="30、逻辑结构设计及其设计步骤"></a>30、逻辑结构设计及其设计步骤</h4><blockquote><ul><li>将E-R模型转换为DBMS所支持的数据模型相符合的逻辑结构</li><li>步骤：<ul><li>概念模型—&gt;关系模型</li><li>对数据模型优化</li></ul></li></ul></blockquote><h4 id="31、规范化理论对数据库设计的意义"><a href="#31、规范化理论对数据库设计的意义" class="headerlink" title="31、规范化理论对数据库设计的意义"></a>31、规范化理论对数据库设计的意义</h4><blockquote><ul><li>为判断关系模式的优劣提供标准</li><li>指导关系数据模型的优化 </li><li>预测模式可能出现的问题</li><li>提供自动产生各种模式的算法工具</li><li>提供严格的理论基础</li></ul></blockquote><h4 id="32、数据库物理设计的内容和步骤"><a href="#32、数据库物理设计的内容和步骤" class="headerlink" title="32、数据库物理设计的内容和步骤"></a>32、数据库物理设计的内容和步骤</h4><blockquote><ul><li>为逻辑数据模型选取一个最适合应用要求的物理结构</li><li>步骤：<ul><li>确定数据库的物理结构，主要指存取方法和存储结构</li><li>对物理结构进行评价，重点是时间和空间效率</li></ul></li></ul></blockquote><h4 id="33、为什么要进行数据库的再组织和重构造"><a href="#33、为什么要进行数据库的再组织和重构造" class="headerlink" title="33、为什么要进行数据库的再组织和重构造"></a>33、为什么要进行数据库的再组织和重构造</h4><blockquote><ul><li>再组织：重新安排存储位置、回收垃圾、减少指针链 </li><li>重构造：部分修改模式和内模式，既修改逻辑和物理结构</li><li>原因：物理存储变坏，降低了存取效率，数据库性能下降，应用需求改变了，实体间的联系发生了变化</li></ul></blockquote><h4 id="34、范式理论"><a href="#34、范式理论" class="headerlink" title="34、范式理论"></a>34、范式理论</h4><blockquote><ul><li>非平凡的函数依赖：X→Y，但Y⊈X<ul><li>(Sno，Cno) ——&gt; Grade</li></ul></li><li>平凡的函数依赖：X→Y，但Y⊆X <ul><li>(Sno，Cno) ——&gt; Sno</li><li>(Sno，Cno) ——&gt; Cno</li></ul></li><li>传递函数依赖<ul><li>(Sno，Cno) ——&gt; Mname</li></ul></li><li>候选码是最小的超码，超码相对比较大</li><li>1NF：(表中不含表)<ul><li>强调的是列的原子性，即列不能够再分成其他几列。</li></ul></li><li>2NF：(消除部分函数依赖)<ul><li>若关系模式R∈1NF，并且每一个非主属性都完全函数依赖于R的码，则R∈2NF。</li><li>例子：<br>S-L-C(Sno, Cno, Sdept, Sloc, Grade) ∈1NF<br>S-L-C(Sno, Cno, Sdept, Sloc, Grade) ∈ 2NF<br>非主属性 Sdept 和 Sloc 部分函数依赖于码(Sno, Cno)</li></ul></li><li>3NF：(消除传递函数依赖)<ul><li>符合2NF，另外非主属性必须直接依赖于主属性，不能存在传递依赖。</li></ul></li><li>BCNF：(消除主属性对码的部分函数依赖以及传递函数依赖)<ul><li>符合3NF，并且主属性不依赖于主属性 </li><li>在满足第三范式的基础上，且不允许主键的一部分被另一部分或其它部分决定。</li><li>特定：<ul><li>满足第三范式。</li><li>所有非主属性对每一个码都是完全函数依赖。</li><li>所有的主属性对每一个不包含它的码，也是完全函数依赖。</li><li>没有任何属性完全函数依赖于飞码的任何一组属性。</li></ul></li><li>示例：（以下例子 不符合 第BCNF范式）<br>   <strong>学生       老师        课程</strong><pre><code>  Stu      Teacher      Course  张三       李开复       数据库  假设：每个老师只教一门课   候选码：   (Stu,Teacher)-&gt;Course                           (Stu,Course)-&gt;Teacher   这两个码由两个属性组成，而且它们是相互交叉的，所以不存在传递依赖，所以为3NF   但是由于：Teacher-&gt;Course，（主键的一部分被另一部分决定），所以不符合BCNF</code></pre></li></ul></li></ul></blockquote><h4 id="35、求闭包"><a href="#35、求闭包" class="headerlink" title="35、求闭包"></a>35、求闭包</h4><p><img src="./1520063124413.png" alt="Alt text"></p><p><img src="./1520062779805.png" alt="Alt text"></p><p><img src="./1520062714428.png" alt="Alt text"></p><h4 id="36、最小依赖集"><a href="#36、最小依赖集" class="headerlink" title="36、最小依赖集"></a>36、最小依赖集</h4><p><img src="./1520063698015.png" alt="Alt text"><br><img src="./1520063746123.png" alt="Alt text"><br><img src="./1520250996226.png" alt="Alt text"><br><img src="./1520251054232.png" alt="Alt text"><br><img src="./1520251096782.png" alt="Alt text"><br><img src="./1520931938548.png" alt="Alt text"><br><img src="./1520931982324.png" alt="Alt text"><br><img src="./1520932012314.png" alt="Alt text"></p><h4 id="37、Armstrong-公理系统"><a href="#37、Armstrong-公理系统" class="headerlink" title="37、Armstrong 公理系统"></a>37、Armstrong 公理系统</h4><p><img src="./1520064305887.png" alt="Alt text"><br><img src="./1520064332613.png" alt="Alt text"><br><a href="http://www.cnblogs.com/bewolf/p/4445027.html" target="_blank" rel="noopener">http://www.cnblogs.com/bewolf/p/4445027.html</a></p><h4 id="38、登记日志文件时为什么必须先写日志文件，后修改数据库？"><a href="#38、登记日志文件时为什么必须先写日志文件，后修改数据库？" class="headerlink" title="38、登记日志文件时为什么必须先写日志文件，后修改数据库？"></a>38、登记日志文件时为什么必须先写日志文件，后修改数据库？</h4><blockquote><ul><li>当两个操作之间发生故障时，只写入成功一个的时候：<ul><li>若先写数据库，日志文件没写成功，则无法恢复</li><li>若先写日志文件，数据库没写成功，则执行UNDO操作即可恢复</li></ul></li></ul></blockquote><h4 id="39、事务重做与回滚策略"><a href="#39、事务重做与回滚策略" class="headerlink" title="39、事务重做与回滚策略"></a>39、事务重做与回滚策略</h4><blockquote><ul><li>若故障发生时，T1的事物已开始但未做完则回滚，否则重做</li></ul></blockquote><h4 id="40、故障的恢复策略和方法"><a href="#40、故障的恢复策略和方法" class="headerlink" title="40、故障的恢复策略和方法"></a>40、故障的恢复策略和方法</h4><blockquote><ul><li><p>事务故障的恢复策略和方法</p><ul><li>反向扫描文件日志，查找该事务的更新操作</li><li>对该事物的更新操作执行逆操作，直至读到此事物的开始标记，事务故障恢复完成</li></ul></li><li><p>系统故障的恢复策略和方法</p><ul><li>正向扫描日志文件找出在故障发生前已经提交的事务队列和未完成的事物队列</li><li>对未完成的事务队列中的各个事务执行回滚操作</li><li>对已经提交的事务队列中的各个事务执行重做操作</li></ul></li><li>介质故障的恢复策略和方法<ul><li>装入最新的数据库后备副本，是数据库恢复到最近一次转储时的一致性状态</li><li>装入转储结束时刻的日志文件副本</li><li>启动系统恢复命令，由DBMS完成恢复功能</li></ul></li></ul></blockquote><h4 id="41、检查点技术的优点"><a href="#41、检查点技术的优点" class="headerlink" title="41、检查点技术的优点"></a>41、检查点技术的优点</h4><blockquote><ul><li>利用检查点技术，只需从某个时刻开始扫描日志文件，这样就缩短了扫描日志的时间</li><li>检查点技术不需要执行重做操作</li></ul></blockquote><h4 id="42、数据库镜像的用途"><a href="#42、数据库镜像的用途" class="headerlink" title="42、数据库镜像的用途"></a>42、数据库镜像的用途</h4><blockquote><ul><li>保证镜像数据与主数据一致性 </li><li>用途：<ul><li>用于数据库恢复</li><li>提高数据的可用性（充当从服务器）</li></ul></li></ul></blockquote><h4 id="43、并发控制"><a href="#43、并发控制" class="headerlink" title="43、并发控制"></a>43、并发控制</h4><blockquote><ul><li>保证事务的一致性和隔离性</li><li>带来数据不一致：<ul><li>丢失修改（结果被覆盖）</li><li>不可重复读（数据被修改）</li><li>读脏数据（读到不正确的数据）</li></ul></li></ul></blockquote><h4 id="44、基本的封锁类型"><a href="#44、基本的封锁类型" class="headerlink" title="44、基本的封锁类型"></a>44、基本的封锁类型</h4><blockquote><ul><li>排他锁（写锁）</li><li>共享锁（读锁）</li></ul></blockquote><h4 id="45、活锁的含义及其避免策略"><a href="#45、活锁的含义及其避免策略" class="headerlink" title="45、活锁的含义及其避免策略"></a>45、活锁的含义及其避免策略</h4><blockquote><ul><li>含义：该等待事务等待时间太长，好像被锁住了</li><li>避免策略：先来先服务</li></ul></blockquote><h4 id="46、死锁的含义及其避免策略"><a href="#46、死锁的含义及其避免策略" class="headerlink" title="46、死锁的含义及其避免策略"></a>46、死锁的含义及其避免策略</h4><blockquote><ul><li>含义：事务永远无法结束，形成死锁</li><li>避免策略：<ul><li>一次封锁（一次将所要使用的数据加锁）</li><li>顺序封锁（预先规定封锁顺序）</li></ul></li><li>诊断死锁：超时法、事务等待图法</li></ul></blockquote><h4 id="47、可串行化的调度"><a href="#47、可串行化的调度" class="headerlink" title="47、可串行化的调度"></a>47、可串行化的调度</h4><blockquote><ul><li>定义：多个事务的并发执行是正确的，当且仅当其结果与按某一次次序串行地执行它们时的结果相同</li></ul></blockquote><h4 id="48、两段锁协议"><a href="#48、两段锁协议" class="headerlink" title="48、两段锁协议"></a>48、两段锁协议</h4><blockquote><ul><li>先一起获得锁，再一起释放锁，两个阶段分开</li></ul></blockquote><h4 id="49、意向锁的作用和含义"><a href="#49、意向锁的作用和含义" class="headerlink" title="49、意向锁的作用和含义"></a>49、意向锁的作用和含义</h4><blockquote><ul><li>提高封锁子系统的效率</li><li>对任一节点加锁时，先对它的上层节点加意向锁。引进意向锁之后，系统对某一个数据对象加锁时不必逐个检查与下一级节点的封锁冲突了</li></ul></blockquote><h4 id="50、依赖集求候选码"><a href="#50、依赖集求候选码" class="headerlink" title="50、依赖集求候选码"></a>50、依赖集求候选码</h4><blockquote><ul><li>四大类型：<ul><li>L：属性值出现在左边</li><li>R：属性值出现在右边</li><li>N：属性值两边都没有</li><li>LR：属性值出现在两边</li></ul></li><li>定理：<ol><li>若X是L类的属性，则X是R的任一候选码成员</li><li>若X是R类的属性，则X不在任何候选码中</li><li>若X是N类的属性，则X必是R的其中一个候选码</li><li>若X是N和L类的属性，则X是R的唯一候选码</li></ol></li></ul></blockquote><h1 id="补充："><a href="#补充：" class="headerlink" title="补充："></a>补充：</h1><ol><li>模式分解<ul><li>若要求分解保持函数依赖，则总可以达到3NF, 但不一定能达到BCNF.</li><li>若要求分解既保持函数依赖，又保持无损连接，则可以达到3NF, 但不一定能达到BCNF.</li><li>若要求分解保持无损连接，则一定能达到4NF.</li></ul></li><li>判断模式分解的保持函数依赖以及无损连接性（见课件——第13讲模式分解.pdf）</li><li>创建索引<ul><li>CREATE UNIQUE INDEX SPJ_NO ON SPJ(Sno ASC，Pno DESC，JNO ASC)；</li></ul></li><li><p>在 DBTG 系统中，数据的存取机制有哪几种？<br>（1）入口点的存取方法。例如用 HASH 方法，索引方法<br>（2）导航的存取方法。<br>（3）用 DBK 直接存取记录的方法。</p></li><li><p>试述 IMS 系统中数据库组织的方法</p><ul><li>IMS 提供了两类数据库组织的方法，HS 和 HD。它们的共同点是：都按 IMS<br>的层次序列来组织一个数据库记录的逻辑次序。不同点是：HS 类用邻接<br>法实现层次序列，HD 类用链接法实现层次序列，所以，前者称为层次顺<br>序，后者称为层次直接。在这两种组织中又按根片段不同的组织方法分<br>为四种，根片段有两种组织方法，索引的（HISAM、HIDAM）和直接的（HDAM）<br>即杂凑方法。</li></ul></li></ol>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>爬虫</title>
      <link href="/2018/03/28/pa-chong/"/>
      <url>/2018/03/28/pa-chong/</url>
      
        <content type="html"><![CDATA[<h3 id="1-创建项目"><a href="#1-创建项目" class="headerlink" title="1.创建项目"></a>1.创建项目</h3><blockquote><ul><li>scrapy startproject p1</li></ul></blockquote><h3 id="2-文件说明："><a href="#2-文件说明：" class="headerlink" title="2.文件说明："></a>2.文件说明：</h3><blockquote><ul><li>scrapy.cfg  项目的配置信息，主要为Scrapy命令行工具提供一个基础的配置信息。（真正爬虫相关的配置信息在settings.py文件中）<br>items.py    设置数据存储模板，用于结构化数据，如：Django的Model<br>pipelines    数据处理行为，如：一般结构化的数据持久化<br>settings.py 配置文件，如：递归的层数、并发数，延迟下载等<br>spiders      爬虫目录，如：创建文件，编写爬虫规则<br>注意：一般创建爬虫文件时，以网站域名命名</li></ul></blockquote><h3 id="3-编写爬虫"><a href="#3-编写爬虫" class="headerlink" title="3.编写爬虫"></a>3.编写爬虫</h3><blockquote><ul><li>在spiders目录中新建 xiaohuar_spider.py 文件</li></ul></blockquote><h3 id="4-运行"><a href="#4-运行" class="headerlink" title="4.运行"></a>4.运行</h3><blockquote><ul><li>进入p1目录，运行命令scrapy crawl xiaohau —nolog</li><li>格式：scrapy crawl+爬虫名  –nolog即不显示日志</li></ul></blockquote><p>[注]: scrapy 报错 no module named win32api解决方案如下：</p><blockquote><ul><li>pip install pypiwin32</li></ul></blockquote>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>Hexo+GithubPage制作自己的博客</title>
      <link href="/2018/01/30/hexo-githubpage/"/>
      <url>/2018/01/30/hexo-githubpage/</url>
      
        <content type="html"><![CDATA[<h2 id="具体步骤如下："><a href="#具体步骤如下：" class="headerlink" title="具体步骤如下："></a><strong>具体步骤如下</strong>：</h2><h3 id="1-创建一个文件夹（如Blog"><a href="#1-创建一个文件夹（如Blog" class="headerlink" title="1. 创建一个文件夹（如Blog)"></a>1. 创建一个文件夹（如Blog)</h3><h3 id="2-开始安装Hexo，在Bolg文件夹里面打开git-bash，输入如下命令"><a href="#2-开始安装Hexo，在Bolg文件夹里面打开git-bash，输入如下命令" class="headerlink" title="2. 开始安装Hexo，在Bolg文件夹里面打开git bash，输入如下命令"></a>2. 开始安装Hexo，在Bolg文件夹里面打开git bash，输入如下命令</h3><pre class="line-numbers language-lang-bash"><code class="language-lang-bash">$ npm install hexo -g<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-初始化Hexo"><a href="#3-初始化Hexo" class="headerlink" title="3. 初始化Hexo"></a>3. 初始化Hexo</h3><pre class="line-numbers language-lang-bash"><code class="language-lang-bash">$ hexo init<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-输入命令，安装所需要的组件"><a href="#4-输入命令，安装所需要的组件" class="headerlink" title="4. 输入命令，安装所需要的组件"></a>4. 输入命令，安装所需要的组件</h3><pre class="line-numbers language-lang-bash"><code class="language-lang-bash">$ npm install<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="5-首次体验Hexo"><a href="#5-首次体验Hexo" class="headerlink" title="5. 首次体验Hexo"></a>5. 首次体验Hexo</h3><pre class="line-numbers language-lang-bash"><code class="language-lang-bash">$ hexo g<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="6-开启服务器，访问该网址，正式体验Hexo"><a href="#6-开启服务器，访问该网址，正式体验Hexo" class="headerlink" title="6. 开启服务器，访问该网址，正式体验Hexo"></a>6. 开启服务器，访问该网址，正式体验Hexo</h3><pre class="line-numbers language-lang-bash"><code class="language-lang-bash">$ hexo s<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="7-首次体验Hexo"><a href="#7-首次体验Hexo" class="headerlink" title="7. 首次体验Hexo"></a>7. 首次体验Hexo</h3><pre class="line-numbers language-lang-bash"><code class="language-lang-bash">$ hexo g<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="8-配置Deployment，在其文件夹中，找到-config-yml文件，修改repo值（在末尾）"><a href="#8-配置Deployment，在其文件夹中，找到-config-yml文件，修改repo值（在末尾）" class="headerlink" title="8. 配置Deployment，在其文件夹中，找到_config.yml文件，修改repo值（在末尾）"></a>8. 配置Deployment，在其文件夹中，找到_config.yml文件，修改repo值（在末尾）</h3><pre class="line-numbers language-lang-bash"><code class="language-lang-bash">deploy:  type: git  repository: git@github.com:ZSCDumin/ZSCDumin.github.io.git  branch: master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="9-新建一篇博客，命令如下"><a href="#9-新建一篇博客，命令如下" class="headerlink" title="9. 新建一篇博客，命令如下"></a>9. 新建一篇博客，命令如下</h3><pre class="line-numbers language-lang-bash"><code class="language-lang-bash">$ hexo new post "博客名"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="10-安装一个扩展"><a href="#10-安装一个扩展" class="headerlink" title="10. 安装一个扩展"></a>10. 安装一个扩展</h3><pre class="line-numbers language-lang-bash"><code class="language-lang-bash">$ npm install hexo-deployer-git --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="11-生成以及部署"><a href="#11-生成以及部署" class="headerlink" title="11. 生成以及部署"></a>11. 生成以及部署</h3><pre class="line-numbers language-lang-bash"><code class="language-lang-bash">$ hexo d -g<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      
    </entry>
    
  
  
</search>
